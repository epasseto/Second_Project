{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "#measuring time and making basic math\n",
    "from time import time\n",
    "import math\n",
    "import numpy as np\n",
    "import udacourse2 #my library for this project!\n",
    "\n",
    "#my own ETL pipeline\n",
    "#import process_data as pr\n",
    "\n",
    "#dealing with datasets and showing content\n",
    "import pandas as pd\n",
    "#import pprint as pp\n",
    "\n",
    "#SQLAlchemy toolkit\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import pool\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "#natural language toolkit\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#REGEX toolkit\n",
    "import re\n",
    "\n",
    "#Machine Learning toolkit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Machine Learning Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier #need MOClassifier!\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#pickling tool\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trying to use NLTK, I took the following error:\n",
    "\n",
    "- the point is - it´s not only about installing a library\n",
    "\n",
    "- you need to install de supporting dictionnaries for doing the tasks\n",
    "\n",
    "- this can be solved quite easilly (in hope that I will find a Portuguese-Brazil dictionnary when I will need to put it in practic in my work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    LookupError: \n",
    "    **********************************************************************\n",
    "      Resource stopwords not found.\n",
    "      Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "      >>> import nltk\n",
    "      >>> nltk.download('stopwords')\n",
    "  \n",
    "      For more information see: https://www.nltk.org/data.html\n",
    "\n",
    "      Attempted to load corpora/stopwords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    LookupError: \n",
    "    **********************************************************************\n",
    "    Resource stopwords not found.\n",
    "    Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "    >>> import nltk\n",
    "    >>> nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    LookupError: \n",
    "    **********************************************************************\n",
    "    Resource wordnet not found.\n",
    "    Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "    >>> import nltk\n",
    "    >>> nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing tables in my SQLite database: ['Messages']\n"
     ]
    }
   ],
   "source": [
    "#load data from database\n",
    "#setting NullPool prevents a pool, so it is easy to close the database connection\n",
    "#in our case, the DB is so simple, that it looks the best choice\n",
    "#SLQAlchemy documentation\n",
    "#https://docs.sqlalchemy.org/en/14/core/reflection.html\n",
    "engine = create_engine('sqlite:///Messages.db', poolclass=pool.NullPool) #, echo=True)\n",
    "\n",
    "#retrieving tables names from my DB\n",
    "#https://stackoverflow.com/questions/6473925/sqlalchemy-getting-a-list-of-tables\n",
    "inspector = inspect(engine)\n",
    "print('existing tables in my SQLite database:', inspector.get_table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As my target is Messages table, so I reed this table as a Pandas dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>if_blank</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  Weather update - a cold front from Cuba that c...   \n",
       "\n",
       "                                            original   genre  if_blank  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct         0   \n",
       "\n",
       "   related  request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        1        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing MySQL to Pandas\n",
    "#https://stackoverflow.com/questions/37730243/importing-data-from-a-mysql-database-into-a-pandas-data-frame-including-column-n/37730334\n",
    "#connection_str = 'mysql+pymysql://mysql_user:mysql_password@mysql_host/mysql_db'\n",
    "#connection = create_engine(connection_str)\n",
    "\n",
    "connection = engine.connect()\n",
    "df = pd.read_sql('SELECT * FROM Messages', con=connection)\n",
    "connection.close()\n",
    "\n",
    "df.name = 'df'\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting in X and Y datasets:\n",
    "\n",
    "- X is the **Message** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Weather update - a cold front from Cuba that c...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['message']\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Y is the **Classification** labels\n",
    "\n",
    "- I excluded all my columns that don´t make sense as labels to classify our message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone  ...  aid_centers  \\\n",
       "0                  0         0         0            0  ...            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df[df.columns[4:]]\n",
    "Y.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weather update - a cold front from Cuba that could pass over Haiti'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_text = X.iloc[0]\n",
    "msg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weather update     a   cold front from cuba s that could pass over haiti  today'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let´s insert some noise to see if it is filtering well\n",
    "msg_text = \"Weather update01 - a 00cold-front from Cuba's that could pass over Haiti' today\"\n",
    "low_text = msg_text.lower()\n",
    "\n",
    "#I need to take only valid words\n",
    "#a basic one (very common in Regex courses classes)\n",
    "gex_text = re.sub(r'[^a-zA-Z]', ' ', low_text)\n",
    "\n",
    "#other tryed sollutions from several sources\n",
    "#re.sub(r'^\\b[^a-zA-Z]\\b', ' ', low_text)\n",
    "#re.sub(r'^/[^a-zA-Z ]/g', ' ', low_text)\n",
    "#re.sub(r'^/[^a-zA-Z0-9 ]/g', ' ', low_text)\n",
    "\n",
    "gex_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found this [here](https://stackoverflow.com/questions/1751301/regex-match-entire-words-only)\n",
    "\n",
    "- '-' passed away, so it´s not so nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weather update01 - a 00cold-front from cuba's that could pass over haiti' today\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'^/\\b($word)\\b/i', ' ', low_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weather update01 - a 00cold-front from cuba's that could pass over haiti' today\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'^\\b[a-zA-Z]{3}\\b', ' ', low_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weather update01 - a 00cold-front from cuba's that could pass over haiti' today\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'^[a-zA-Z]{3}$', ' ', low_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather',\n",
       " 'update',\n",
       " 'a',\n",
       " 'cold',\n",
       " 'front',\n",
       " 'from',\n",
       " 'cuba',\n",
       " 's',\n",
       " 'that',\n",
       " 'could',\n",
       " 'pass',\n",
       " 'over',\n",
       " 'haiti',\n",
       " 'today']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_words = word_tokenize(gex_text)\n",
    "col_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather',\n",
       " 'update',\n",
       " 'cold',\n",
       " 'front',\n",
       " 'cuba',\n",
       " 'could',\n",
       " 'pass',\n",
       " 'haiti',\n",
       " 'today']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unnuseful = stopwords.words(\"english\")\n",
    "relevant_words = [word for word in col_words if word not in unnuseful]\n",
    "relevant_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed a lot of geographic references. I think they will not be so useful for us. Let´s try to remove them too...\n",
    "\n",
    "References for City at NLKT [here](https://stackoverflow.com/questions/37025872/unable-to-import-city-database-dataset-from-nltk-data-in-anaconda-spyder-windows?rq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.sem.chat80 as ct #.sql_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LookupError: \n",
    "**********************************************************************\n",
    "  Resource city_database not found.\n",
    "  Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "  >>> import nltk\n",
    "  >>> nltk.download('city_database')\n",
    "  \n",
    "  For more information see: https://www.nltk.org/data.html\n",
    "\n",
    "  Attempted to load corpora/city_database/city.db\n",
    "\n",
    "  Searched in:\n",
    "    - 'C:\\\\Users\\\\epass/nltk_data'\n",
    "    - 'C:\\\\ProgramData\\\\Anaconda3\\\\nltk_data'\n",
    "    - 'C:\\\\ProgramData\\\\Anaconda3\\\\share\\\\nltk_data'\n",
    "    - 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data'\n",
    "    - 'C:\\\\Users\\\\epass\\\\AppData\\\\Roaming\\\\nltk_data'\n",
    "    - 'C:\\\\nltk_data'\n",
    "    - 'D:\\\\nltk_data'\n",
    "    - 'E:\\\\nltk_data'\n",
    "**********************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('city_database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = {\n",
    "    country:city for city, country in ct.sql_query(\n",
    "        \"corpora/city_database/city.db\",\n",
    "        \"SELECT City, Country FROM city_table\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look nice (and lower cased):\n",
    "    \n",
    "- observe possible errors with composite names, like united_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greece\n",
      "thailand\n",
      "spain\n",
      "east_germany\n",
      "united_kingdom\n",
      "india\n",
      "belgium\n",
      "romania\n",
      "hungary\n",
      "argentina\n",
      "egypt\n",
      "china\n",
      "venezuela\n",
      "united_states\n",
      "west_germany\n",
      "hongkong\n",
      "turkey\n",
      "indonesia\n",
      "south_africa\n",
      "pakistan\n",
      "soviet_union\n",
      "japan\n",
      "peru\n",
      "philippines\n",
      "australia\n",
      "mexico\n",
      "italy\n",
      "canada\n",
      "france\n",
      "south_korea\n",
      "brazil\n",
      "vietnam\n",
      "chile\n",
      "singapore\n",
      "iran\n",
      "austria\n",
      "poland\n"
     ]
    }
   ],
   "source": [
    "for c in countries:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I couldn't find Haiti:\n",
    "\n",
    "- countries list is not complete!\n",
    "\n",
    "- it gaves `KeyError: 'haiti'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countries['haiti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather',\n",
       " 'update',\n",
       " 'cold',\n",
       " 'front',\n",
       " 'cuba',\n",
       " 'could',\n",
       " 'pass',\n",
       " 'haiti',\n",
       " 'today']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nogeo_words = [word for word in relevant_words if word not in countries]\n",
    "nogeo_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortatelly, it´s only a **demo**! We need something better for our project..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umm Al Quwain City</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ras Al Khaimah City</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zayed City</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  City          Region\n",
       "0         les Escaldes  Europe/Andorra\n",
       "1     Andorra la Vella  Europe/Andorra\n",
       "2   Umm Al Quwain City      Asia/Dubai\n",
       "3  Ras Al Khaimah City      Asia/Dubai\n",
       "4           Zayed City      Asia/Dubai"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_cities = pd.read_csv('cities15000.txt', sep=';')\n",
    "df_cities = pd.read_csv('cities15000.txt', sep='\\t', header=None)\n",
    "df_cities_15000 = df_cities[[1, 17]]\n",
    "df_cities_15000.columns = ['City', 'Region']\n",
    "df_cities_15000.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried this [here](https://data.opendatasoft.com/explore/dataset/geonames-all-cities-with-a-population-1000%40public/information/?disjunctive.cou_name_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3040051</td>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>Ehskal'des-Ehndzhordani,Escaldes,Escaldes-Engo...</td>\n",
       "      <td>42.50729</td>\n",
       "      <td>1.53414</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1033</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2008-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3041563</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>ALV,Ando-la-Vyey,Andora,Andora la Vela,Andora ...</td>\n",
       "      <td>42.50779</td>\n",
       "      <td>1.52109</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLC</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1037</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2020-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290594</td>\n",
       "      <td>Umm Al Quwain City</td>\n",
       "      <td>Umm Al Quwain City</td>\n",
       "      <td>Oumm al Qaiwain,Oumm al Qaïwaïn,Um al Kawain,U...</td>\n",
       "      <td>25.56473</td>\n",
       "      <td>55.55517</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "      <td>2019-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>291074</td>\n",
       "      <td>Ras Al Khaimah City</td>\n",
       "      <td>Ras Al Khaimah City</td>\n",
       "      <td>Julfa,Khaimah,RAK City,RKT,Ra's al Khaymah,Ra'...</td>\n",
       "      <td>25.78953</td>\n",
       "      <td>55.94320</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>351943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "      <td>2019-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291580</td>\n",
       "      <td>Zayed City</td>\n",
       "      <td>Zayed City</td>\n",
       "      <td>Bid' Zayed,Bid’ Zayed,Madinat Za'id,Madinat Za...</td>\n",
       "      <td>23.65416</td>\n",
       "      <td>53.70522</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "      <td>2019-10-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                    1                    2   \\\n",
       "0  3040051         les Escaldes         les Escaldes   \n",
       "1  3041563     Andorra la Vella     Andorra la Vella   \n",
       "2   290594   Umm Al Quwain City   Umm Al Quwain City   \n",
       "3   291074  Ras Al Khaimah City  Ras Al Khaimah City   \n",
       "4   291580           Zayed City           Zayed City   \n",
       "\n",
       "                                                  3         4         5  6   \\\n",
       "0  Ehskal'des-Ehndzhordani,Escaldes,Escaldes-Engo...  42.50729   1.53414  P   \n",
       "1  ALV,Ando-la-Vyey,Andora,Andora la Vela,Andora ...  42.50779   1.52109  P   \n",
       "2  Oumm al Qaiwain,Oumm al Qaïwaïn,Um al Kawain,U...  25.56473  55.55517  P   \n",
       "3  Julfa,Khaimah,RAK City,RKT,Ra's al Khaymah,Ra'...  25.78953  55.94320  P   \n",
       "4  Bid' Zayed,Bid’ Zayed,Madinat Za'id,Madinat Za...  23.65416  53.70522  P   \n",
       "\n",
       "     7   8    9   10   11   12   13      14  15    16              17  \\\n",
       "0  PPLA  AD  NaN  08  NaN  NaN  NaN   15853 NaN  1033  Europe/Andorra   \n",
       "1  PPLC  AD  NaN  07  NaN  NaN  NaN   20430 NaN  1037  Europe/Andorra   \n",
       "2  PPLA  AE  NaN  07  NaN  NaN  NaN   62747 NaN     2      Asia/Dubai   \n",
       "3  PPLA  AE  NaN  05  NaN  NaN  NaN  351943 NaN     2      Asia/Dubai   \n",
       "4   PPL  AE  NaN  01  103  NaN  NaN   63482 NaN   124      Asia/Dubai   \n",
       "\n",
       "           18  \n",
       "0  2008-10-15  \n",
       "1  2020-03-03  \n",
       "2  2019-10-24  \n",
       "3  2019-09-09  \n",
       "4  2019-10-24  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "found country names at Github [here](https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes/blob/master/all/all.csv)\n",
    "\n",
    "- a small trick and we have our own coutries list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afghanistan',\n",
       " 'åland islands',\n",
       " 'albania',\n",
       " 'algeria',\n",
       " 'american samoa',\n",
       " 'andorra',\n",
       " 'angola',\n",
       " 'anguilla',\n",
       " 'antarctica',\n",
       " 'antigua and barbuda',\n",
       " 'argentina',\n",
       " 'armenia',\n",
       " 'aruba',\n",
       " 'australia',\n",
       " 'austria',\n",
       " 'azerbaijan',\n",
       " 'bahamas',\n",
       " 'bahrain',\n",
       " 'bangladesh',\n",
       " 'barbados',\n",
       " 'belarus',\n",
       " 'belgium',\n",
       " 'belize',\n",
       " 'benin',\n",
       " 'bermuda',\n",
       " 'bhutan',\n",
       " 'bolivia (plurinational state of)',\n",
       " 'bonaire, sint eustatius and saba',\n",
       " 'bosnia and herzegovina',\n",
       " 'botswana',\n",
       " 'bouvet island',\n",
       " 'brazil',\n",
       " 'british indian ocean territory',\n",
       " 'brunei darussalam',\n",
       " 'bulgaria',\n",
       " 'burkina faso',\n",
       " 'burundi',\n",
       " 'cabo verde',\n",
       " 'cambodia',\n",
       " 'cameroon',\n",
       " 'canada',\n",
       " 'cayman islands',\n",
       " 'central african republic',\n",
       " 'chad',\n",
       " 'chile',\n",
       " 'china',\n",
       " 'christmas island',\n",
       " 'cocos (keeling) islands',\n",
       " 'colombia',\n",
       " 'comoros',\n",
       " 'congo',\n",
       " 'congo, democratic republic of the',\n",
       " 'cook islands',\n",
       " 'costa rica',\n",
       " \"côte d'ivoire\",\n",
       " 'croatia',\n",
       " 'cuba',\n",
       " 'curaçao',\n",
       " 'cyprus',\n",
       " 'czechia',\n",
       " 'denmark',\n",
       " 'djibouti',\n",
       " 'dominica',\n",
       " 'dominican republic',\n",
       " 'ecuador',\n",
       " 'egypt',\n",
       " 'el salvador',\n",
       " 'equatorial guinea',\n",
       " 'eritrea',\n",
       " 'estonia',\n",
       " 'eswatini',\n",
       " 'ethiopia',\n",
       " 'falkland islands (malvinas)',\n",
       " 'faroe islands',\n",
       " 'fiji',\n",
       " 'finland',\n",
       " 'france',\n",
       " 'french guiana',\n",
       " 'french polynesia',\n",
       " 'french southern territories',\n",
       " 'gabon',\n",
       " 'gambia',\n",
       " 'georgia',\n",
       " 'germany',\n",
       " 'ghana',\n",
       " 'gibraltar',\n",
       " 'greece',\n",
       " 'greenland',\n",
       " 'grenada',\n",
       " 'guadeloupe',\n",
       " 'guam',\n",
       " 'guatemala',\n",
       " 'guernsey',\n",
       " 'guinea',\n",
       " 'guinea-bissau',\n",
       " 'guyana',\n",
       " 'haiti',\n",
       " 'heard island and mcdonald islands',\n",
       " 'holy see',\n",
       " 'honduras',\n",
       " 'hong kong',\n",
       " 'hungary',\n",
       " 'iceland',\n",
       " 'india',\n",
       " 'indonesia',\n",
       " 'iran (islamic republic of)',\n",
       " 'iraq',\n",
       " 'ireland',\n",
       " 'isle of man',\n",
       " 'israel',\n",
       " 'italy',\n",
       " 'jamaica',\n",
       " 'japan',\n",
       " 'jersey',\n",
       " 'jordan',\n",
       " 'kazakhstan',\n",
       " 'kenya',\n",
       " 'kiribati',\n",
       " \"korea (democratic people's republic of)\",\n",
       " 'korea, republic of',\n",
       " 'kuwait',\n",
       " 'kyrgyzstan',\n",
       " \"lao people's democratic republic\",\n",
       " 'latvia',\n",
       " 'lebanon',\n",
       " 'lesotho',\n",
       " 'liberia',\n",
       " 'libya',\n",
       " 'liechtenstein',\n",
       " 'lithuania',\n",
       " 'luxembourg',\n",
       " 'macao',\n",
       " 'madagascar',\n",
       " 'malawi',\n",
       " 'malaysia',\n",
       " 'maldives',\n",
       " 'mali',\n",
       " 'malta',\n",
       " 'marshall islands',\n",
       " 'martinique',\n",
       " 'mauritania',\n",
       " 'mauritius',\n",
       " 'mayotte',\n",
       " 'mexico',\n",
       " 'micronesia (federated states of)',\n",
       " 'moldova, republic of',\n",
       " 'monaco',\n",
       " 'mongolia',\n",
       " 'montenegro',\n",
       " 'montserrat',\n",
       " 'morocco',\n",
       " 'mozambique',\n",
       " 'myanmar',\n",
       " 'namibia',\n",
       " 'nauru',\n",
       " 'nepal',\n",
       " 'netherlands',\n",
       " 'new caledonia',\n",
       " 'new zealand',\n",
       " 'nicaragua',\n",
       " 'niger',\n",
       " 'nigeria',\n",
       " 'niue',\n",
       " 'norfolk island',\n",
       " 'north macedonia',\n",
       " 'northern mariana islands',\n",
       " 'norway',\n",
       " 'oman',\n",
       " 'pakistan',\n",
       " 'palau',\n",
       " 'palestine, state of',\n",
       " 'panama',\n",
       " 'papua new guinea',\n",
       " 'paraguay',\n",
       " 'peru',\n",
       " 'philippines',\n",
       " 'pitcairn',\n",
       " 'poland',\n",
       " 'portugal',\n",
       " 'puerto rico',\n",
       " 'qatar',\n",
       " 'réunion',\n",
       " 'romania',\n",
       " 'russian federation',\n",
       " 'rwanda',\n",
       " 'saint barthélemy',\n",
       " 'saint helena, ascension and tristan da cunha',\n",
       " 'saint kitts and nevis',\n",
       " 'saint lucia',\n",
       " 'saint martin (french part)',\n",
       " 'saint pierre and miquelon',\n",
       " 'saint vincent and the grenadines',\n",
       " 'samoa',\n",
       " 'san marino',\n",
       " 'sao tome and principe',\n",
       " 'saudi arabia',\n",
       " 'senegal',\n",
       " 'serbia',\n",
       " 'seychelles',\n",
       " 'sierra leone',\n",
       " 'singapore',\n",
       " 'sint maarten (dutch part)',\n",
       " 'slovakia',\n",
       " 'slovenia',\n",
       " 'solomon islands',\n",
       " 'somalia',\n",
       " 'south africa',\n",
       " 'south georgia and the south sandwich islands',\n",
       " 'south sudan',\n",
       " 'spain',\n",
       " 'sri lanka',\n",
       " 'sudan',\n",
       " 'suriname',\n",
       " 'svalbard and jan mayen',\n",
       " 'sweden',\n",
       " 'switzerland',\n",
       " 'syrian arab republic',\n",
       " 'taiwan, province of china',\n",
       " 'tajikistan',\n",
       " 'tanzania, united republic of',\n",
       " 'thailand',\n",
       " 'timor-leste',\n",
       " 'togo',\n",
       " 'tokelau',\n",
       " 'tonga',\n",
       " 'trinidad and tobago',\n",
       " 'tunisia',\n",
       " 'turkey',\n",
       " 'turkmenistan',\n",
       " 'turks and caicos islands',\n",
       " 'tuvalu',\n",
       " 'uganda',\n",
       " 'ukraine',\n",
       " 'united arab emirates',\n",
       " 'united kingdom of great britain and northern ireland',\n",
       " 'united states of america',\n",
       " 'united states minor outlying islands',\n",
       " 'uruguay',\n",
       " 'uzbekistan',\n",
       " 'vanuatu',\n",
       " 'venezuela (bolivarian republic of)',\n",
       " 'viet nam',\n",
       " 'virgin islands (british)',\n",
       " 'virgin islands (u.s.)',\n",
       " 'wallis and futuna',\n",
       " 'western sahara',\n",
       " 'yemen',\n",
       " 'zambia',\n",
       " 'zimbabwe']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countries = pd.read_csv('all.csv')\n",
    "df_countries = df_countries['name'].apply(lambda x: x.lower())\n",
    "countries = df_countries.tolist()\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can elliminate (perhaps not the whole) a lot of names of countries. In our case, the produce noise on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather', 'update', 'cold', 'front', 'could', 'pass', 'today']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nogeo_words = [word for word in relevant_words if word not in countries]\n",
    "nogeo_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First test:\n",
    "    \n",
    "- over the first message only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['update', 'today', 'pass', 'weather', 'cold', 'haiti', 'front', 'cuba']\n"
     ]
    }
   ],
   "source": [
    "message = 'Weather update - a cold front from Cuba that could pass over Haiti'\n",
    "tokens = udacourse2.fn_tokenize_fast(msg_text, \n",
    "                                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###Tokenizer function started\n",
      "process time:0.0205 seconds\n",
      "Tokens-start:79, token/stop:9, remove cities:7 &noise:7\n",
      " +lemmatizer:7\n",
      " +eliminate short:7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['could', 'update', 'today', 'pas', 'weather', 'cold', 'front']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = 'Weather update - a cold front from Cuba that could pass over Haiti'\n",
    "tokens = udacourse2.fn_tokenize(msg_text, \n",
    "                                lemmatize=True, \n",
    "                                rem_city=True, \n",
    "                                agg_words=True,\n",
    "                                rem_noise=True,\n",
    "                                elm_short=3,\n",
    "                                verbose=True)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It´s not so cool, some noise is still appearing in lemmatized words:\n",
    "    \n",
    "- an \"l\" was found, as in **French words**, like *l'orange*;\n",
    "\n",
    "- my **City** filter needs a lot of improving, as it didn´t filter avenues and so many other **geographic** references;\n",
    "\n",
    "- it passed a lot of unnuseful **two** or less letters words, as **u**, **st**;\n",
    "\n",
    "- a lot of noisy words as **help**, **thanks**, **please** were found;\n",
    "\n",
    "- there are several words **repetition** in some messages, like ['river', ... 'river', ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic test call\n",
    "\n",
    "- only for the first 50 messages, verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['update', 'pass', 'weather', 'cold', 'haiti', 'front', 'cuba']\n",
      "['hurricane']\n",
      "['name', 'looking']\n",
      "['desperately', 'destroyed', 'hospital', 'leogane', 'croix', 'needs', 'supplies', 'functioning', 'reports']\n",
      "['today', 'tonight', 'side', 'haiti', 'rest', 'says']\n",
      "['national', 'information']\n",
      "['storm']\n",
      "['silo', 'water', 'need', 'tents', 'please']\n",
      "['messages', 'receive']\n",
      "['issues', 'health', 'workers', 'croix', 'des', 'bouquets']\n",
      "['water', 'starving', 'nothing', 'eat', 'thirsty']\n",
      "['petionville', 'regarding', 'information', 'need']\n",
      "['water', 'thomassin', 'desperately', 'pyron', 'need']\n",
      "['delma', 'didine', 'need', 'together', 'food']\n",
      "['order', 'participate', 'use', 'information']\n",
      "['water', 'temporary', 'delmas', 'impasse', 'medications', 'clothes', 'charite', 'need', 'tents', 'comitee', 'shelter', 'dire', 'food', 'please']\n",
      "['water', 'chretien', 'extension', 'impasse', 'dying', 'need', 'klecin', 'extended', 'hungry', 'sick', 'food', 'hunger']\n",
      "['want', 'call']\n",
      "['understand', 'use']\n",
      "['earthquake']\n",
      "['journalist', 'ginen', 'died', 'radio']\n",
      "['laplaine', 'victim']\n",
      "['informed', 'water', 'lack', 'moleya', 'please']\n",
      "['sibert', 'live', 'need', 'hungry', 'food']\n",
      "['water', 'nothing', 'faustin', 'want', 'anhy', 'medicine', 'food']\n",
      "['tell']\n",
      "['water', 'delma', 'anything', 'provide', 'medicine', 'food', 'please', 'ever']\n",
      "['away', 'help', 'needs', 'assistance', 'gressier']\n",
      "['cite', 'water', 'food', 'fontamara']\n",
      "['completely', 'odor', 'forgotten', 'killing', 'letting', 'need', 'help', 'carrefour', 'foul']\n",
      "['evening', 'please', 'information', 'tiyous', 'radio']\n",
      "['water', 'problem', 'delma', 'need', 'albert', 'food', 'jode']\n",
      "['needed', 'pant', 'phone', 'find']\n",
      "['lilavois', 'pap', 'sleeping', 'jan', 'coords', 'apparently', 'outdoors', 'field']\n",
      "['starving', 'need', 'want', 'help', 'carrefour', 'death']\n",
      "['water', 'differents', 'fontamara', 'needs', 'find', 'medicine', 'cite', 'food']\n",
      "['delmas', 'silo', 'water', 'need']\n",
      "['help', 'carrefour', 'cote', 'plage']\n",
      "['leoganes', 'food', 'please']\n",
      "['miracle', 'monseigneur', 'guilloux', 'water', 'alerte', 'mgr', 'comite', 'tents', 'urgently', 'streets', 'food', 'receive']\n",
      "['water', 'blocked', 'medical', 'wednesday', 'carrefour', 'shortage', 'assistance', 'food', 'dal']\n",
      "['hunger', 'dying', 'jacmel', 'working']\n",
      "['everybody', 'dead']\n",
      "['petit', 'talk', 'look', 'goave', 'please']\n",
      "['evening', 'earthquake']\n",
      "['fontamara', 'pierre', 'lots', 'difficulties', 'louis', 'help', 'impass', 'please']\n",
      "['upon', 'water', 'provided', 'evening', 'matisan', 'listening', 'strenght', 'shortage', 'work', 'food']\n",
      "['fontamara', 'aid', 'carrefour', 'find', 'food']\n",
      "['trinite', 'students', 'dead', 'listening', 'universite', 'jacmel', 'need', 'help', 'remove', 'professors', 'bodies', 'colege', 'radio']\n",
      "['tractor', 'civil', 'social', 'jacmel', 'requesting', 'disturbance', 'unrest']\n",
      "['asking', 'haiti', 'prayer']\n",
      "['water', 'marotiere', 'shortage', 'food', 'please']\n",
      "['asking', 'change', 'gallon', 'listening', 'miraguan', 'gas', 'government']\n",
      "['arab']\n",
      "['teachers', 'asking', 'trinite', 'students', 'dead', 'listening', 'jacmel', 'inasmo', 'help', 'remove', 'bodies', 'college', 'university', 'radio']\n",
      "['transfert', 'house', 'money', 'haiti']\n",
      "['school', 'trinite', 'sainte', 'found', 'colombian', 'cookies', 'brought', 'dogs', 'information', 'jacmel', 'keeping', 'rubbles', 'alive', 'ecole']\n",
      "['help', 'jacmel']\n",
      "['fontamara', 'menos', 'help', 'find', 'food']\n",
      "['police', 'officers', 'insecure', 'provide', 'sos', 'streets', 'please']\n",
      "['water', 'provided', 'mother']\n",
      "['baby', 'water', 'needing', 'beach']\n",
      "['haitian', 'tell', 'needed', 'help', 'fond', 'parisien', 'idea']\n",
      "['asking', 'water', 'medical', 'supply', 'food']\n",
      "['collapses', 'collapsed', 'completly', 'home', 'distroy', 'almost', 'gressier']\n",
      "['water', 'provided', 'food', 'distributed']\n",
      "['religious', 'happy', 'hear', 'hyme']\n",
      "['seven', 'sure', 'betwenn', 'house', 'dyobel', 'information', 'dyobal', 'musso', 'rest', 'clear', 'juvenat']\n",
      "['teams', 'interpreter', 'help', 'pastor', 'seeking']\n",
      "['water', 'police', 'problem', 'want', 'almost', 'paco', 'food', 'lazon']\n",
      "['received', 'water', 'sainte', 'gourdes', 'anything', 'buying', 'areas', 'warm', 'bernadette']\n",
      "['family', 'cell', 'phone', 'help', 'communicate', 'minutes', 'please']\n",
      "['lilavois', 'sleeping', 'dying', 'field', 'hunger', 'outside']\n",
      "['news', 'happen', 'friend', 'dont', 'hear', 'carrefour', 'petion']\n",
      "['help', 'asking', 'especially', 'sath']\n",
      "['mechanic', 'want', 'driver', 'help']\n",
      "['news', 'hospitals', 'found', 'dead', 'seems', 'need', 'help', 'books', 'registry', 'body', 'please', 'checked']\n",
      "['without', 'problem', 'port', 'big', 'left', 'clothes', 'jacmel', 'situation', 'really', 'critical', 'money', 'food']\n",
      "['help', 'communale', 'violence', 'receive']\n",
      "['food', 'distributed']\n",
      "['anbasad', 'camp', 'read', 'group', 'carnaval', 'creole', 'refer', 'play', 'help', 'comment', 'cry', 'simple']\n",
      "['tomorrow', 'expected', 'rain', 'found', 'tonight', 'cold', 'haiti', 'morning', 'front', 'isolated', 'cuba', 'showers']\n",
      "['cell', 'phone', 'buy', 'find', 'minuts', 'cards', 'give']\n",
      "['shirt', 'black', 'wearing', 'sees', 'printed', 'skirt', 'streets', 'white', 'cornrow', 'denim', 'whoever', 'hair']\n",
      "['toiletries', 'need', 'help', 'food', 'please']\n",
      "['forcast', 'pass', 'weather', 'cold', 'haiti', 'front', 'night', 'cuba']\n",
      "['cistern', 'water', 'provided', 'lovation', 'mediacation', 'dont', 'tents', 'selves', 'using', 'protect', 'food']\n",
      "['help']\n",
      "['adjs', 'especially', 'collapsing', 'suffering', 'something', 'house', 'talking', 'group', 'pop', 'jacmel', 'cut', 'sot', 'victims', 'southeast']\n",
      "['suffering', 'south', 'services', 'victims', 'aid', 'request', 'forget']\n",
      "['water', 'mercredi', 'fort', 'find', 'food']\n",
      "['fort', 'whos', 'understand', 'taking', 'close', 'sms', 'mounn', 'please', 'food', 'water', 'french', 'problem', 'hurt', 'guess', 'creole', 'mix', 'mercredi', 'help', 'low', 'running']\n",
      "['water', 'treated', 'wednesday', 'mercredi', 'fort', 'find', 'tents']\n",
      "['whos', 'water', 'mercredi', 'fort', 'food', 'please']\n",
      "['hospital', 'looks', 'michely', 'cut', 'medicine', 'wounded']\n",
      "['dantes', 'martissant']\n",
      "['digicel', 'emergency']\n",
      "['capital', 'find', 'please', 'bank']\n",
      "['nearest', 'plaine', 'sac', 'food', 'distribution']\n",
      "['unable', 'close', 'leogane', 'listening', 'doctors', 'move', 'dabon', 'need', 'help', 'gas', 'radio']\n",
      "['water', 'presidential', 'need', 'finding', 'stuck', 'names', 'pal', 'says', 'quake', 'saying']\n",
      "['wife', 'moya', 'pregnant', 'blocks', 'found', 'walk', 'live', 'help', 'anyone', 'plaine', 'called', 'falling', 'injured']\n",
      "['grango', 'duvivier', 'member', 'fond', 'repatriated']\n",
      "['urgent', 'sms', 'action', 'needed', 'delivery', 'matter', 'follow', 'baby', 'possible', 'deliver']\n",
      "['airtime', 'add', 'phone', 'please']\n",
      "['water', 'temporary', 'need', 'frere', 'supplies', 'plaine', 'shelter', 'boukan', 'dire', 'food']\n",
      "['damaged', 'port', 'costs', 'find', 'gas', 'money', 'motocycle']\n",
      "['pap', 'provinces', 'badly', 'woul', 'available', 'hit', 'aide']\n",
      "['factory', 'sogebank', 'airport', 'please', 'documents', 'left', 'nearby', 'help', 'starting', 'houses', 'fire', 'several', 'burn']\n",
      "['verettes', 'morning', 'speak', 'victims', 'fonds', 'radio']\n",
      "['representatives', 'post', 'contact', 'assistance', 'station', 'radio']\n",
      "['alive', 'announcers', 'radio']\n",
      "['tomorrow', 'expected', 'rain', 'cold', 'haiti', 'morning', 'front', 'isolated', 'cuba', 'showers']\n",
      "['help', 'victims']\n",
      "['water', 'money', 'nothing', 'petion']\n",
      "['port', 'titanyen']\n",
      "['police', 'found', 'rescue', 'group', 'kid', 'anne', 'please']\n",
      "['route', 'bloqu', 'etienne', 'jacmel', 'rendre', 'dans', 'trsdifficile', 'est']\n",
      "['freres', 'route', 'vivi', 'robbed', 'currently', 'hungry', 'streets', 'mitchell']\n",
      "['need', 'gravel', 'vob', 'hungry', 'food', 'please']\n",
      "['today', 'water']\n",
      "['desprez', 'muguet', 'route', 'airport']\n",
      "['sleeping', 'pleine', 'live', 'killing', 'hunger']\n",
      "['sleeping', 'destroyed', 'house', 'live', 'dying', 'help', 'anymore', 'plaine', 'thirst', 'streets', 'coming', 'hunger']\n",
      "['marin', 'carrefour', 'lapleine', 'precise']\n",
      "['perpetuel', 'firefighters', 'church', 'fire', 'secours', 'please']\n",
      "['everything', 'anse', 'inside', 'pitree', 'destroyed', 'went', 'delmas', 'house', 'nothing', 'help', 'absolutely', 'hometown']\n",
      "['lilovois', 'need', 'monarque', 'medicine', 'food']\n",
      "['tent', 'shelters', 'safety', 'place', 'house', 'thief', 'available', 'spaces', 'want', 'front', 'station', 'reason']\n",
      "['water', 'distributing', 'need', 'everywhere', 'food']\n",
      "['galet', 'tabarre', 'embassy', 'american', 'hungry']\n",
      "['association', 'youth', 'nameajeans', 'action', 'society', 'september', 'commitee', 'president', 'founded']\n",
      "['asking', 'police', 'jacmel', 'criminals']\n",
      "['dying', 'hunger', 'petion']\n",
      "['akay', 'name', 'kafou', 'lachomy', 'kabar', 'miles', 'toman', 'exactly']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['american', 'tomorrow', 'embassy', 'open']\n",
      "['firm', 'south', 'architects', 'african', 'wondering', 'construction', 'stockholders', 'needs', 'civilians', 'moment', 'recruited']\n",
      "['done', 'underneath', 'jacmel', 'rubbles', 'trapped', 'help', 'college', 'latriniti']\n",
      "['enter', 'electricity', 'houses']\n",
      "['kinds', 'vile', 'ona', 'route', 'bon', 'repos', 'need', 'help', 'really']\n",
      "['muguet', 'please', 'petion']\n",
      "['else', 'services', 'call', 'information', 'need', 'help', 'translators', 'distributors', 'food', 'beeing', 'write', 'please']\n",
      "['political', 'hinche', 'true', 'held']\n",
      "['french', 'creole', 'need', 'half', 'speak', 'field', 'english']\n",
      "['financed', 'unrecognized', 'bid', 'initial', 'truncated', 'accelerated', 'launched', 'characterse', 'menfp', 'organized', 'formation']\n",
      "['truncated', 'continues', 'education', 'regarding']\n",
      "['desperately', 'help', 'needs', 'humiliated', 'bizoton']\n",
      "['car', 'leave', 'find']\n",
      "['water', 'without', 'delmas', 'something', 'live', 'finished', 'morning', 'food', 'please']\n",
      "['need', 'feuille', 'help', 'carrefour', 'extended', 'waiting']\n",
      "['electricity', 'help', 'haiti', 'carrefour', 'edh', 'please']\n",
      "['everyone', 'water', 'forget', 'merger', 'rains', 'die', 'hungry']\n",
      "['family', 'problem', 'help', 'digicel', 'call', 'please']\n",
      "['humanitarian', 'course', 'delmas', 'survive', 'aid', 'musso', 'golf', 'please']\n",
      "['water', 'evening', 'dying', 'help', 'pleas', 'carrefour', 'ther', 'feuill', 'hunger']\n",
      "['water', 'delmas', 'kiskeya', 'university', 'respond', 'need', 'pleas', 'delams', 'food', 'stay']\n",
      "['travel', 'visa']\n",
      "['ath', 'arrived', 'ranboto', 'looked', 'alot', 'desalin', 'hospital', 'specialist', 'supplys', 'surgeons', 'victimes', 'nan', 'marchand', 'enough']\n",
      "['help', 'orchidee', 'delmas', 'thirsty']\n",
      "['haitian', 'came', 'haitien', 'port', 'eat', 'want', 'cap', 'food', 'north']\n",
      "['save', 'came', 'marc', 'lives']\n",
      "['please', 'talk', 'earthquake']\n",
      "['international', 'port', 'goverment', 'thak', 'need', 'haiti', 'aid', 'food']\n",
      "['international', 'port', 'goverment', 'thak', 'need', 'haiti', 'aid', 'food']\n",
      "['pap', 'condition', 'alot', 'recieved', 'help', 'artibonit', 'pleas', 'serious', 'victimes', 'different', 'liancourt']\n",
      "['close', 'water', 'bary', 'route', 'live', 'vencent', 'need', 'national', 'carrefour', 'plaine', 'tents', 'food']\n",
      "['abitation', 'riviere', 'leogane', 'grand', 'communal', 'mathieu', 'waiting']\n",
      "['unrecognized', 'hill', 'water', 'fontamara', 'characters', 'label', 'carrefour', 'tents', 'medicine', 'assistance', 'top', 'food']\n",
      "['hospital', 'departments', 'medicine', 'counties', 'distributed']\n",
      "['asking', 'sent', 'tranfer', 'open', 'offices', 'money']\n",
      "['truncated', 'water', 'cator', 'nazon', 'need', 'sylvio', 'food', 'please']\n",
      "['everyone', 'wife', 'starve', 'countries', 'miami', 'listening', 'kids', 'help', 'haiti', 'morning', 'helping', 'death', 'please']\n",
      "['water', 'destroyed', 'delmas', 'house', 'clothes', 'need', 'food']\n",
      "['afternoon', 'sense', 'nobody', 'something', 'thinking', 'bon', 'group', 'word', 'help', 'need', 'bye', 'loubens', 'please', 'repo']\n",
      "['suffering', 'something', 'stuff', 'help', 'malgro', 'fight', 'thirsty', 'gave', 'hungry', 'primati', 'please']\n",
      "['falaise', 'everyone', 'zones', 'laptops', 'internet', 'croix', 'des', 'open', 'wireless', 'important', 'bouquets']\n",
      "['group', 'solidarite', 'rubles']\n",
      "['delmas', 'water', 'problem']\n",
      "['phone', 'minutes']\n",
      "['conditions', 'cayes', 'life', 'les', 'leave', 'guerrier', 'bad', 'port', 'lycee', 'odor', 'please', 'philippe', 'need', 'help', 'capital']\n",
      "['smell', 'bad', 'yard', 'woolio', 'warning', 'house', 'church', 'watch', 'coming', 'lingering', 'nway', 'foul']\n",
      "['problems', 'place', 'port', 'live', 'help', 'louis']\n",
      "['wounded', 'badly', 'eat']\n",
      "['water', 'visit', 'delmas', 'noone', 'need', 'food']\n",
      "['delmas', 'yard', 'need', 'help', 'goldstar', 'painson']\n",
      "['rabel', 'everything', 'port', 'nothing', 'lost', 'eat', 'jean', 'please']\n",
      "['haitian', 'problems', 'hospital', 'help', 'anymore', 'cap', 'please']\n",
      "['delmas', 'rescuing', 'need', 'help', 'university', 'caraibean', 'rubble']\n",
      "['humanitarian', 'badly', 'lwes', 'hit', 'need', 'aid', 'please']\n",
      "['fou', 'homeless', 'evening', 'taifer', 'carrefour', 'municipality', 'morin', 'assist', 'victims', 'please', 'quickly']\n",
      "['haitian', 'problems', 'housing', 'lack', 'cap', 'medication', 'food']\n",
      "['haitian', 'asking', 'agents', 'united', 'states', 'cap', 'money']\n",
      "['rabel', 'sister', 'port', 'dont', 'jan', 'brother', 'something', 'anyone', 'population']\n",
      "['months', 'anse', 'pregnant', 'deliverance', 'whatever', 'jeremie', 'died', 'grand', 'boyfriend', 'money']\n",
      "['silo', 'delmas', 'head', 'hit', 'help', 'please']\n",
      "['water', 'rain', 'leogane', 'need', 'shelter', 'mathieu', 'food']\n",
      "['water', 'support', 'organization', 'need', 'hungry', 'food']\n",
      "['water', 'relief', 'need', 'help', 'morning', 'called', 'emergency', 'food', 'please', 'gabyon']\n",
      "['haitian', 'family', 'remains', 'port', 'pay', 'house', 'parts', 'something', 'lost', 'alive', 'husband', 'still', 'making', 'usa', 'crushed', 'work', 'thereas']\n",
      "['tortue', 'evening', 'clothes', 'mind', 'hope', 'keep', 'island', 'coming', 'food', 'wounded']\n",
      "['driving', 'haitian', 'port', 'hrs', 'survive', 'margot', 'dying', 'anything', 'help', 'cap', 'please']\n",
      "process time:0 seconds\n"
     ]
    }
   ],
   "source": [
    "b_start = time()\n",
    "\n",
    "i = 0\n",
    "for message in X:\n",
    "    out = udacourse2.fn_tokenize_fast(message, \n",
    "                                      verbose=True)\n",
    "    i += 1\n",
    "    if i > 200: #it´s only for test, you can adjust it!\n",
    "        break\n",
    "\n",
    "b_spent = time() - b_start\n",
    "print('process time:{:.0f} seconds'.format(b_spent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather update - a cold front from Cuba that could pass over Haiti\n",
      "###Tokenizer function started\n",
      "process time:0.0150 seconds\n",
      "Tokens-start:66, token/stop:8, remove cities:6 &noise:6\n",
      " +lemmatizer:6\n",
      " +eliminate short:6\n",
      " +eliminate noisy from 300:6\n",
      "['could', 'update', 'pas', 'weather', 'cold', 'front']\n",
      "\n",
      "Is the Hurricane over or is it not over\n",
      "###Tokenizer function started\n",
      "process time:0.0135 seconds\n",
      "Tokens-start:39, token/stop:1, remove cities:1 &noise:1\n",
      " +lemmatizer:1\n",
      " +eliminate short:1\n",
      " +eliminate noisy from 300:1\n",
      "['hurricane']\n",
      "\n",
      "Looking for someone but no name\n",
      "###Tokenizer function started\n",
      "process time:0.0120 seconds\n",
      "Tokens-start:31, token/stop:3, remove cities:3 &noise:2\n",
      " +lemmatizer:2\n",
      " +eliminate short:2\n",
      " +eliminate noisy from 300:2\n",
      "['name', 'looking']\n",
      "\n",
      "UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.\n",
      "###Tokenizer function started\n",
      "process time:0.0135 seconds\n",
      "Tokens-start:100, token/stop:11, remove cities:11 &noise:10\n",
      " +lemmatizer:10\n",
      " +eliminate short:8\n",
      " +eliminate noisy from 300:6\n",
      "['desperately', 'destroyed', 'hospital', 'leogane', 'supply', 'functioning']\n",
      "\n",
      "says: west side of Haiti, rest of the country today and tonight\n",
      "###Tokenizer function started\n",
      "process time:0.0125 seconds\n",
      "Tokens-start:63, token/stop:8, remove cities:7 &noise:6\n",
      " +lemmatizer:6\n",
      " +eliminate short:6\n",
      " +eliminate noisy from 300:5\n",
      "['today', 'say', 'tonight', 'side', 'rest']\n",
      "\n",
      "Information about the National Palace-\n",
      "###Tokenizer function started\n",
      "process time:0.0140 seconds\n",
      "Tokens-start:38, token/stop:3, remove cities:3 &noise:2\n",
      " +lemmatizer:2\n",
      " +eliminate short:2\n",
      " +eliminate noisy from 300:1\n",
      "['national']\n",
      "\n",
      "Storm at sacred heart of jesus\n",
      "###Tokenizer function started\n",
      "process time:0.0130 seconds\n",
      "Tokens-start:30, token/stop:4, remove cities:4 &noise:1\n",
      " +lemmatizer:1\n",
      " +eliminate short:1\n",
      " +eliminate noisy from 300:1\n",
      "['storm']\n",
      "\n",
      "Please, we need tents and water. We are in Silo, Thank you!\n",
      "###Tokenizer function started\n",
      "process time:0.0130 seconds\n",
      "Tokens-start:59, token/stop:6, remove cities:6 &noise:4\n",
      " +lemmatizer:4\n",
      " +eliminate short:4\n",
      " +eliminate noisy from 300:3\n",
      "['silo', 'water', 'tent']\n",
      "\n",
      "I would like to receive the messages, thank you\n",
      "###Tokenizer function started\n",
      "process time:0.0145 seconds\n",
      "Tokens-start:47, token/stop:5, remove cities:5 &noise:2\n",
      " +lemmatizer:2\n",
      " +eliminate short:2\n",
      " +eliminate noisy from 300:1\n",
      "['receive']\n",
      "\n",
      "I am in Croix-des-Bouquets. We have health issues. They ( workers ) are in Santo 15. ( an area in Croix-des-Bouquets )\n",
      "###Tokenizer function started\n",
      "process time:0.0130 seconds\n",
      "Tokens-start:118, token/stop:11, remove cities:11 &noise:7\n",
      " +lemmatizer:7\n",
      " +eliminate short:4\n",
      " +eliminate noisy from 300:4\n",
      "['health', 'bouquet', 'worker', 'issue']\n",
      "\n",
      "There's nothing to eat and water, we starving and thirsty.\n",
      "###Tokenizer function started\n",
      "process time:0.0120 seconds\n",
      "Tokens-start:58, token/stop:5, remove cities:5 &noise:5\n",
      " +lemmatizer:5\n",
      " +eliminate short:5\n",
      " +eliminate noisy from 300:5\n",
      "['water', 'starving', 'nothing', 'eat', 'thirsty']\n",
      "\n",
      "I am in Petionville. I need more information regarding 4636\n",
      "###Tokenizer function started\n",
      "process time:0.0135 seconds\n",
      "Tokens-start:59, token/stop:4, remove cities:4 &noise:4\n",
      " +lemmatizer:4\n",
      " +eliminate short:4\n",
      " +eliminate noisy from 300:2\n",
      "['petionville', 'regarding']\n",
      "\n",
      "I am in Thomassin number 32, in the area named Pyron. I would like to have some water. Thank God we are fine, but we desperately need water. Thanks\n",
      "###Tokenizer function started\n",
      "process time:0.0165 seconds\n",
      "Tokens-start:147, token/stop:15, remove cities:15 &noise:6\n",
      " +lemmatizer:6\n",
      " +eliminate short:5\n",
      " +eliminate noisy from 300:4\n",
      "['water', 'thomassin', 'desperately', 'pyron']\n",
      "\n",
      "Let's do it together, need food in Delma 75, in didine area\n",
      "###Tokenizer function started\n",
      "process time:0.0130 seconds\n",
      "Tokens-start:59, token/stop:7, remove cities:7 &noise:5\n",
      " +lemmatizer:5\n",
      " +eliminate short:5\n",
      " +eliminate noisy from 300:4\n",
      "['delma', 'didine', 'together', 'food']\n",
      "\n",
      "More information on the 4636 number in order for me to participate. ( To see if I can use it )\n",
      "###Tokenizer function started\n",
      "process time:0.0135 seconds\n",
      "Tokens-start:94, token/stop:6, remove cities:6 &noise:5\n",
      " +lemmatizer:5\n",
      " +eliminate short:5\n",
      " +eliminate noisy from 300:3\n",
      "['use', 'order', 'participate']\n",
      "\n",
      "A Comitee in Delmas 19, Rue ( street ) Janvier, Impasse Charite #2. We have about 500 people in a temporary shelter and we are in dire need of Water, Food, Medications, Tents and Clothes. Please stop by and see us.\n",
      "###Tokenizer function started\n",
      "process time:0.0140 seconds\n",
      "Tokens-start:214, token/stop:21, remove cities:21 &noise:16\n",
      " +lemmatizer:16\n",
      " +eliminate short:15\n",
      " +eliminate noisy from 300:11\n",
      "['tent', 'water', 'temporary', 'impasse', 'clothes', 'charite', 'medication', 'comitee', 'shelter', 'dire', 'food']\n",
      "\n",
      "We need food and water in Klecin 12. We are dying of hunger. Impasse Chretien Klecin 12 extended ( extension ) We are hungry and sick.\n",
      "###Tokenizer function started\n",
      "process time:0.0120 seconds\n",
      "Tokens-start:134, token/stop:13, remove cities:13 &noise:13\n",
      " +lemmatizer:13\n",
      " +eliminate short:12\n",
      " +eliminate noisy from 300:11\n",
      "['water', 'chretien', 'extension', 'impasse', 'dying', 'klecin', 'extended', 'hungry', 'sick', 'food', 'hunger']\n",
      "\n",
      "are you going to call me or do you want me to call ou? let me know?\n",
      "###Tokenizer function started\n",
      "process time:0.0125 seconds\n",
      "Tokens-start:67, token/stop:7, remove cities:7 &noise:3\n",
      " +lemmatizer:3\n",
      " +eliminate short:1\n",
      " +eliminate noisy from 300:0\n",
      "[]\n",
      "\n",
      "I don't understand how to use this thing 4636.\n",
      "###Tokenizer function started\n",
      "process time:0.0279 seconds\n",
      "Tokens-start:46, token/stop:3, remove cities:3 &noise:2\n",
      " +lemmatizer:2\n",
      " +eliminate short:2\n",
      " +eliminate noisy from 300:2\n",
      "['understand', 'use']\n",
      "\n",
      "I would like to know if the earthquake is over. Thanks\n",
      "###Tokenizer function started\n",
      "process time:0.0125 seconds\n",
      "Tokens-start:54, token/stop:5, remove cities:5 &noise:1\n",
      " +lemmatizer:1\n",
      " +eliminate short:1\n",
      " +eliminate noisy from 300:1\n",
      "['earthquake']\n",
      "\n",
      "I would like to know if one of the radio ginen Journalist died?\n",
      "###Tokenizer function started\n",
      "process time:0.0130 seconds\n",
      "Tokens-start:63, token/stop:8, remove cities:8 &noise:5\n",
      " +lemmatizer:5\n",
      " +eliminate short:5\n",
      " +eliminate noisy from 300:4\n",
      "['ginen', 'died', 'journalist', 'radio']\n",
      "\n",
      "process time:0.3124 seconds\n"
     ]
    }
   ],
   "source": [
    "b_start = time()\n",
    "\n",
    "i = 0\n",
    "for message in X:\n",
    "    print(message)\n",
    "    out = udacourse2.fn_tokenize(message, \n",
    "                                 lemmatize=True, \n",
    "                                 rem_city=True, \n",
    "                                 agg_words=True,\n",
    "                                 rem_noise=True,\n",
    "                                 elm_short=3,\n",
    "                                 great_noisy=True,\n",
    "                                 verbose=True)\n",
    "    print(out)\n",
    "    print()\n",
    "    i += 1\n",
    "    if i > 20: #it´s only for test, you can adjust it!\n",
    "        break\n",
    "\n",
    "b_spent = time() - b_start\n",
    "print('process time:{:.4f} seconds'.format(b_spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don´t try it! (complete tokenizer)\n",
    "\n",
    "- it´s a slow test! (takes like 221 seconds to tokenize all the dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b_start = time()\n",
    "\n",
    "#X_tokens = X.apply(lambda x: udacourse2.fn_tokenize(x, \n",
    "#                                                    lemmatize=True, \n",
    "#                                                    rem_city=True, \n",
    "#                                                    agg_words=True,\n",
    "#                                                    rem_noise=True,\n",
    "#                                                    elm_short=3,\n",
    "#                                                    great_noisy=True,\n",
    "#                                                    verbose=False))\n",
    "\n",
    "#b_spent = time() - b_start\n",
    "#print('process time:{:.0f} seconds'.format(b_spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it´s a bit faster test (it takes 46 seconds to run)\n",
    "\n",
    "- the secret is that it loops only one time for row, as it condenses all the filters into one loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time:55 seconds\n"
     ]
    }
   ],
   "source": [
    "b_start = time()\n",
    "\n",
    "X_tokens = X.apply(lambda x: udacourse2.fn_tokenize_fast(x, \n",
    "                                                         verbose=False))\n",
    "\n",
    "b_spent = time() - b_start\n",
    "print('process time:{:.0f} seconds'.format(b_spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have a **series** with all my tokenized messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [update, pass, weather, cold, haiti, front, cuba]\n",
       "1                                          [hurricane]\n",
       "2                                      [name, looking]\n",
       "3    [desperately, destroyed, hospital, leogane, cr...\n",
       "4            [today, tonight, side, haiti, rest, says]\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokens.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I can filter it for rows that have an **empty list**:\n",
    "    \n",
    "- solution found [here](https://stackoverflow.com/questions/29100380/remove-empty-lists-in-pandas-series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2522     []\n",
       "2678     []\n",
       "4487     []\n",
       "5347     []\n",
       "5709     []\n",
       "5737     []\n",
       "6152     []\n",
       "6153     []\n",
       "6229     []\n",
       "7190     []\n",
       "7266     []\n",
       "7559     []\n",
       "7751     []\n",
       "7807     []\n",
       "8891     []\n",
       "8901     []\n",
       "9650     []\n",
       "9863     []\n",
       "12221    []\n",
       "12225    []\n",
       "12258    []\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokens[X_tokens.str.len() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [update, pass, weather, cold, haiti, front, cuba]\n",
       "1                                              [hurricane]\n",
       "2                                          [name, looking]\n",
       "3        [desperately, destroyed, hospital, leogane, cr...\n",
       "4                [today, tonight, side, haiti, rest, says]\n",
       "                               ...                        \n",
       "26240    [rice, locally, meals, fish, demonstrated, ene...\n",
       "26241    [candidate, contract, month, starting, jakarta...\n",
       "26242    [chokoria, rice, assessment, lentils, operatin...\n",
       "26243    [women, elections, harcourt, port, conduct, co...\n",
       "26244    [recognizing, radical, humanitarian, came, cri...\n",
       "Name: message, Length: 26224, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser2 = X_tokens[X_tokens.str.len() > 0]\n",
    "ser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time:0 seconds\n"
     ]
    }
   ],
   "source": [
    "b_start = time()\n",
    "\n",
    "dic_tokens = udacourse2.fn_subcount_lists(column=X_tokens, \n",
    "                                          verbose=False)\n",
    "\n",
    "b_spent = time() - b_start\n",
    "print('process time:{:.0f} seconds'.format(b_spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorted dictionnary [here](https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data processed\n"
     ]
    }
   ],
   "source": [
    "dic_tokens\n",
    "\n",
    "d_tokens = dic_tokens['elements']\n",
    "t_sorted = sorted(d_tokens.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "if t_sorted:\n",
    "    print('data processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorted list of tuples of most counted tokens:\n",
    "\n",
    "- filtering the more counted 300 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('food', 2528),\n",
       " ('water', 2413),\n",
       " ('help', 2344),\n",
       " ('need', 2003),\n",
       " ('please', 1901),\n",
       " ('earthquake', 1705),\n",
       " ('government', 930),\n",
       " ('haiti', 926),\n",
       " ('areas', 913),\n",
       " ('find', 873),\n",
       " ('information', 842),\n",
       " ('relief', 745),\n",
       " ('aid', 726),\n",
       " ('affected', 705),\n",
       " ('sandy', 702),\n",
       " ('health', 644),\n",
       " ('children', 591),\n",
       " ('work', 561),\n",
       " ('tents', 532),\n",
       " ('emergency', 531),\n",
       " ('give', 521),\n",
       " ('flood', 513),\n",
       " ('want', 510),\n",
       " ('supplies', 508),\n",
       " ('last', 500),\n",
       " ('international', 494),\n",
       " ('house', 488),\n",
       " ('power', 477),\n",
       " ('still', 471),\n",
       " ('rain', 467),\n",
       " ('million', 467),\n",
       " ('hit', 454),\n",
       " ('rains', 454),\n",
       " ('support', 444),\n",
       " ('santiago', 441),\n",
       " ('school', 432),\n",
       " ('disaster', 429),\n",
       " ('heavy', 429),\n",
       " ('assistance', 425),\n",
       " ('victims', 420),\n",
       " ('hurricane', 419),\n",
       " ('shelter', 419),\n",
       " ('family', 414),\n",
       " ('storm', 412),\n",
       " ('live', 412),\n",
       " ('destroyed', 410),\n",
       " ('floods', 396),\n",
       " ('families', 393),\n",
       " ('south', 389),\n",
       " ('medical', 384),\n",
       " ('houses', 383),\n",
       " ('national', 379),\n",
       " ('port', 377),\n",
       " ('united', 376),\n",
       " ('years', 376),\n",
       " ('north', 374),\n",
       " ('days', 364),\n",
       " ('living', 363),\n",
       " ('high', 362),\n",
       " ('job', 360),\n",
       " ('anything', 349),\n",
       " ('first', 349),\n",
       " ('notes', 347),\n",
       " ('homes', 341),\n",
       " ('provide', 338),\n",
       " ('community', 334),\n",
       " ('quake', 328),\n",
       " ('weather', 325),\n",
       " ('flooding', 324),\n",
       " ('needs', 323),\n",
       " ('care', 314),\n",
       " ('working', 313),\n",
       " ('reported', 312),\n",
       " ('conditions', 311),\n",
       " ('pakistan', 310),\n",
       " ('villages', 309),\n",
       " ('river', 309),\n",
       " ('situation', 307),\n",
       " ('caused', 307),\n",
       " ('left', 305),\n",
       " ('red', 304),\n",
       " ('thousands', 302),\n",
       " ('humanitarian', 300),\n",
       " ('tsunami', 300),\n",
       " ('today', 299),\n",
       " ('team', 299),\n",
       " ('distribution', 298),\n",
       " ('tent', 298),\n",
       " ('received', 295),\n",
       " ('efforts', 291),\n",
       " ('hospital', 284),\n",
       " ('important', 281),\n",
       " ('countries', 280),\n",
       " ('security', 280),\n",
       " ('damaged', 279),\n",
       " ('place', 279),\n",
       " ('morning', 277),\n",
       " ('lost', 277),\n",
       " ('nations', 277),\n",
       " ('drought', 277),\n",
       " ('women', 274),\n",
       " ('major', 272),\n",
       " ('several', 271),\n",
       " ('development', 269),\n",
       " ('damage', 268),\n",
       " ('authorities', 267),\n",
       " ('call', 266),\n",
       " ('provided', 266),\n",
       " ('without', 266),\n",
       " ('central', 265),\n",
       " ('home', 263),\n",
       " ('news', 263),\n",
       " ('disease', 263),\n",
       " ('killed', 261),\n",
       " ('rice', 260),\n",
       " ('crops', 260),\n",
       " ('roads', 258),\n",
       " ('nothing', 256),\n",
       " ('use', 255),\n",
       " ('system', 254),\n",
       " ('officials', 251),\n",
       " ('chile', 250),\n",
       " ('population', 248),\n",
       " ('needed', 244),\n",
       " ('following', 243),\n",
       " ('blankets', 241),\n",
       " ('military', 241),\n",
       " ('public', 236),\n",
       " ('season', 235),\n",
       " ('severe', 235),\n",
       " ('providing', 234),\n",
       " ('tell', 232),\n",
       " ('life', 231),\n",
       " ('parts', 231),\n",
       " ('hygiene', 231),\n",
       " ('land', 230),\n",
       " ('winter', 230),\n",
       " ('risk', 229),\n",
       " ('capital', 228),\n",
       " ('drinking', 228),\n",
       " ('communities', 228),\n",
       " ('workers', 227),\n",
       " ('rescue', 226),\n",
       " ('open', 224),\n",
       " ('diseases', 224),\n",
       " ('china', 224),\n",
       " ('districts', 223),\n",
       " ('away', 222),\n",
       " ('coming', 222),\n",
       " ('cyclone', 222),\n",
       " ('continue', 221),\n",
       " ('evening', 220),\n",
       " ('large', 219),\n",
       " ('residents', 219),\n",
       " ('dead', 216),\n",
       " ('project', 216),\n",
       " ('died', 215),\n",
       " ('rainfall', 215),\n",
       " ('supply', 213),\n",
       " ('night', 213),\n",
       " ('possible', 213),\n",
       " ('early', 213),\n",
       " ('facilities', 212),\n",
       " ('month', 211),\n",
       " ('hunger', 210),\n",
       " ('found', 210),\n",
       " ('electricity', 210),\n",
       " ('problems', 210),\n",
       " ('services', 209),\n",
       " ('equipment', 207),\n",
       " ('crop', 206),\n",
       " ('recent', 205),\n",
       " ('africa', 205),\n",
       " ('systems', 205),\n",
       " ('sanitation', 204),\n",
       " ('island', 203),\n",
       " ('schools', 203),\n",
       " ('expected', 202),\n",
       " ('building', 202),\n",
       " ('farmers', 202),\n",
       " ('items', 201),\n",
       " ('states', 200),\n",
       " ('sent', 199),\n",
       " ('card', 199),\n",
       " ('months', 198),\n",
       " ('production', 198),\n",
       " ('temporary', 197),\n",
       " ('money', 197),\n",
       " ('hungry', 196),\n",
       " ('human', 195),\n",
       " ('problem', 194),\n",
       " ('carrefour', 192),\n",
       " ('asking', 192),\n",
       " ('ask', 192),\n",
       " ('group', 191),\n",
       " ('bring', 191),\n",
       " ('access', 191),\n",
       " ('camps', 191),\n",
       " ('reports', 190),\n",
       " ('survivors', 190),\n",
       " ('ground', 190),\n",
       " ('provinces', 189),\n",
       " ('sleep', 189),\n",
       " ('displaced', 188),\n",
       " ('receive', 187),\n",
       " ('safe', 187),\n",
       " ('delmas', 186),\n",
       " ('answer', 186),\n",
       " ('unicef', 186),\n",
       " ('eat', 185),\n",
       " ('programme', 185),\n",
       " ('coast', 183),\n",
       " ('afghanistan', 183),\n",
       " ('sleeping', 181),\n",
       " ('office', 181),\n",
       " ('cold', 180),\n",
       " ('police', 180),\n",
       " ('clean', 180),\n",
       " ('groups', 179),\n",
       " ('activities', 178),\n",
       " ('poor', 175),\n",
       " ('worst', 175),\n",
       " ('hundreds', 175),\n",
       " ('something', 174),\n",
       " ('organization', 174),\n",
       " ('clothing', 174),\n",
       " ('result', 174),\n",
       " ('buildings', 174),\n",
       " ('include', 173),\n",
       " ('available', 172),\n",
       " ('kits', 172),\n",
       " ('waiting', 171),\n",
       " ('addition', 171),\n",
       " ('control', 171),\n",
       " ('agricultural', 171),\n",
       " ('able', 170),\n",
       " ('india', 170),\n",
       " ('operations', 170),\n",
       " ('phone', 169),\n",
       " ('air', 169),\n",
       " ('agency', 168),\n",
       " ('shelters', 167),\n",
       " ('weeks', 167),\n",
       " ('camp', 166),\n",
       " ('based', 166),\n",
       " ('snow', 166),\n",
       " ('center', 165),\n",
       " ('program', 165),\n",
       " ('march', 165),\n",
       " ('political', 164),\n",
       " ('per', 164),\n",
       " ('death', 163),\n",
       " ('lives', 163),\n",
       " ('staff', 163),\n",
       " ('refugees', 163),\n",
       " ('agriculture', 163),\n",
       " ('report', 163),\n",
       " ('distributed', 162),\n",
       " ('natural', 162),\n",
       " ('october', 162),\n",
       " ('monsoon', 162),\n",
       " ('baby', 161),\n",
       " ('cause', 161),\n",
       " ('members', 161),\n",
       " ('training', 161),\n",
       " ('cases', 161),\n",
       " ('president', 159),\n",
       " ('regions', 159),\n",
       " ('clothes', 158),\n",
       " ('army', 158),\n",
       " ('far', 158),\n",
       " ('strong', 158),\n",
       " ('temperatures', 158),\n",
       " ('teams', 157),\n",
       " ('winds', 157),\n",
       " ('called', 155),\n",
       " ('infrastructure', 155),\n",
       " ('indonesia', 155),\n",
       " ('magnitude', 154),\n",
       " ('scale', 154),\n",
       " ('especially', 153),\n",
       " ('crisis', 153),\n",
       " ('resources', 153),\n",
       " ('levels', 153),\n",
       " ('order', 152),\n",
       " ('address', 152),\n",
       " ('minister', 152),\n",
       " ('massive', 152),\n",
       " ('says', 151),\n",
       " ('low', 151),\n",
       " ('fire', 150),\n",
       " ('treatment', 150),\n",
       " ('prevent', 150),\n",
       " ('agencies', 150),\n",
       " ('monday', 150),\n",
       " ('capacity', 150),\n",
       " ('increase', 150),\n",
       " ('coastal', 150),\n",
       " ('really', 148),\n",
       " ('love', 148)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sorted[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the **tokenize** function just to absorve less meaningful tokens to discard:\n",
    "    \n",
    "- **ver 1.2** created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "great_noisy = ['people', 'help', 'need', 'said', 'country', 'government', 'one', 'year', 'good', 'day',\n",
    "    'two', 'get', 'message', 'many', 'region', 'city', 'province', 'road', 'district', 'including', 'time',\n",
    "    'new', 'still', 'due', 'local', 'part', 'problem', 'may', 'take', 'come', 'effort', 'note', 'around',\n",
    "    'person', 'lot', 'already', 'situation', 'see', 'response', 'even', 'reported', 'caused', 'village', 'bit',\n",
    "    'made', 'way', 'across', 'west', 'never', 'southern', 'january', 'least', 'zone', 'small', 'next', 'little',\n",
    "    'four', 'must', 'non', 'used', 'five', 'wfp', 'however', 'com', 'set', 'every', 'think', 'item', 'yet', \n",
    "    'carrefour', 'asking', 'ask', 'site', 'line', 'put', 'unicef', 'got', 'east', 'june', 'got', 'ministry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Older atempt to clear tokens\n",
    "\n",
    "Tried to isolate some words that I think are noisy, for exclusion:\n",
    "    \n",
    "- general geographic references, as **area** and **village**;\n",
    "\n",
    "- social communication words, as **thanks** and **please**;\n",
    "\n",
    "- religious ways to talk, as **pray**\n",
    "\n",
    "- unmeaningful words, as **thing** and **like**\n",
    "\n",
    "- tokenize function **ver 1.1** created \n",
    "\n",
    "- visually filtered some words that I think don´t aggregate too much to the **Machine Learning**\n",
    "\n",
    "- just think about - you prefer your **IA** trained for 'thanks' or for 'hurricane'?\n",
    "\n",
    "- really I´m not 100% sure about these words, buy my **tokenize** function can enable and disable this list, and re-train the machine, and see if the performance increase or decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "unhelpful_words = ['thank', 'thanks', 'god', 'fine', 'number', 'area', 'let', 'stop', 'know', 'going', 'thing',\n",
    "    'would', 'hello', 'say', 'neither', 'right', 'asap', 'near', 'want', 'also', 'like', 'since', 'grace', \n",
    "    'congratulate', 'situated', 'tell', 'almost', 'hyme', 'sainte', 'croix', 'ville', 'street', 'valley', 'section',\n",
    "    'carnaval', 'rap', 'cry', 'location', 'ples', 'bless', 'entire', 'specially',  'sorry', 'saint', 'village', \n",
    "    'located', 'palace', 'might', 'given']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing **elliminate duplicates**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addon', 'place']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ['addon', 'place', 'addon']\n",
    "test = list(set(test))\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing **elliminate short words**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elliminate: l\n",
      "elliminate: us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['addon', 'place']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min = 3\n",
    "list2 = []\n",
    "test2 = ['addon', 'l', 'us', 'place']\n",
    "\n",
    "for word in test2:\n",
    "    if len(word) < min:\n",
    "        print('elliminate:', word)\n",
    "    else: \n",
    "        list2.append(word)\n",
    "    \n",
    "list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solution [here](https://stackoverflow.com/questions/3501382/checking-whether-a-variable-is-an-integer-or-not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "if isinstance(min, int):\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have two **Tokenizer** functions:\n",
    "\n",
    "- `fn_tokenize` $\\rightarrow$ it allows to test each individual methods, and contains all the methods described, but a bit slow, as it iterates all the words again for each method\n",
    "\n",
    "- `fn_tokenize_fast` $\\rightarrow$ it is a **boosted** version, with only one iteration, for running faster, but you cannot set each method individually for more accurate test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### A small review over each item for our first machine learning pipelines\n",
    "\n",
    "#### Feature Extraction\n",
    "\n",
    "Feature Extraction from SKlearn documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
    "\n",
    "*\"Convert a collection of text documents to a matrix of token counts\"*\n",
    "\n",
    "- we are looking for **tokens** that will be turned into **vectors** in a Machine Learning Model;\n",
    "\n",
    "- they are represented as **scalars** in a **matrix**, that indicates the scale of each one of these tokens.\n",
    "\n",
    "\"This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.\"\n",
    "\n",
    "- normally matrix representations of the natural reallity are a bit **sparse**\n",
    "\n",
    "- in this case, to save some memory, they indicate a use of a propper representation\n",
    "\n",
    "\"If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data.\"\n",
    "\n",
    "- me already made it, drastically reducing the **variability** of terms\n",
    "\n",
    "- it its represented by our **fn_tokenizer**\n",
    "\n",
    "#### Preprocessing\n",
    "\n",
    "TF-IDF from SKlearn documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)\n",
    "\n",
    "- **tf** is about **term frequency** and;\n",
    "\n",
    "- **idf** is about **inverse document frequency**.\n",
    "\n",
    "*\"Transform a count matrix to a normalized tf or tf-idf representation\"*\n",
    "\n",
    "- it means that it basically **normalizes** the count matrix\n",
    "\n",
    "*Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification.*\n",
    "\n",
    "- it takes term-frequency and it **rescales** it by the gereral document-frequency\n",
    "\n",
    "*The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus.*\n",
    "\n",
    "- the idea is to not weight too much a **noisy** and very frequent word\n",
    "\n",
    "- we tried to \"manually\" elliminate some of the **noisy** words, but as the number of tokens is too high, it´s quite impossible to make a good job\n",
    "\n",
    "#### Training a Machine Learning\n",
    "\n",
    "As we have **labels**, a good strategy is to use **supervised learning**\n",
    "\n",
    "- we could try to kind of make **clusters** of messages, using **unsupervised learning**, or try some strategy on **semi-supervised learning**, as we have some of the messages (40) that don´t have any classification;\n",
    "\n",
    "- the most obvious way is to train a **Classifier**;\n",
    "\n",
    "- as we have multiple labels, a **Multi Target Classifier** seems to be the better choice.\n",
    "\n",
    "Multi target classification [here](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html)\n",
    "\n",
    "*\"This strategy consists of fitting one classifier per target. This is a simple strategy for extending classifiers that do not natively support multi-target classification\"*\n",
    "\n",
    "- OK, we will be basically using **slices** of train for each feature, as we don´t have so much **Machines** that are natively supporting multi-target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Prepare the data\n",
    "\n",
    "Make the lasts opperations for preparing the dataset for training on **Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **training** data, it is a **data inconsistency** if you consider that all the labels are blank\n",
    "\n",
    "- so we have 6,317 rows that we need to **remove** before **training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all labels are blank in 6317 rows\n"
     ]
    }
   ],
   "source": [
    "print('all labels are blank in {} rows'.format(df[df['if_blank'] == 1].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19928"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['if_blank'] == 0]\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying if removal was complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removal complete!\n"
     ]
    }
   ],
   "source": [
    "if df[df['if_blank'] == 1].shape[0] == 0:\n",
    "    print('removal complete!')\n",
    "else:\n",
    "    raise Exception('something went wrong with rows removal before training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this **crazy thing** over here? \n",
    "\n",
    ">- I created a **provisory** column, and **tokenizing** it\n",
    ">- Why I need it for now? Just for removing rows that are **impossible to train**\n",
    ">- After tokenization, if I get a **empty list**, I need to remove this row before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "process time:48 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>if_blank</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>[update, pass, weather, cold, haiti, front, cuba]</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  Weather update - a cold front from Cuba that c...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [update, pass, weather, cold, haiti, front, cuba]   \n",
       "\n",
       "                                            original   genre  if_blank  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct         0   \n",
       "\n",
       "   related  request  offer  aid_related  medical_help  ...  aid_centers  \\\n",
       "0        1        0      0            0             0  ...            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "try:\n",
    "    df = df.drop('tokenized', axis=1)\n",
    "except KeyError:\n",
    "    print('OK')\n",
    "\n",
    "#inserting a provisory column\n",
    "df.insert(1, 'tokenized', np.nan)\n",
    "\n",
    "#tokenizing over the provisory\n",
    "df['tokenized'] = df.apply(lambda x: udacourse2.fn_tokenize_fast(x['message']), axis=1)\n",
    "\n",
    "#removing NaN over provisory (if istill exist)\n",
    "df = df[df['tokenized'].notnull()]\n",
    "\n",
    "spent = time() - start\n",
    "print('process time:{:.0f} seconds'.format(spent))\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering empy lists on `provisory`, found [here](https://stackoverflow.com/questions/42964724/pandas-filter-out-column-values-containing-empty-list)\n",
    "\n",
    "And another **crazy thing**, I regretted to remove `provisory` tokenized column:\n",
    "\n",
    ">- why? Just because I already **trained** my **X** subdataset, o I will not need to do it later!\n",
    ">- and if I make the thing **wizely**, I will accelerate the pipeline process, as I already made the hard job for the **CountVectorized**\n",
    ">- it will also faccilitate to **train** diverse Classifiers, as I save a lot of individual processing, making it **early** in my process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 6 rows with no tokens\n",
      "*after removal, found 0 rows with no tokens\n",
      "now I have 19922 rows to train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>if_blank</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[update, pass, weather, cold, haiti, front, cuba]</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tokenized  \\\n",
       "0  [update, pass, weather, cold, haiti, front, cuba]   \n",
       "\n",
       "                                            original   genre  if_blank  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct         0   \n",
       "\n",
       "   related  request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        1        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_tokens = df[df['tokenized'].apply(lambda x: len(x)) == 0].shape[0]\n",
    "print('found {} rows with no tokens'.format(empty_tokens))\n",
    "\n",
    "df = df[df['tokenized'].apply(lambda x: len(x)) > 0]\n",
    "empty_tokens = df[df['tokenized'].apply(lambda x: len(x)) == 0].shape[0]\n",
    "print('*after removal, found {} rows with no tokens'.format(empty_tokens))\n",
    "\n",
    "#I will not drop it anymore!\n",
    "#try:\n",
    "#    df = df.drop('provisory', axis=1)\n",
    "#except KeyError:\n",
    "#    print('OK')\n",
    "\n",
    "#Instead, I will drop 'message' column\n",
    "try:\n",
    "    df = df.drop('message', axis=1)\n",
    "except KeyError:\n",
    "    print('OK')\n",
    "\n",
    "print('now I have {} rows to train'.format(df.shape[0]))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Break the data\n",
    "\n",
    "Break the dataset into the **training columns** and **labels** (if it have **multilabels**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is the **Training Text Column**:\n",
    "    \n",
    "- if I observe the potential training data really well, I could `genre` column as training data too!\n",
    "\n",
    "- or I can use also `related`, `request`, `offer` columns for training `aid_related` data\n",
    "\n",
    "*A discussion of how much these **Label** columns are **hierarchically defined** is made laterly in this notebook*\n",
    "\n",
    "---\n",
    "\n",
    "For this moment, I am using only `message` as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [update, pass, weather, cold, haiti, front, cuba]\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['tokenized']\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y is constituted by the **Classification Labels**\n",
    "\n",
    "*Updated 1 - removed `related` column from the Labels dataset. Why? Because when I go to statistics, it turns allways at `1`. So It is causing problems when training our Classifier*\n",
    "\n",
    ">- was: `y = df[df.columns[4:]]`\n",
    ">- now: `y = df[df.columns[5:]]`\n",
    "\n",
    "*Updated 2 - removed columns that contains **only zeroes**. Why? Just because they are **impossible to train** on our Classifier!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*child_alone -> only zeroes training column!\n",
      "['child_alone']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  water  food  ...  aid_centers  \\\n",
       "0                  0         0         0      0     0  ...            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[df.columns[5:]]\n",
    "\n",
    "remove_lst = []\n",
    "\n",
    "for column in y.columns:\n",
    "    col = y[column]\n",
    "    if (col == 0).all():\n",
    "        print('*{} -> only zeroes training column!'.format(column))\n",
    "        remove_lst.append(column)\n",
    "    else:\n",
    "        #print('*{} -> column OK'.format(column))\n",
    "        pass\n",
    "print(remove_lst)\n",
    "\n",
    "y = y.drop(remove_lst, axis=1)\n",
    "\n",
    "y.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Split the data \n",
    "\n",
    "Into **Train** and **Test** subdatasets\n",
    "\n",
    "- let´s start it with **20%** of test data\n",
    "\n",
    "- I am not using **random_state** settings (and why **42**? I personally think it is about a reference to the book **The Hitchhicker´s Guide to de Galaxy**, from Douglas Adams!\n",
    "\n",
    "*Note update: now, I am using **random_state**, for ensuring the same results for each function call*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it looks OK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19922"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0] + X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Choose your first Classifier \n",
    "\n",
    "- and build a **Pipeline** for it\n",
    "\n",
    "Each Pipeline is a Python Object that can be called for **methods**, as **fit()**\n",
    "\n",
    "---\n",
    "\n",
    "What **Classifier** to choose?\n",
    "\n",
    "- **Towards Data Science** give us some tips [here](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)\n",
    "\n",
    "---\n",
    "\n",
    "Start with a **Naïve Bayes** (NB)\n",
    "\n",
    "`clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)`\n",
    "\n",
    "In a Pipeline way:\n",
    "\n",
    ">- i should use `CountVectorizer(tokenizer=udacourse2.fn_tokenize_fast)`, but I will **not**!\n",
    ">- why? Just because I already proceeded with **tokenization** in a earlier step\n",
    ">- so, how to overpass this hellish `tokenizer=...` parameter?\n",
    ">- I found a clever solution [here](https://stackoverflow.com/questions/35867484/pass-tokens-to-countvectorizer)\n",
    ">- so, I prepared a **dummy** function to overpass the tokenizer over **CountVertorizer**\n",
    "\n",
    "First I tried to set Classifier as **MultinomialNB()**, and it crashes:\n",
    "\n",
    ">- only **one** Label to be trained was expected, and there were 36 Labels!;\n",
    ">- reading the documentation for SKlearn, it turned clear that it is necessary (if your Classifier algorithm was not originally built for **multicriteria**, to run it **n** times, one for each label\n",
    ">- so it is necessary to include it our pipeline, using `MultiOutputClassifier()` transformer\n",
    "\n",
    "*And... it looks pretty **fast** to train, not? What is the secret? We are **bypassing** the tokenizer and preprecessor, as we **already made** it at the dataset!*\n",
    "\n",
    "*Another thing, we are not using the **whole** dataset... it´s just about a little **issue** we have, as there are a lot of **missing labels** at the dataset! And for me, it will **distort** our training! (lately I will compare the results with traning the **raw** dataset)*\n",
    "\n",
    "**Naïve Bayes** is known as a very **fast** method:\n",
    "\n",
    ">- but it is also known as being not so **accurate**\n",
    ">- and it have so **few** parameters for a later refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-97bc9fc63352>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m pipeline_mbnb = Pipeline([('vect', CountVectorizer(tokenizer=dummy, preprocessor=dummy)),\n\u001b[0;32m      8\u001b[0m                           \u001b[1;33m(\u001b[0m\u001b[1;34m'tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                           ('clf',  MultiOutputClassifier(MultinomialNB(random_state=42)))])\n\u001b[0m\u001b[0;32m     10\u001b[0m                           \u001b[1;31m#('clf', MultinomialNB())]) #<-my terrible mistake!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m#remembering:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'random_state'"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "#Naïve Bayes classifier pipeline\n",
    "pipeline_mbnb = Pipeline([('vect', CountVectorizer(tokenizer=dummy, preprocessor=dummy)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf',  MultiOutputClassifier(MultinomialNB()))])\n",
    "                          #('clf', MultinomialNB())]) #<-my terrible mistake!\n",
    "#remembering:\n",
    "#CountVectorizer -> makes the count for tokenized vectors\n",
    "#TfidTransformer -> makes the weight \"normalization\" for word occurences\n",
    "#MultinomialNB -> is my Classifier\n",
    "\n",
    "#fit text_clf (our first Classifier model)\n",
    "fit_mbnb = pipeline_mbnb.fit(X_train, y_train)\n",
    "\n",
    "spent = time() - start\n",
    "print('NAÏVE BAYES - process time:{:.2f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want, I can see the parameters for my **Pipeline**, using this command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline_mbnb.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Run metrics for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting using **Naïve Bayes** Classifier\n",
    "\n",
    "And I took this **weird** Error Message:\n",
    "\n",
    "\"**UndefinedMetricWarning:**\" \n",
    "\n",
    ">- \"Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples\"\n",
    ">- \"Use `zero_division` parameter to control this behavior\"\n",
    "\n",
    "And searching, I found this explanation [here](https://stackoverflow.com/questions/43162506/undefinedmetricwarning-f-score-is-ill-defined-and-being-set-to-0-0-in-labels-wi)\n",
    "\n",
    ">- it is not an **weird error** at all. Some labels could´t be predicted when running the Classifier\n",
    ">- so the report don´t know how to handle them\n",
    "\n",
    "\"What you can do, is decide that you are not interested in the scores of labels that were not predicted, and then explicitly specify the labels you are interested in (which are labels that were predicted at least once):\"\n",
    "\n",
    "`metrics.f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))`\n",
    "\n",
    "#### Dealing with this issue\n",
    "\n",
    "**First**, I altered my function `fn_plot_scores` for not allowing comparisons over an empty (**not trained**) column, as `y_pred`\n",
    "\n",
    "And to check if all predicted values are **zeroes** [here](https://stackoverflow.com/questions/48570797/check-if-pandas-column-contains-all-zeros)\n",
    "\n",
    "And I was using in my function a **general** calculus for Accuracy. The problem is: **zeroes** for **zeroes** result a **1** accuracy, distorting my actual Accuracy, for a better (**unreal**) higher value:\n",
    "\n",
    ">- so, for general model Accuracy, I cannot use this `accuracy = (y_pred == y_test.values).mean()`\n",
    ">- using instead `f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###function scores_report started\n",
      "######################################################\n",
      "*request -> label iloc[0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      3088\n",
      "           1       0.83      0.45      0.59       897\n",
      "\n",
      "    accuracy                           0.86      3985\n",
      "   macro avg       0.85      0.71      0.75      3985\n",
      "weighted avg       0.85      0.86      0.84      3985\n",
      "\n",
      "######################################################\n",
      "*offer -> label iloc[1]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*aid_related -> label iloc[2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.48      0.60      1819\n",
      "           1       0.67      0.89      0.76      2166\n",
      "\n",
      "    accuracy                           0.70      3985\n",
      "   macro avg       0.72      0.68      0.68      3985\n",
      "weighted avg       0.72      0.70      0.69      3985\n",
      "\n",
      "######################################################\n",
      "*medical_help -> label iloc[3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      3572\n",
      "           1       1.00      0.00      0.00       413\n",
      "\n",
      "    accuracy                           0.90      3985\n",
      "   macro avg       0.95      0.50      0.48      3985\n",
      "weighted avg       0.91      0.90      0.85      3985\n",
      "\n",
      "######################################################\n",
      "*medical_products -> label iloc[4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      3699\n",
      "           1       1.00      0.00      0.01       286\n",
      "\n",
      "    accuracy                           0.93      3985\n",
      "   macro avg       0.96      0.50      0.48      3985\n",
      "weighted avg       0.93      0.93      0.89      3985\n",
      "\n",
      "######################################################\n",
      "*search_and_rescue -> label iloc[5]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*security -> label iloc[6]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*military -> label iloc[7]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*water -> label iloc[8]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*food -> label iloc[9]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93      3400\n",
      "           1       0.82      0.08      0.15       585\n",
      "\n",
      "    accuracy                           0.86      3985\n",
      "   macro avg       0.84      0.54      0.54      3985\n",
      "weighted avg       0.86      0.86      0.81      3985\n",
      "\n",
      "######################################################\n",
      "*shelter -> label iloc[10]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      3529\n",
      "           1       0.93      0.03      0.06       456\n",
      "\n",
      "    accuracy                           0.89      3985\n",
      "   macro avg       0.91      0.51      0.50      3985\n",
      "weighted avg       0.89      0.89      0.84      3985\n",
      "\n",
      "######################################################\n",
      "*clothing -> label iloc[11]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*money -> label iloc[12]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*missing_people -> label iloc[13]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*refugees -> label iloc[14]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*death -> label iloc[15]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*other_aid -> label iloc[16]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*infrastructure_related -> label iloc[17]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*transport -> label iloc[18]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*buildings -> label iloc[19]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*electricity -> label iloc[20]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*tools -> label iloc[21]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*hospitals -> label iloc[22]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*shops -> label iloc[23]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*aid_centers -> label iloc[24]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*other_infrastructure -> label iloc[25]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*weather_related -> label iloc[26]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.85      2528\n",
      "           1       0.80      0.60      0.69      1457\n",
      "\n",
      "    accuracy                           0.80      3985\n",
      "   macro avg       0.80      0.76      0.77      3985\n",
      "weighted avg       0.80      0.80      0.79      3985\n",
      "\n",
      "######################################################\n",
      "*floods -> label iloc[27]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      3560\n",
      "           1       1.00      0.03      0.06       425\n",
      "\n",
      "    accuracy                           0.90      3985\n",
      "   macro avg       0.95      0.52      0.50      3985\n",
      "weighted avg       0.91      0.90      0.85      3985\n",
      "\n",
      "######################################################\n",
      "*storm -> label iloc[28]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94      3500\n",
      "           1       0.82      0.06      0.10       485\n",
      "\n",
      "    accuracy                           0.88      3985\n",
      "   macro avg       0.85      0.53      0.52      3985\n",
      "weighted avg       0.88      0.88      0.84      3985\n",
      "\n",
      "######################################################\n",
      "*fire -> label iloc[29]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*earthquake -> label iloc[30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.94      3496\n",
      "           1       0.88      0.17      0.28       489\n",
      "\n",
      "    accuracy                           0.90      3985\n",
      "   macro avg       0.89      0.58      0.61      3985\n",
      "weighted avg       0.89      0.90      0.86      3985\n",
      "\n",
      "######################################################\n",
      "*cold -> label iloc[31]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*other_weather -> label iloc[32]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*direct_report -> label iloc[33]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88      2960\n",
      "           1       0.77      0.37      0.50      1025\n",
      "\n",
      "    accuracy                           0.81      3985\n",
      "   macro avg       0.80      0.67      0.69      3985\n",
      "weighted avg       0.81      0.81      0.79      3985\n",
      "\n",
      "Model Accuracy: 0.924 (92.4%)\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline_mbnb.predict(X_test)\n",
    "udacourse2.fn_scores_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy is distorted by **false fitting** (zeroes over zeroes)\n",
    "\n",
    "Manually, I could find the true meaning as **82.2%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8227272727272728"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "real_f1 = [.78, .86, .83, .85, .80, .83, .81, .91, .86, .69, .83]\n",
    "statistics.mean(real_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critics about the performance of my Classifier\n",
    "\n",
    "I know what you are thinking: \"Uh, there is something **wrong** with the Accuracy of this guy\"\n",
    "\n",
    "So, as you can see: **92.3%** is too high for a **Naïve Bayes Classifier**!\n",
    "\n",
    "There are some explanations here:\n",
    "\n",
    ">- if you read it with care, you will find this **weird** label `related`. And it seems to **positivate** for every row on my dataset. So It distorts the average for a **higher** one\n",
    ">- if you look at each **weighted avg**, you will find some clearly **bad** values, as **68%** for **aid_related** (if you start thinking about it, is something like in **2/3** of the cases the model guesses well for this label... so a really **bad** performance)\n",
    "\n",
    "*Updated 1: when I removed `related` column, my **Model Accuracy** felt down to **56.1%**. Normally my Labels are holding something as **75-78%** f1-score. Now I think that these **untrainable columns** are making my average Accuracy to fall down!*\n",
    "\n",
    "---\n",
    "\n",
    "But there is another **critic** about this data.\n",
    "\n",
    "I am **Engineer** by profession. And I work for almost **19** years in a **hidrology** datacenter for the Brazillian Government. So, in some cases, you see some data and start thinking: \"this data is not what it seems\".\n",
    "\n",
    "And the main problem with this data is:\n",
    "\n",
    ">- it is a **mistake** to think that all we need to do with it is to train a **Supervised Learning** machine!\n",
    ">- if you look with care, this is not about **Supervised Learning**, it is an actual **Semi-Supervised Learning** problem. Why?\n",
    ">- just consider that there were **zillions** of Tweeter messages about catastrophes all around the world. And then, when the message was not originally in English, they translated it. And then someone manually **labeled** each of these catastrophe reports. And a **lot** of them remained with **no classification**\n",
    ">- it I just interpret it as a **Supervised Learning** challenge, I will feed my Classifier with a lot of **false negatives**. And my Machine Learning Model will learn how to **keep in blank** a lot of these messages, as it was trained by my **raw** data!\n",
    "\n",
    "So in **preprocessing** step, I avoided **unlabelled data**, filtering and removing for training every row that not contains any label on it. They were clearly, **negleted** for labeling, when manually processed!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Try other Classifiers\n",
    "\n",
    "- I will try some Classifiers based on a **hierarchical structure**:\n",
    "\n",
    ">- why **hierarchical structure** for words? Just because I think we do it **naturally** in our brain\n",
    ">- when science mimic nature I personally think that things goes in a better way. So, let´s try it!\n",
    "\n",
    "First of them, **Random Forest** Classifier\n",
    "\n",
    ">- as **RFC** is a **single-label** Classifier, we need to call it **n** times for each label to be classified\n",
    ">- so, que need to call it indirectly, using **Multi-Output** Classifier tool\n",
    ">- it took **693.73 seconds** (as 11 minutes and 35 seconds) to complete the tast (not so bad!)\n",
    ">- I tried to configure a **GridSearch**, just to set the number of processors to `-1` (meaning, the **maximum** number)\n",
    "\n",
    "Accuracy was near to **93%** before removing `related` label. Now it remains as **93.8%**. So, it don't matter!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-e4c8443cccff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m pipeline_rafo = Pipeline([('vect', CountVectorizer(tokenizer=dummy, preprocessor=dummy)),\n\u001b[1;32m----> 7\u001b[1;33m                           \u001b[1;33m(\u001b[0m\u001b[1;34m'tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m                           ('clf', MultiOutputClassifier(RandomForestClassifier(random_state=42)))])\n\u001b[0;32m      9\u001b[0m \u001b[0mfit_rafo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline_rafo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'random_state'"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "pipeline_rafo = Pipeline([('vect', CountVectorizer(tokenizer=dummy, preprocessor=dummy)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', MultiOutputClassifier(RandomForestClassifier(random_state=42)))])\n",
    "fit_rafo = pipeline_rafo.fit(X_train, y_train)\n",
    "\n",
    "#an attempt to use multiple cores to process the task\n",
    "\n",
    "#param_grid = \n",
    "#gs_clf = GridSearchCV(pipeline_rafo, parameters, n_jobs=-1)\n",
    "#gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "spent = time() - start\n",
    "print('RANDOM FOREST - process time:{:.2f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###function scores_report started\n",
      "######################################################\n",
      "*request -> label iloc[0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      3088\n",
      "           1       0.78      0.64      0.70       897\n",
      "\n",
      "    accuracy                           0.88      3985\n",
      "   macro avg       0.84      0.79      0.81      3985\n",
      "weighted avg       0.87      0.88      0.87      3985\n",
      "\n",
      "######################################################\n",
      "*offer -> label iloc[1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3956\n",
      "           1       1.00      0.03      0.07        29\n",
      "\n",
      "    accuracy                           0.99      3985\n",
      "   macro avg       1.00      0.52      0.53      3985\n",
      "weighted avg       0.99      0.99      0.99      3985\n",
      "\n",
      "######################################################\n",
      "*aid_related -> label iloc[2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.69      0.71      1819\n",
      "           1       0.75      0.80      0.78      2166\n",
      "\n",
      "    accuracy                           0.75      3985\n",
      "   macro avg       0.75      0.74      0.75      3985\n",
      "weighted avg       0.75      0.75      0.75      3985\n",
      "\n",
      "######################################################\n",
      "*medical_help -> label iloc[3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      3572\n",
      "           1       0.61      0.18      0.28       413\n",
      "\n",
      "    accuracy                           0.90      3985\n",
      "   macro avg       0.76      0.58      0.61      3985\n",
      "weighted avg       0.88      0.90      0.88      3985\n",
      "\n",
      "######################################################\n",
      "*medical_products -> label iloc[4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97      3699\n",
      "           1       0.85      0.10      0.18       286\n",
      "\n",
      "    accuracy                           0.93      3985\n",
      "   macro avg       0.89      0.55      0.57      3985\n",
      "weighted avg       0.93      0.93      0.91      3985\n",
      "\n",
      "######################################################\n",
      "*search_and_rescue -> label iloc[5]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      3851\n",
      "           1       0.76      0.10      0.17       134\n",
      "\n",
      "    accuracy                           0.97      3985\n",
      "   macro avg       0.87      0.55      0.58      3985\n",
      "weighted avg       0.96      0.97      0.96      3985\n",
      "\n",
      "######################################################\n",
      "*security -> label iloc[6]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3900\n",
      "           1       0.00      0.00      0.00        85\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.49      0.50      0.49      3985\n",
      "weighted avg       0.96      0.98      0.97      3985\n",
      "\n",
      "######################################################\n",
      "*military -> label iloc[7]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3806\n",
      "           1       0.67      0.16      0.25       179\n",
      "\n",
      "    accuracy                           0.96      3985\n",
      "   macro avg       0.81      0.58      0.62      3985\n",
      "weighted avg       0.95      0.96      0.95      3985\n",
      "\n",
      "######################################################\n",
      "*water -> label iloc[8]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      3662\n",
      "           1       0.84      0.46      0.60       323\n",
      "\n",
      "    accuracy                           0.95      3985\n",
      "   macro avg       0.90      0.73      0.79      3985\n",
      "weighted avg       0.95      0.95      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*food -> label iloc[9]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3400\n",
      "           1       0.83      0.72      0.77       585\n",
      "\n",
      "    accuracy                           0.94      3985\n",
      "   macro avg       0.89      0.85      0.87      3985\n",
      "weighted avg       0.94      0.94      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*shelter -> label iloc[10]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      3529\n",
      "           1       0.80      0.50      0.62       456\n",
      "\n",
      "    accuracy                           0.93      3985\n",
      "   macro avg       0.87      0.74      0.79      3985\n",
      "weighted avg       0.92      0.93      0.92      3985\n",
      "\n",
      "######################################################\n",
      "*clothing -> label iloc[11]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3896\n",
      "           1       0.87      0.15      0.25        89\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.92      0.57      0.62      3985\n",
      "weighted avg       0.98      0.98      0.97      3985\n",
      "\n",
      "######################################################\n",
      "*money -> label iloc[12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      3873\n",
      "           1       0.75      0.03      0.05       112\n",
      "\n",
      "    accuracy                           0.97      3985\n",
      "   macro avg       0.86      0.51      0.52      3985\n",
      "weighted avg       0.97      0.97      0.96      3985\n",
      "\n",
      "######################################################\n",
      "*missing_people -> label iloc[13]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3927\n",
      "           1       1.00      0.03      0.07        58\n",
      "\n",
      "    accuracy                           0.99      3985\n",
      "   macro avg       0.99      0.52      0.53      3985\n",
      "weighted avg       0.99      0.99      0.98      3985\n",
      "\n",
      "######################################################\n",
      "*refugees -> label iloc[14]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3815\n",
      "           1       0.70      0.11      0.19       170\n",
      "\n",
      "    accuracy                           0.96      3985\n",
      "   macro avg       0.83      0.55      0.59      3985\n",
      "weighted avg       0.95      0.96      0.95      3985\n",
      "\n",
      "######################################################\n",
      "*death -> label iloc[15]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      3725\n",
      "           1       0.81      0.35      0.49       260\n",
      "\n",
      "    accuracy                           0.95      3985\n",
      "   macro avg       0.88      0.67      0.73      3985\n",
      "weighted avg       0.95      0.95      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*other_aid -> label iloc[16]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.99      0.90      3273\n",
      "           1       0.65      0.08      0.14       712\n",
      "\n",
      "    accuracy                           0.83      3985\n",
      "   macro avg       0.74      0.54      0.52      3985\n",
      "weighted avg       0.80      0.83      0.77      3985\n",
      "\n",
      "######################################################\n",
      "*infrastructure_related -> label iloc[17]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95      3624\n",
      "           1       0.00      0.00      0.00       361\n",
      "\n",
      "    accuracy                           0.91      3985\n",
      "   macro avg       0.45      0.50      0.48      3985\n",
      "weighted avg       0.83      0.91      0.87      3985\n",
      "\n",
      "######################################################\n",
      "*transport -> label iloc[18]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      3739\n",
      "           1       0.71      0.20      0.32       246\n",
      "\n",
      "    accuracy                           0.95      3985\n",
      "   macro avg       0.83      0.60      0.64      3985\n",
      "weighted avg       0.94      0.95      0.93      3985\n",
      "\n",
      "######################################################\n",
      "*buildings -> label iloc[19]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      3717\n",
      "           1       0.87      0.21      0.33       268\n",
      "\n",
      "    accuracy                           0.94      3985\n",
      "   macro avg       0.91      0.60      0.65      3985\n",
      "weighted avg       0.94      0.94      0.93      3985\n",
      "\n",
      "######################################################\n",
      "*electricity -> label iloc[20]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3877\n",
      "           1       0.83      0.09      0.17       108\n",
      "\n",
      "    accuracy                           0.97      3985\n",
      "   macro avg       0.90      0.55      0.58      3985\n",
      "weighted avg       0.97      0.97      0.97      3985\n",
      "\n",
      "######################################################\n",
      "*tools -> label iloc[21]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*hospitals -> label iloc[22]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*shops -> label iloc[23]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*aid_centers -> label iloc[24]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*other_infrastructure -> label iloc[25]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      3731\n",
      "           1       0.00      0.00      0.00       254\n",
      "\n",
      "    accuracy                           0.93      3985\n",
      "   macro avg       0.47      0.50      0.48      3985\n",
      "weighted avg       0.88      0.93      0.90      3985\n",
      "\n",
      "######################################################\n",
      "*weather_related -> label iloc[26]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      2528\n",
      "           1       0.83      0.76      0.80      1457\n",
      "\n",
      "    accuracy                           0.86      3985\n",
      "   macro avg       0.85      0.84      0.84      3985\n",
      "weighted avg       0.86      0.86      0.86      3985\n",
      "\n",
      "######################################################\n",
      "*floods -> label iloc[27]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      3560\n",
      "           1       0.91      0.56      0.69       425\n",
      "\n",
      "    accuracy                           0.95      3985\n",
      "   macro avg       0.93      0.77      0.83      3985\n",
      "weighted avg       0.94      0.95      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*storm -> label iloc[28]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3500\n",
      "           1       0.77      0.63      0.69       485\n",
      "\n",
      "    accuracy                           0.93      3985\n",
      "   macro avg       0.86      0.80      0.83      3985\n",
      "weighted avg       0.93      0.93      0.93      3985\n",
      "\n",
      "######################################################\n",
      "*fire -> label iloc[29]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3921\n",
      "           1       1.00      0.05      0.09        64\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.99      0.52      0.54      3985\n",
      "weighted avg       0.98      0.98      0.98      3985\n",
      "\n",
      "######################################################\n",
      "*earthquake -> label iloc[30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3496\n",
      "           1       0.89      0.80      0.84       489\n",
      "\n",
      "    accuracy                           0.96      3985\n",
      "   macro avg       0.93      0.89      0.91      3985\n",
      "weighted avg       0.96      0.96      0.96      3985\n",
      "\n",
      "######################################################\n",
      "*cold -> label iloc[31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3890\n",
      "           1       0.80      0.13      0.22        95\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.89      0.56      0.60      3985\n",
      "weighted avg       0.97      0.98      0.97      3985\n",
      "\n",
      "######################################################\n",
      "*other_weather -> label iloc[32]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.96      3716\n",
      "           1       0.50      0.06      0.11       269\n",
      "\n",
      "    accuracy                           0.93      3985\n",
      "   macro avg       0.72      0.53      0.54      3985\n",
      "weighted avg       0.91      0.93      0.91      3985\n",
      "\n",
      "######################################################\n",
      "*direct_report -> label iloc[33]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      2960\n",
      "           1       0.71      0.49      0.58      1025\n",
      "\n",
      "    accuracy                           0.82      3985\n",
      "   macro avg       0.77      0.71      0.73      3985\n",
      "weighted avg       0.81      0.82      0.80      3985\n",
      "\n",
      "Model Accuracy: 0.939 (93.9%)\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline_rafo.predict(X_test)\n",
    "udacourse2.fn_scores_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another tree like Classifier is **Adaboost**:\n",
    "\n",
    ">- they say Adaboost is specially good for **differenciate** positives and negatives\n",
    ">- it took **106.16 seconds** (kind of 1 minute and 45 seconds) to complete the task... not so bad... (as AdaBoost don´t use **trees**, but **stumps** for doing its job)\n",
    "\n",
    "Accuracy was near to **91%**. After removing `related` label, it raised to **93.9%**. As Adaboost is based on **stumps**, a bad label perhaps distorts the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-98220c79fcbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                          \u001b[1;33m(\u001b[0m\u001b[1;34m'tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                          ('clf',  MultiOutputClassifier(AdaBoostClassifier(random_state=42)))])\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mfit_adab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline_adab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mspent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, Y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \"\"\"\n\u001b[1;32m--> 368\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                 **fit_params_validated)\n\u001b[1;32m--> 182\u001b[1;33m             for i in range(y.shape[1]))\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multioutput.py\u001b[0m in \u001b[0;36m_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 random_state)\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;31m# Early termination\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    501\u001b[0m         \"\"\"\n\u001b[0;32m    502\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'SAMME.R'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    905\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 907\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    908\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "pipeline_adab = Pipeline([('vect', CountVectorizer(tokenizer=dummy, preprocessor=dummy)),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf',  MultiOutputClassifier(AdaBoostClassifier(random_state=42)))])\n",
    "fit_adab = pipeline_adab.fit(X_train, y_train)\n",
    "\n",
    "spent = time() - start\n",
    "print('ADABOOST - process time:{:.2f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###function scores_report started\n",
      "######################################################\n",
      "*request -> label iloc[0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      3088\n",
      "           1       0.78      0.55      0.65       897\n",
      "\n",
      "    accuracy                           0.86      3985\n",
      "   macro avg       0.83      0.75      0.78      3985\n",
      "weighted avg       0.86      0.86      0.86      3985\n",
      "\n",
      "######################################################\n",
      "*offer -> label iloc[1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3956\n",
      "           1       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.99      3985\n",
      "   macro avg       0.50      0.50      0.50      3985\n",
      "weighted avg       0.99      0.99      0.99      3985\n",
      "\n",
      "######################################################\n",
      "*aid_related -> label iloc[2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71      1819\n",
      "           1       0.76      0.70      0.73      2166\n",
      "\n",
      "    accuracy                           0.72      3985\n",
      "   macro avg       0.72      0.72      0.72      3985\n",
      "weighted avg       0.72      0.72      0.72      3985\n",
      "\n",
      "######################################################\n",
      "*medical_help -> label iloc[3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      3572\n",
      "           1       0.61      0.27      0.37       413\n",
      "\n",
      "    accuracy                           0.91      3985\n",
      "   macro avg       0.77      0.62      0.66      3985\n",
      "weighted avg       0.89      0.91      0.89      3985\n",
      "\n",
      "######################################################\n",
      "*medical_products -> label iloc[4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      3699\n",
      "           1       0.74      0.30      0.42       286\n",
      "\n",
      "    accuracy                           0.94      3985\n",
      "   macro avg       0.84      0.64      0.70      3985\n",
      "weighted avg       0.93      0.94      0.93      3985\n",
      "\n",
      "######################################################\n",
      "*search_and_rescue -> label iloc[5]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      3851\n",
      "           1       0.53      0.13      0.21       134\n",
      "\n",
      "    accuracy                           0.97      3985\n",
      "   macro avg       0.75      0.57      0.60      3985\n",
      "weighted avg       0.96      0.97      0.96      3985\n",
      "\n",
      "######################################################\n",
      "*security -> label iloc[6]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3900\n",
      "           1       0.24      0.05      0.08        85\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.61      0.52      0.53      3985\n",
      "weighted avg       0.96      0.98      0.97      3985\n",
      "\n",
      "######################################################\n",
      "*military -> label iloc[7]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3806\n",
      "           1       0.63      0.37      0.47       179\n",
      "\n",
      "    accuracy                           0.96      3985\n",
      "   macro avg       0.80      0.68      0.73      3985\n",
      "weighted avg       0.96      0.96      0.96      3985\n",
      "\n",
      "######################################################\n",
      "*water -> label iloc[8]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      3662\n",
      "           1       0.76      0.65      0.70       323\n",
      "\n",
      "    accuracy                           0.95      3985\n",
      "   macro avg       0.86      0.82      0.84      3985\n",
      "weighted avg       0.95      0.95      0.95      3985\n",
      "\n",
      "######################################################\n",
      "*food -> label iloc[9]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      3400\n",
      "           1       0.81      0.77      0.79       585\n",
      "\n",
      "    accuracy                           0.94      3985\n",
      "   macro avg       0.89      0.87      0.88      3985\n",
      "weighted avg       0.94      0.94      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*shelter -> label iloc[10]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      3529\n",
      "           1       0.81      0.58      0.68       456\n",
      "\n",
      "    accuracy                           0.94      3985\n",
      "   macro avg       0.88      0.78      0.82      3985\n",
      "weighted avg       0.93      0.94      0.93      3985\n",
      "\n",
      "######################################################\n",
      "*clothing -> label iloc[11]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3896\n",
      "           1       0.73      0.42      0.53        89\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.86      0.71      0.76      3985\n",
      "weighted avg       0.98      0.98      0.98      3985\n",
      "\n",
      "######################################################\n",
      "*money -> label iloc[12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3873\n",
      "           1       0.50      0.29      0.36       112\n",
      "\n",
      "    accuracy                           0.97      3985\n",
      "   macro avg       0.74      0.64      0.67      3985\n",
      "weighted avg       0.97      0.97      0.97      3985\n",
      "\n",
      "######################################################\n",
      "*missing_people -> label iloc[13]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3927\n",
      "           1       0.58      0.26      0.36        58\n",
      "\n",
      "    accuracy                           0.99      3985\n",
      "   macro avg       0.78      0.63      0.68      3985\n",
      "weighted avg       0.98      0.99      0.98      3985\n",
      "\n",
      "######################################################\n",
      "*refugees -> label iloc[14]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3815\n",
      "           1       0.59      0.21      0.31       170\n",
      "\n",
      "    accuracy                           0.96      3985\n",
      "   macro avg       0.78      0.60      0.64      3985\n",
      "weighted avg       0.95      0.96      0.95      3985\n",
      "\n",
      "######################################################\n",
      "*death -> label iloc[15]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      3725\n",
      "           1       0.67      0.36      0.47       260\n",
      "\n",
      "    accuracy                           0.95      3985\n",
      "   macro avg       0.81      0.67      0.72      3985\n",
      "weighted avg       0.94      0.95      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*other_aid -> label iloc[16]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      3273\n",
      "           1       0.57      0.16      0.25       712\n",
      "\n",
      "    accuracy                           0.83      3985\n",
      "   macro avg       0.70      0.57      0.58      3985\n",
      "weighted avg       0.79      0.83      0.79      3985\n",
      "\n",
      "######################################################\n",
      "*infrastructure_related -> label iloc[17]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95      3624\n",
      "           1       0.53      0.10      0.17       361\n",
      "\n",
      "    accuracy                           0.91      3985\n",
      "   macro avg       0.72      0.55      0.56      3985\n",
      "weighted avg       0.88      0.91      0.88      3985\n",
      "\n",
      "######################################################\n",
      "*transport -> label iloc[18]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      3739\n",
      "           1       0.72      0.30      0.42       246\n",
      "\n",
      "    accuracy                           0.95      3985\n",
      "   macro avg       0.84      0.65      0.70      3985\n",
      "weighted avg       0.94      0.95      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*buildings -> label iloc[19]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      3717\n",
      "           1       0.70      0.39      0.50       268\n",
      "\n",
      "    accuracy                           0.95      3985\n",
      "   macro avg       0.83      0.69      0.74      3985\n",
      "weighted avg       0.94      0.95      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*electricity -> label iloc[20]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3877\n",
      "           1       0.62      0.37      0.47       108\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.80      0.68      0.73      3985\n",
      "weighted avg       0.97      0.98      0.97      3985\n",
      "\n",
      "######################################################\n",
      "*tools -> label iloc[21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3963\n",
      "           1       0.10      0.05      0.06        22\n",
      "\n",
      "    accuracy                           0.99      3985\n",
      "   macro avg       0.55      0.52      0.53      3985\n",
      "weighted avg       0.99      0.99      0.99      3985\n",
      "\n",
      "######################################################\n",
      "*hospitals -> label iloc[22]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3935\n",
      "           1       0.21      0.08      0.12        50\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.60      0.54      0.55      3985\n",
      "weighted avg       0.98      0.98      0.98      3985\n",
      "\n",
      "######################################################\n",
      "*shops -> label iloc[23]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3954\n",
      "           1       0.25      0.03      0.06        31\n",
      "\n",
      "    accuracy                           0.99      3985\n",
      "   macro avg       0.62      0.52      0.53      3985\n",
      "weighted avg       0.99      0.99      0.99      3985\n",
      "\n",
      "######################################################\n",
      "*aid_centers -> label iloc[24]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3915\n",
      "           1       0.60      0.04      0.08        70\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.79      0.52      0.54      3985\n",
      "weighted avg       0.98      0.98      0.98      3985\n",
      "\n",
      "######################################################\n",
      "*other_infrastructure -> label iloc[25]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      3731\n",
      "           1       0.57      0.09      0.16       254\n",
      "\n",
      "    accuracy                           0.94      3985\n",
      "   macro avg       0.76      0.54      0.56      3985\n",
      "weighted avg       0.92      0.94      0.92      3985\n",
      "\n",
      "######################################################\n",
      "*weather_related -> label iloc[26]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      2528\n",
      "           1       0.87      0.71      0.78      1457\n",
      "\n",
      "    accuracy                           0.85      3985\n",
      "   macro avg       0.86      0.82      0.84      3985\n",
      "weighted avg       0.86      0.85      0.85      3985\n",
      "\n",
      "######################################################\n",
      "*floods -> label iloc[27]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      3560\n",
      "           1       0.90      0.59      0.71       425\n",
      "\n",
      "    accuracy                           0.95      3985\n",
      "   macro avg       0.93      0.79      0.84      3985\n",
      "weighted avg       0.95      0.95      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*storm -> label iloc[28]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      3500\n",
      "           1       0.79      0.61      0.69       485\n",
      "\n",
      "    accuracy                           0.93      3985\n",
      "   macro avg       0.87      0.79      0.83      3985\n",
      "weighted avg       0.93      0.93      0.93      3985\n",
      "\n",
      "######################################################\n",
      "*fire -> label iloc[29]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3921\n",
      "           1       0.28      0.11      0.16        64\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.63      0.55      0.57      3985\n",
      "weighted avg       0.97      0.98      0.98      3985\n",
      "\n",
      "######################################################\n",
      "*earthquake -> label iloc[30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3496\n",
      "           1       0.88      0.82      0.85       489\n",
      "\n",
      "    accuracy                           0.96      3985\n",
      "   macro avg       0.93      0.90      0.92      3985\n",
      "weighted avg       0.96      0.96      0.96      3985\n",
      "\n",
      "######################################################\n",
      "*cold -> label iloc[31]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3890\n",
      "           1       0.63      0.27      0.38        95\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.81      0.63      0.69      3985\n",
      "weighted avg       0.97      0.98      0.97      3985\n",
      "\n",
      "######################################################\n",
      "*other_weather -> label iloc[32]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      3716\n",
      "           1       0.39      0.10      0.15       269\n",
      "\n",
      "    accuracy                           0.93      3985\n",
      "   macro avg       0.66      0.54      0.56      3985\n",
      "weighted avg       0.90      0.93      0.91      3985\n",
      "\n",
      "######################################################\n",
      "*direct_report -> label iloc[33]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      2960\n",
      "           1       0.71      0.43      0.54      1025\n",
      "\n",
      "    accuracy                           0.81      3985\n",
      "   macro avg       0.77      0.69      0.71      3985\n",
      "weighted avg       0.80      0.81      0.79      3985\n",
      "\n",
      "Model Accuracy: 0.939 (93.9%)\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline_adab.predict(X_test)\n",
    "udacourse2.fn_scores_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Falling in a trap when choosing another Classifier\n",
    "\n",
    "Then I tried a **Stochastic Gradient Descent** (SGD) [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    "\n",
    "_\"Linear classifiers (SVM, logistic regression, etc.) with SGD training\"_\n",
    "\n",
    "It can works with a **Support Vector Machine** (SVM), that is a fancy way of defining a good frontier\n",
    "\n",
    "\n",
    "`clf = SGDClassifier()` with some parameters\n",
    "  \n",
    ">- `learning_rate='optimal'`$\\rightarrow$ **decreasing strength schedule** used for updating the gradient of the loss at each sample\n",
    ">- `loss='hinge'` $\\rightarrow$ **Linear SVM** for the fitting model (works with data represented as dense or sparse arrays for features)\n",
    ">- `penalty=[‘l2’, ‘l1’, ‘elasticnet’]` $\\rightarrow$ **regularizer**  shrinks model parameters towards the zero vector using an **Elastic Net** (l2) or \n",
    ">- `alpha=[1e-5, 1e-4, 1e-3]` $\\rightarrow$ stopping criteria, the higher the value, the **stronger** the regularization (also used to compute the **Learning Rate**, when set to learning_rate is set to ‘optimal’\n",
    ">- `n_iter=[1, 5, 10]` $\\rightarrow$ number of passes over the **Epochs** (Training Data). It only impacts the behavior in the **fit method**, and not the partial_fit method\n",
    ">- `random_state=42` $\\rightarrow$ if you want to replicate exactly the same output each time you retrain your machine\n",
    "  \n",
    "*Observe that this is a kind of a lecture over the text at SkLearn website for this Classifier*\n",
    "\n",
    "---\n",
    "\n",
    "And **SGDC** didn´t work! It gave me a **ValueError: y should be a 1d array, got an array instead**. So, something went wrong:\n",
    "\n",
    "Searching for the cause of the problem, I found this explanation [here](https://stackoverflow.com/questions/20335853/scikit-multilabel-classification-valueerror-bad-input-shape)\n",
    "\n",
    "\"No, SGDClassifier does not do **multilabel classification** (what I need!) -- it does **multiclass classification**, which is a different problem, although both are solved using a one-vs-all problem reduction*\n",
    "\n",
    "*Then, neither **SGD** nor OneVsRestClassifier.fit will accept a **sparse matrix** (is what I have!) for y* \n",
    "\n",
    "*- SGD wants an **array of labels** (is what I have!), as you've already found out*\n",
    "\n",
    "*- OneVsRestClassifier wants, for multilabel purposes, a list of lists of labels*\n",
    "\n",
    "*Observe that this is a kind of a lecture over the explanatory text that I got at SKLearn website for SGDC for Multilabel*\n",
    "\n",
    "---\n",
    "\n",
    "There is a good explanation about **Multiclass** and **Multilabel** Classifiers [here](https://scikit-learn.org/stable/modules/multiclass.html)\n",
    "\n",
    "Don´t try to run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time()\n",
    "\n",
    "#def dummy(doc):\n",
    "#    return doc\n",
    "\n",
    "#random_state=42 #<-just to remember!\n",
    "#pipeline_sgrd = Pipeline([('vect', CountVectorizer(tokenizer=dummy, preprocessor=dummy)),\n",
    "#                          ('tfidf', TfidfTransformer()),\n",
    "#                          ('clf', SGDClassifier(loss='hinge', \n",
    "#                                                penalty='l2',\n",
    "#                                                alpha=1e-3))]) \n",
    "#fit_sgrd = pipeline_sgrd.fit(X_train, y_train)\n",
    "\n",
    "#spent = time() - start\n",
    "#print('STOCHASTIC GRADIENT DESCENT - process time:{:.2f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try **K-Neighbors Classifier**:\n",
    "\n",
    "- average Accuracy was **91.8%**... not so bad!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K NEIGHBORS CLASSIFIER - process time:0.63 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "#random_state=42 #<-just to remember!\n",
    "pipeline_knbr = Pipeline([('vect', CountVectorizer(tokenizer=dummy, preprocessor=dummy)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', MultiOutputClassifier(KNeighborsClassifier(n_neighbors=3)))])\n",
    "fit_knbr = pipeline_knbr.fit(X_train, y_train)\n",
    "\n",
    "spent = time() - start\n",
    "print('K NEIGHBORS CLASSIFIER - process time:{:.2f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-581cd7712d0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline_knbr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mudacourse2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn_scores_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_final_estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multioutput.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    207\u001b[0m         y = Parallel(n_jobs=self.n_jobs)(\n\u001b[0;32m    208\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 263\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 **kwds))\n\u001b[0m\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ball_tree'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kd_tree'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1622\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1623\u001b[0m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[1;32m-> 1624\u001b[1;33m                                      n_jobs=n_jobs, **kwds)\n\u001b[0m\u001b[0;32m   1625\u001b[0m         if ((X is Y or Y is None)\n\u001b[0;32m   1626\u001b[0m                 \u001b[1;32mand\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1788\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1790\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[1;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 313\u001b[1;33m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    314\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n\u001b[0;32m    155\u001b[0m             and dense_output and hasattr(ret, \"toarray\")):\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1040\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m         \u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m         \u001b[0mcsr_todense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred = pipeline_knbr.predict(X_test)\n",
    "udacourse2.fn_scores_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Supor Vector Machuine, fed by TfidVectorizer:\n",
    "    \n",
    "- Average Accuracy of **93.8%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR SUPPORT VECTOR MACHINE - process time:22.85 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "feats = TfidfVectorizer(analyzer='word', \n",
    "                        tokenizer=dummy, \n",
    "                        preprocessor=dummy,\n",
    "                        token_pattern=None,\n",
    "                        ngram_range=(1, 3))\n",
    "\n",
    "#feats = feats.fit_transform(X_train)\n",
    "\n",
    "pipeline_lnsv = Pipeline([\n",
    "    ('vect', feats),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC(C=2., \n",
    "                                          random_state=42)))\n",
    "])\n",
    "\n",
    "fit_lnsv = pipeline_lnsv.fit(X_train, y_train)\n",
    "\n",
    "spent = time() - start\n",
    "print('LINEAR SUPPORT VECTOR MACHINE - process time:{:.2f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NotFittedError: Vocabulary not fitted or provided*\n",
    "[here](https://stackoverflow.com/questions/60472925/python-scikit-svm-vocabulary-not-fitted-or-provided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###function scores_report started\n",
      "######################################################\n",
      "*request -> label iloc[0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      3088\n",
      "           1       0.69      0.73      0.71       897\n",
      "\n",
      "    accuracy                           0.87      3985\n",
      "   macro avg       0.81      0.82      0.81      3985\n",
      "weighted avg       0.87      0.87      0.87      3985\n",
      "\n",
      "######################################################\n",
      "*offer -> label iloc[1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3956\n",
      "           1       1.00      0.03      0.07        29\n",
      "\n",
      "    accuracy                           0.99      3985\n",
      "   macro avg       1.00      0.52      0.53      3985\n",
      "weighted avg       0.99      0.99      0.99      3985\n",
      "\n",
      "######################################################\n",
      "*aid_related -> label iloc[2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.57      0.65      1819\n",
      "           1       0.70      0.85      0.77      2166\n",
      "\n",
      "    accuracy                           0.72      3985\n",
      "   macro avg       0.73      0.71      0.71      3985\n",
      "weighted avg       0.73      0.72      0.72      3985\n",
      "\n",
      "######################################################\n",
      "*medical_help -> label iloc[3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3572\n",
      "           1       0.57      0.44      0.49       413\n",
      "\n",
      "    accuracy                           0.91      3985\n",
      "   macro avg       0.75      0.70      0.72      3985\n",
      "weighted avg       0.90      0.91      0.90      3985\n",
      "\n",
      "######################################################\n",
      "*medical_products -> label iloc[4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97      3699\n",
      "           1       0.62      0.38      0.48       286\n",
      "\n",
      "    accuracy                           0.94      3985\n",
      "   macro avg       0.79      0.68      0.72      3985\n",
      "weighted avg       0.93      0.94      0.93      3985\n",
      "\n",
      "######################################################\n",
      "*search_and_rescue -> label iloc[5]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      3851\n",
      "           1       0.64      0.24      0.35       134\n",
      "\n",
      "    accuracy                           0.97      3985\n",
      "   macro avg       0.81      0.62      0.67      3985\n",
      "weighted avg       0.96      0.97      0.96      3985\n",
      "\n",
      "######################################################\n",
      "*security -> label iloc[6]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3900\n",
      "           1       0.38      0.04      0.06        85\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.68      0.52      0.53      3985\n",
      "weighted avg       0.97      0.98      0.97      3985\n",
      "\n",
      "######################################################\n",
      "*military -> label iloc[7]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3806\n",
      "           1       0.59      0.48      0.53       179\n",
      "\n",
      "    accuracy                           0.96      3985\n",
      "   macro avg       0.78      0.73      0.75      3985\n",
      "weighted avg       0.96      0.96      0.96      3985\n",
      "\n",
      "######################################################\n",
      "*water -> label iloc[8]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97      3662\n",
      "           1       0.66      0.85      0.74       323\n",
      "\n",
      "    accuracy                           0.95      3985\n",
      "   macro avg       0.82      0.91      0.86      3985\n",
      "weighted avg       0.96      0.95      0.96      3985\n",
      "\n",
      "######################################################\n",
      "*food -> label iloc[9]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      3400\n",
      "           1       0.77      0.84      0.80       585\n",
      "\n",
      "    accuracy                           0.94      3985\n",
      "   macro avg       0.87      0.90      0.88      3985\n",
      "weighted avg       0.94      0.94      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*shelter -> label iloc[10]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      3529\n",
      "           1       0.69      0.74      0.71       456\n",
      "\n",
      "    accuracy                           0.93      3985\n",
      "   macro avg       0.83      0.85      0.84      3985\n",
      "weighted avg       0.93      0.93      0.93      3985\n",
      "\n",
      "######################################################\n",
      "*clothing -> label iloc[11]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3896\n",
      "           1       0.81      0.62      0.70        89\n",
      "\n",
      "    accuracy                           0.99      3985\n",
      "   macro avg       0.90      0.81      0.85      3985\n",
      "weighted avg       0.99      0.99      0.99      3985\n",
      "\n",
      "######################################################\n",
      "*money -> label iloc[12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3873\n",
      "           1       0.61      0.37      0.46       112\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.80      0.68      0.72      3985\n",
      "weighted avg       0.97      0.98      0.97      3985\n",
      "\n",
      "######################################################\n",
      "*missing_people -> label iloc[13]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3927\n",
      "           1       0.65      0.22      0.33        58\n",
      "\n",
      "    accuracy                           0.99      3985\n",
      "   macro avg       0.82      0.61      0.66      3985\n",
      "weighted avg       0.98      0.99      0.98      3985\n",
      "\n",
      "######################################################\n",
      "*refugees -> label iloc[14]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3815\n",
      "           1       0.63      0.34      0.44       170\n",
      "\n",
      "    accuracy                           0.96      3985\n",
      "   macro avg       0.80      0.66      0.71      3985\n",
      "weighted avg       0.96      0.96      0.96      3985\n",
      "\n",
      "######################################################\n",
      "*death -> label iloc[15]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      3725\n",
      "           1       0.71      0.58      0.64       260\n",
      "\n",
      "    accuracy                           0.96      3985\n",
      "   macro avg       0.84      0.78      0.81      3985\n",
      "weighted avg       0.95      0.96      0.95      3985\n",
      "\n",
      "######################################################\n",
      "*other_aid -> label iloc[16]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90      3273\n",
      "           1       0.51      0.34      0.41       712\n",
      "\n",
      "    accuracy                           0.82      3985\n",
      "   macro avg       0.69      0.64      0.65      3985\n",
      "weighted avg       0.80      0.82      0.81      3985\n",
      "\n",
      "######################################################\n",
      "*infrastructure_related -> label iloc[17]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95      3624\n",
      "           1       0.38      0.13      0.19       361\n",
      "\n",
      "    accuracy                           0.90      3985\n",
      "   macro avg       0.65      0.55      0.57      3985\n",
      "weighted avg       0.87      0.90      0.88      3985\n",
      "\n",
      "######################################################\n",
      "*transport -> label iloc[18]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      3739\n",
      "           1       0.71      0.32      0.44       246\n",
      "\n",
      "    accuracy                           0.95      3985\n",
      "   macro avg       0.83      0.65      0.71      3985\n",
      "weighted avg       0.94      0.95      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*buildings -> label iloc[19]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      3717\n",
      "           1       0.59      0.55      0.57       268\n",
      "\n",
      "    accuracy                           0.94      3985\n",
      "   macro avg       0.78      0.76      0.77      3985\n",
      "weighted avg       0.94      0.94      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*electricity -> label iloc[20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3877\n",
      "           1       0.62      0.51      0.56       108\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.81      0.75      0.78      3985\n",
      "weighted avg       0.98      0.98      0.98      3985\n",
      "\n",
      "######################################################\n",
      "*tools -> label iloc[21]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*hospitals -> label iloc[22]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3935\n",
      "           1       0.33      0.04      0.07        50\n",
      "\n",
      "    accuracy                           0.99      3985\n",
      "   macro avg       0.66      0.52      0.53      3985\n",
      "weighted avg       0.98      0.99      0.98      3985\n",
      "\n",
      "######################################################\n",
      "*shops -> label iloc[23]\n",
      "  - as y_pred has only zeroes, report is not valid\n",
      "######################################################\n",
      "*aid_centers -> label iloc[24]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3915\n",
      "           1       0.50      0.01      0.03        70\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.74      0.51      0.51      3985\n",
      "weighted avg       0.97      0.98      0.97      3985\n",
      "\n",
      "######################################################\n",
      "*other_infrastructure -> label iloc[25]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      3731\n",
      "           1       0.27      0.06      0.10       254\n",
      "\n",
      "    accuracy                           0.93      3985\n",
      "   macro avg       0.60      0.53      0.53      3985\n",
      "weighted avg       0.90      0.93      0.91      3985\n",
      "\n",
      "######################################################\n",
      "*weather_related -> label iloc[26]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      2528\n",
      "           1       0.75      0.82      0.78      1457\n",
      "\n",
      "    accuracy                           0.83      3985\n",
      "   macro avg       0.82      0.83      0.82      3985\n",
      "weighted avg       0.84      0.83      0.84      3985\n",
      "\n",
      "######################################################\n",
      "*floods -> label iloc[27]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      3560\n",
      "           1       0.77      0.66      0.71       425\n",
      "\n",
      "    accuracy                           0.94      3985\n",
      "   macro avg       0.87      0.82      0.84      3985\n",
      "weighted avg       0.94      0.94      0.94      3985\n",
      "\n",
      "######################################################\n",
      "*storm -> label iloc[28]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      3500\n",
      "           1       0.70      0.76      0.73       485\n",
      "\n",
      "    accuracy                           0.93      3985\n",
      "   macro avg       0.83      0.86      0.84      3985\n",
      "weighted avg       0.93      0.93      0.93      3985\n",
      "\n",
      "######################################################\n",
      "*fire -> label iloc[29]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3921\n",
      "           1       0.70      0.33      0.45        64\n",
      "\n",
      "    accuracy                           0.99      3985\n",
      "   macro avg       0.84      0.66      0.72      3985\n",
      "weighted avg       0.98      0.99      0.98      3985\n",
      "\n",
      "######################################################\n",
      "*earthquake -> label iloc[30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      3496\n",
      "           1       0.83      0.75      0.79       489\n",
      "\n",
      "    accuracy                           0.95      3985\n",
      "   macro avg       0.90      0.86      0.88      3985\n",
      "weighted avg       0.95      0.95      0.95      3985\n",
      "\n",
      "######################################################\n",
      "*cold -> label iloc[31]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      3890\n",
      "           1       0.71      0.46      0.56        95\n",
      "\n",
      "    accuracy                           0.98      3985\n",
      "   macro avg       0.85      0.73      0.78      3985\n",
      "weighted avg       0.98      0.98      0.98      3985\n",
      "\n",
      "######################################################\n",
      "*other_weather -> label iloc[32]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      3716\n",
      "           1       0.45      0.22      0.29       269\n",
      "\n",
      "    accuracy                           0.93      3985\n",
      "   macro avg       0.70      0.60      0.63      3985\n",
      "weighted avg       0.91      0.93      0.92      3985\n",
      "\n",
      "######################################################\n",
      "*direct_report -> label iloc[33]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      2960\n",
      "           1       0.63      0.63      0.63      1025\n",
      "\n",
      "    accuracy                           0.81      3985\n",
      "   macro avg       0.75      0.75      0.75      3985\n",
      "weighted avg       0.81      0.81      0.81      3985\n",
      "\n",
      "Model Accuracy: 0.938 (93.8%)\n"
     ]
    }
   ],
   "source": [
    "y_pred = pipeline_lnsv.predict(X_test)\n",
    "udacourse2.fn_scores_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Make a Fine Tunning effort over Classifiers\n",
    "\n",
    "If the Classifier that you choose have parameters that can be worked on, you can try to improve its performance, changing these parameters with some criteria.\n",
    "\n",
    "**Grid Search**\n",
    "\n",
    "`parameters = {'vect__ngram_range': [(1, 1), (1, 2)],`\n",
    "              `'tfidf__use_idf': (True, False),`\n",
    "              `'clf__alpha': (1e-2, 1e-3)}`\n",
    "\n",
    "- use **multiple cores** to process the task\n",
    "\n",
    "`gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)`\n",
    "\n",
    "`gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)`\n",
    "\n",
    "-see the **mean score** of the parameters\n",
    "\n",
    "`gs_clf.best_score_`\n",
    "\n",
    "`gs_clf.best_params_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3)}\n",
    "\n",
    "#use multiple cores to process the task\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('under development')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean score of the parameters\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(y_test, y_pred):\n",
    "    #Testing the model\n",
    "    # Printing the classification report for each label\n",
    "    i = 0\n",
    "    for col in y_test:\n",
    "        print('Feature {}: {}'.format(i+1, col))\n",
    "        print(classification_report(y_test[col], y_pred[:, i]))\n",
    "        i = i + 1\n",
    "    accuracy = (y_pred == y_test.values).mean()\n",
    "    print('The model accuracy is {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction: the Random Forest Classifier  \n",
    "y_pred = pipeline_rfc.predict(X_test)\n",
    "plot_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction: the Naive Bayes classifier \n",
    "y_pred = pipeline_nbc.predict(X_test)\n",
    "plot_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[here](https://stackoverflow.com/questions/31744519/load-pickled-classifier-data-vocabulary-not-fitted-error)\n",
    "\n",
    "[here](https://stackoverflow.com/questions/32674380/countvectorizer-vocabulary-wasnt-fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction: the Adaboost Classifier \n",
    "y_pred = pipeline_ada.predict(X_test)\n",
    "plot_scores(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters = \n",
    "\n",
    "#cv = \n",
    "\n",
    "# Show parameters for the pipline\n",
    "pipeline_rfc.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show parameters for the pipline\n",
    "pipeline_ada.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using grid search\n",
    "# Create Grid search parameters for Random Forest Classifier   \n",
    "parameters_rfc = {\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__estimator__n_estimators': [10, 20]\n",
    "}\n",
    "\n",
    "cv_rfc = GridSearchCV(pipeline_rfc, param_grid = parameters_rfc)\n",
    "cv_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using grid search\n",
    "# Create Grid search parameters\n",
    "parameters_ada = {\n",
    "        'tfidf__use_idf': (True, False),\n",
    "        'clf__estimator__n_estimators': [50, 60, 70]\n",
    "}\n",
    "\n",
    "cv_ada = GridSearchCV(pipeline_ada, param_grid = parameters_ada)\n",
    "cv_ada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pickle file for the model\n",
    "\n",
    "#https://www.codegrepper.com/code-examples/python/save+and+load+python+pickle+stackoverflow\n",
    "#with open('filename.pkl', 'wb') as handle:\n",
    "#    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#with open('filename.pkl', 'rb') as handle:\n",
    "#    b = pickle.load(handle)\n",
    "\n",
    "#Picke documentation\n",
    "#https://docs.python.org/3/library/pickle.html#module-pickle\n",
    "file_name = 'classifier.pkl'\n",
    "with open (file_name, 'wb') as handle: #wb for write+binary\n",
    "    pickle.dump(cv_ada, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import sys\n",
    "\n",
    "def load_data(data_file):\n",
    "    # read in file\n",
    "    # clean data\n",
    "    # load to database\n",
    "    # define features and label arrays\n",
    "    return X, y\n",
    "\n",
    "def build_model():\n",
    "    # text processing and model pipeline\n",
    "    # define parameters for GridSearchCV\n",
    "    # create gridsearch object and return as final model pipeline\n",
    "    return model_pipeline\n",
    "\n",
    "def train(X, y, model):\n",
    "    # train test split\n",
    "    # fit model\n",
    "    # output model test results\n",
    "    return model\n",
    "\n",
    "def export_model(model):\n",
    "    # Export model as a pickle file\n",
    "\n",
    "def run_pipeline(data_file):\n",
    "    X, y = load_data(data_file)  # run ETL pipeline\n",
    "    model = build_model()  # build model pipeline\n",
    "    model = train(X, y, model)  # train model pipeline\n",
    "    export_model(model)  # save model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_file = sys.argv[1]  # get filename of dataset\n",
    "    run_pipeline(data_file)  # run data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "import string\n",
    "\n",
    "\n",
    "# Function to pass the list to the Tf-idf vectorizer\n",
    "def returnPhrase(inputList):\n",
    "    return inputList\n",
    "\n",
    "\n",
    "# Pre-processing the sentence which we input to predict the emotion\n",
    "def transformSentence(sentence):\n",
    "    s = []\n",
    "    sentence = sentence.replace('\\n', '')\n",
    "    sentTokenized = word_tokenize(sentence)\n",
    "    s.append(sentTokenized)\n",
    "    sWithoutPunct = []\n",
    "    punctList = list(string.punctuation)\n",
    "    curSentList = s[0]\n",
    "    newSentList = []\n",
    "    for word in curSentList:\n",
    "        if word.lower() not in punctList:\n",
    "            newSentList.append(word.lower())\n",
    "    sWithoutPunct.append(newSentList)\n",
    "    mystemmer = PorterStemmer()\n",
    "    tokenziedStemmed = []\n",
    "    for i in range(0, len(sWithoutPunct)):\n",
    "        curList = sWithoutPunct[i]\n",
    "        newList = []\n",
    "        for word in curList:\n",
    "            newList.append(mystemmer.stem(word))\n",
    "        tokenziedStemmed.append(newList)\n",
    "    return tokenziedStemmed\n",
    "\n",
    "\n",
    "# Extracting the features for SVM\n",
    "myVectorizer = TfidfVectorizer(analyzer='word', tokenizer=returnPhrase, preprocessor=returnPhrase,\n",
    "                               token_pattern=None,\n",
    "                               ngram_range=(1, 3))\n",
    "\n",
    "# The SVM Model\n",
    "curC = 2  # cost factor in SVM\n",
    "SVMClassifier = svm.LinearSVC(C=curC)\n",
    "\n",
    "filename = 'finalized_model.sav'\n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Input sentence\n",
    "with open('trial_truth_001.txt', 'r') as file:\n",
    "    sent = file.read().replace('\\n', '')\n",
    "\n",
    "transformedTest = transformSentence(sent)\n",
    "\n",
    "X_test = myVectorizer.fit_transform(transformedTest).toarray()\n",
    "Prediction = loaded_model.predict(X_test)\n",
    "\n",
    "# Printing the predicted emotion\n",
    "print(Prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
