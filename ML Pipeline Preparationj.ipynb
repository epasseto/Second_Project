{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "#measuring time and making basic math\n",
    "from time import time\n",
    "import math\n",
    "import numpy as np\n",
    "import udacourse2 #my library for this project!\n",
    "import statistics\n",
    "\n",
    "#my own ETL pipeline\n",
    "#import process_data as pr\n",
    "\n",
    "#dealing with datasets and showing content\n",
    "import pandas as pd\n",
    "#import pprint as pp\n",
    "\n",
    "#SQLAlchemy toolkit\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import pool\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "#natural language toolkit\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#REGEX toolkit\n",
    "import re\n",
    "\n",
    "#Machine Learning preparing/preprocessing toolkits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Machine Learning Feature Extraction tools\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Machine Learning Classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier #need MOClassifier!\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "#Machine Learning Classifiers extra tools\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Machine Learning Metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#pickling tool\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When trying to use NLTK, I took the following error:\n",
    "\n",
    "- the point is - it´s not only about installing a library\n",
    "\n",
    "- you need to install de supporting dictionnaries for doing the tasks\n",
    "\n",
    "- this can be solved quite easilly (in hope that I will find a Portuguese-Brazil dictionnary when I will need to put it in practic in my work)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    LookupError: \n",
    "    **********************************************************************\n",
    "      Resource stopwords not found.\n",
    "      Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "      >>> import nltk\n",
    "      >>> nltk.download('stopwords')\n",
    "  \n",
    "      For more information see: https://www.nltk.org/data.html\n",
    "\n",
    "      Attempted to load corpora/stopwords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    LookupError: \n",
    "    **********************************************************************\n",
    "    Resource stopwords not found.\n",
    "    Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "    >>> import nltk\n",
    "    >>> nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    LookupError: \n",
    "    **********************************************************************\n",
    "    Resource wordnet not found.\n",
    "    Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "    >>> import nltk\n",
    "    >>> nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing tables in my SQLite database: ['Messages']\n"
     ]
    }
   ],
   "source": [
    "#load data from database\n",
    "#setting NullPool prevents a pool, so it is easy to close the database connection\n",
    "#in our case, the DB is so simple, that it looks the best choice\n",
    "#SLQAlchemy documentation\n",
    "#https://docs.sqlalchemy.org/en/14/core/reflection.html\n",
    "engine = create_engine('sqlite:///Messages.db', poolclass=pool.NullPool) #, echo=True)\n",
    "\n",
    "#retrieving tables names from my DB\n",
    "#https://stackoverflow.com/questions/6473925/sqlalchemy-getting-a-list-of-tables\n",
    "inspector = inspect(engine)\n",
    "print('existing tables in my SQLite database:', inspector.get_table_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As my target is Messages table, so I reed this table as a Pandas dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>if_blank</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  Weather update - a cold front from Cuba that c...   \n",
       "\n",
       "                                            original   genre  if_blank  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct         0   \n",
       "\n",
       "   related  request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        1        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing MySQL to Pandas\n",
    "#https://stackoverflow.com/questions/37730243/importing-data-from-a-mysql-database-into-a-pandas-data-frame-including-column-n/37730334\n",
    "#connection_str = 'mysql+pymysql://mysql_user:mysql_password@mysql_host/mysql_db'\n",
    "#connection = create_engine(connection_str)\n",
    "\n",
    "connection = engine.connect()\n",
    "df = pd.read_sql('SELECT * FROM Messages', con=connection)\n",
    "connection.close()\n",
    "\n",
    "df.name = 'df'\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting in X and Y datasets:\n",
    "\n",
    "- X is the **Message** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Weather update - a cold front from Cuba that c...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['message']\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Y is the **Classification** labels\n",
    "\n",
    "- I excluded all my columns that don´t make sense as labels to classify our message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>child_alone</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   related  request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        1        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  child_alone  ...  aid_centers  \\\n",
       "0                  0         0         0            0  ...            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df[df.columns[4:]]\n",
    "Y.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weather update - a cold front from Cuba that could pass over Haiti'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg_text = X.iloc[0]\n",
    "msg_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weather update     a   cold front from cuba s that could pass over haiti  today'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let´s insert some noise to see if it is filtering well\n",
    "msg_text = \"Weather update01 - a 00cold-front from Cuba's that could pass over Haiti' today\"\n",
    "low_text = msg_text.lower()\n",
    "\n",
    "#I need to take only valid words\n",
    "#a basic one (very common in Regex courses classes)\n",
    "gex_text = re.sub(r'[^a-zA-Z]', ' ', low_text)\n",
    "\n",
    "#other tryed sollutions from several sources\n",
    "#re.sub(r'^\\b[^a-zA-Z]\\b', ' ', low_text)\n",
    "#re.sub(r'^/[^a-zA-Z ]/g', ' ', low_text)\n",
    "#re.sub(r'^/[^a-zA-Z0-9 ]/g', ' ', low_text)\n",
    "\n",
    "gex_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found this [here](https://stackoverflow.com/questions/1751301/regex-match-entire-words-only)\n",
    "\n",
    "- '-' passed away, so it´s not so nice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weather update01 - a 00cold-front from cuba's that could pass over haiti' today\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'^/\\b($word)\\b/i', ' ', low_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weather update01 - a 00cold-front from cuba's that could pass over haiti' today\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'^\\b[a-zA-Z]{3}\\b', ' ', low_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weather update01 - a 00cold-front from cuba's that could pass over haiti' today\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'^[a-zA-Z]{3}$', ' ', low_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather',\n",
       " 'update',\n",
       " 'a',\n",
       " 'cold',\n",
       " 'front',\n",
       " 'from',\n",
       " 'cuba',\n",
       " 's',\n",
       " 'that',\n",
       " 'could',\n",
       " 'pass',\n",
       " 'over',\n",
       " 'haiti',\n",
       " 'today']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_words = word_tokenize(gex_text)\n",
    "col_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather',\n",
       " 'update',\n",
       " 'cold',\n",
       " 'front',\n",
       " 'cuba',\n",
       " 'could',\n",
       " 'pass',\n",
       " 'haiti',\n",
       " 'today']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unnuseful = stopwords.words(\"english\")\n",
    "relevant_words = [word for word in col_words if word not in unnuseful]\n",
    "relevant_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed a lot of geographic references. I think they will not be so useful for us. Let´s try to remove them too...\n",
    "\n",
    "References for City at NLKT [here](https://stackoverflow.com/questions/37025872/unable-to-import-city-database-dataset-from-nltk-data-in-anaconda-spyder-windows?rq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.sem.chat80 as ct #.sql_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LookupError: \n",
    "**********************************************************************\n",
    "  Resource city_database not found.\n",
    "  Please use the NLTK Downloader to obtain the resource:\n",
    "\n",
    "  >>> import nltk\n",
    "  >>> nltk.download('city_database')\n",
    "  \n",
    "  For more information see: https://www.nltk.org/data.html\n",
    "\n",
    "  Attempted to load corpora/city_database/city.db\n",
    "\n",
    "  Searched in:\n",
    "    - 'C:\\\\Users\\\\epass/nltk_data'\n",
    "    - 'C:\\\\ProgramData\\\\Anaconda3\\\\nltk_data'\n",
    "    - 'C:\\\\ProgramData\\\\Anaconda3\\\\share\\\\nltk_data'\n",
    "    - 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\nltk_data'\n",
    "    - 'C:\\\\Users\\\\epass\\\\AppData\\\\Roaming\\\\nltk_data'\n",
    "    - 'C:\\\\nltk_data'\n",
    "    - 'D:\\\\nltk_data'\n",
    "    - 'E:\\\\nltk_data'\n",
    "**********************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "#nltk.download('city_database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = {\n",
    "    country:city for city, country in ct.sql_query(\n",
    "        \"corpora/city_database/city.db\",\n",
    "        \"SELECT City, Country FROM city_table\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look nice (and lower cased):\n",
    "    \n",
    "- observe possible errors with composite names, like united_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "greece\n",
      "thailand\n",
      "spain\n",
      "east_germany\n",
      "united_kingdom\n",
      "india\n",
      "belgium\n",
      "romania\n",
      "hungary\n",
      "argentina\n",
      "egypt\n",
      "china\n",
      "venezuela\n",
      "united_states\n",
      "west_germany\n",
      "hongkong\n",
      "turkey\n",
      "indonesia\n",
      "south_africa\n",
      "pakistan\n",
      "soviet_union\n",
      "japan\n",
      "peru\n",
      "philippines\n",
      "australia\n",
      "mexico\n",
      "italy\n",
      "canada\n",
      "france\n",
      "south_korea\n",
      "brazil\n",
      "vietnam\n",
      "chile\n",
      "singapore\n",
      "iran\n",
      "austria\n",
      "poland\n"
     ]
    }
   ],
   "source": [
    "for c in countries:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I couldn't find Haiti:\n",
    "\n",
    "- countries list is not complete!\n",
    "\n",
    "- it gaves `KeyError: 'haiti'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countries['haiti']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather',\n",
       " 'update',\n",
       " 'cold',\n",
       " 'front',\n",
       " 'cuba',\n",
       " 'could',\n",
       " 'pass',\n",
       " 'haiti',\n",
       " 'today']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nogeo_words = [word for word in relevant_words if word not in countries]\n",
    "nogeo_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortatelly, it´s only a **demo**! We need something better for our project..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Umm Al Quwain City</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ras Al Khaimah City</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zayed City</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  City          Region\n",
       "0         les Escaldes  Europe/Andorra\n",
       "1     Andorra la Vella  Europe/Andorra\n",
       "2   Umm Al Quwain City      Asia/Dubai\n",
       "3  Ras Al Khaimah City      Asia/Dubai\n",
       "4           Zayed City      Asia/Dubai"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_cities = pd.read_csv('cities15000.txt', sep=';')\n",
    "df_cities = pd.read_csv('cities15000.txt', sep='\\t', header=None)\n",
    "df_cities_15000 = df_cities[[1, 17]]\n",
    "df_cities_15000.columns = ['City', 'Region']\n",
    "df_cities_15000.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried this [here](https://data.opendatasoft.com/explore/dataset/geonames-all-cities-with-a-population-1000%40public/information/?disjunctive.cou_name_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3040051</td>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>les Escaldes</td>\n",
       "      <td>Ehskal'des-Ehndzhordani,Escaldes,Escaldes-Engo...</td>\n",
       "      <td>42.50729</td>\n",
       "      <td>1.53414</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1033</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2008-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3041563</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>Andorra la Vella</td>\n",
       "      <td>ALV,Ando-la-Vyey,Andora,Andora la Vela,Andora ...</td>\n",
       "      <td>42.50779</td>\n",
       "      <td>1.52109</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLC</td>\n",
       "      <td>AD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1037</td>\n",
       "      <td>Europe/Andorra</td>\n",
       "      <td>2020-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>290594</td>\n",
       "      <td>Umm Al Quwain City</td>\n",
       "      <td>Umm Al Quwain City</td>\n",
       "      <td>Oumm al Qaiwain,Oumm al Qaïwaïn,Um al Kawain,U...</td>\n",
       "      <td>25.56473</td>\n",
       "      <td>55.55517</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "      <td>2019-10-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>291074</td>\n",
       "      <td>Ras Al Khaimah City</td>\n",
       "      <td>Ras Al Khaimah City</td>\n",
       "      <td>Julfa,Khaimah,RAK City,RKT,Ra's al Khaymah,Ra'...</td>\n",
       "      <td>25.78953</td>\n",
       "      <td>55.94320</td>\n",
       "      <td>P</td>\n",
       "      <td>PPLA</td>\n",
       "      <td>AE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>351943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "      <td>2019-09-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291580</td>\n",
       "      <td>Zayed City</td>\n",
       "      <td>Zayed City</td>\n",
       "      <td>Bid' Zayed,Bid’ Zayed,Madinat Za'id,Madinat Za...</td>\n",
       "      <td>23.65416</td>\n",
       "      <td>53.70522</td>\n",
       "      <td>P</td>\n",
       "      <td>PPL</td>\n",
       "      <td>AE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124</td>\n",
       "      <td>Asia/Dubai</td>\n",
       "      <td>2019-10-24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0                    1                    2   \\\n",
       "0  3040051         les Escaldes         les Escaldes   \n",
       "1  3041563     Andorra la Vella     Andorra la Vella   \n",
       "2   290594   Umm Al Quwain City   Umm Al Quwain City   \n",
       "3   291074  Ras Al Khaimah City  Ras Al Khaimah City   \n",
       "4   291580           Zayed City           Zayed City   \n",
       "\n",
       "                                                  3         4         5  6   \\\n",
       "0  Ehskal'des-Ehndzhordani,Escaldes,Escaldes-Engo...  42.50729   1.53414  P   \n",
       "1  ALV,Ando-la-Vyey,Andora,Andora la Vela,Andora ...  42.50779   1.52109  P   \n",
       "2  Oumm al Qaiwain,Oumm al Qaïwaïn,Um al Kawain,U...  25.56473  55.55517  P   \n",
       "3  Julfa,Khaimah,RAK City,RKT,Ra's al Khaymah,Ra'...  25.78953  55.94320  P   \n",
       "4  Bid' Zayed,Bid’ Zayed,Madinat Za'id,Madinat Za...  23.65416  53.70522  P   \n",
       "\n",
       "     7   8    9   10   11   12   13      14  15    16              17  \\\n",
       "0  PPLA  AD  NaN  08  NaN  NaN  NaN   15853 NaN  1033  Europe/Andorra   \n",
       "1  PPLC  AD  NaN  07  NaN  NaN  NaN   20430 NaN  1037  Europe/Andorra   \n",
       "2  PPLA  AE  NaN  07  NaN  NaN  NaN   62747 NaN     2      Asia/Dubai   \n",
       "3  PPLA  AE  NaN  05  NaN  NaN  NaN  351943 NaN     2      Asia/Dubai   \n",
       "4   PPL  AE  NaN  01  103  NaN  NaN   63482 NaN   124      Asia/Dubai   \n",
       "\n",
       "           18  \n",
       "0  2008-10-15  \n",
       "1  2020-03-03  \n",
       "2  2019-10-24  \n",
       "3  2019-09-09  \n",
       "4  2019-10-24  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "found country names at Github [here](https://github.com/lukes/ISO-3166-Countries-with-Regional-Codes/blob/master/all/all.csv)\n",
    "\n",
    "- a small trick and we have our own coutries list!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['afghanistan',\n",
       " 'åland islands',\n",
       " 'albania',\n",
       " 'algeria',\n",
       " 'american samoa',\n",
       " 'andorra',\n",
       " 'angola',\n",
       " 'anguilla',\n",
       " 'antarctica',\n",
       " 'antigua and barbuda',\n",
       " 'argentina',\n",
       " 'armenia',\n",
       " 'aruba',\n",
       " 'australia',\n",
       " 'austria',\n",
       " 'azerbaijan',\n",
       " 'bahamas',\n",
       " 'bahrain',\n",
       " 'bangladesh',\n",
       " 'barbados',\n",
       " 'belarus',\n",
       " 'belgium',\n",
       " 'belize',\n",
       " 'benin',\n",
       " 'bermuda',\n",
       " 'bhutan',\n",
       " 'bolivia (plurinational state of)',\n",
       " 'bonaire, sint eustatius and saba',\n",
       " 'bosnia and herzegovina',\n",
       " 'botswana',\n",
       " 'bouvet island',\n",
       " 'brazil',\n",
       " 'british indian ocean territory',\n",
       " 'brunei darussalam',\n",
       " 'bulgaria',\n",
       " 'burkina faso',\n",
       " 'burundi',\n",
       " 'cabo verde',\n",
       " 'cambodia',\n",
       " 'cameroon',\n",
       " 'canada',\n",
       " 'cayman islands',\n",
       " 'central african republic',\n",
       " 'chad',\n",
       " 'chile',\n",
       " 'china',\n",
       " 'christmas island',\n",
       " 'cocos (keeling) islands',\n",
       " 'colombia',\n",
       " 'comoros',\n",
       " 'congo',\n",
       " 'congo, democratic republic of the',\n",
       " 'cook islands',\n",
       " 'costa rica',\n",
       " \"côte d'ivoire\",\n",
       " 'croatia',\n",
       " 'cuba',\n",
       " 'curaçao',\n",
       " 'cyprus',\n",
       " 'czechia',\n",
       " 'denmark',\n",
       " 'djibouti',\n",
       " 'dominica',\n",
       " 'dominican republic',\n",
       " 'ecuador',\n",
       " 'egypt',\n",
       " 'el salvador',\n",
       " 'equatorial guinea',\n",
       " 'eritrea',\n",
       " 'estonia',\n",
       " 'eswatini',\n",
       " 'ethiopia',\n",
       " 'falkland islands (malvinas)',\n",
       " 'faroe islands',\n",
       " 'fiji',\n",
       " 'finland',\n",
       " 'france',\n",
       " 'french guiana',\n",
       " 'french polynesia',\n",
       " 'french southern territories',\n",
       " 'gabon',\n",
       " 'gambia',\n",
       " 'georgia',\n",
       " 'germany',\n",
       " 'ghana',\n",
       " 'gibraltar',\n",
       " 'greece',\n",
       " 'greenland',\n",
       " 'grenada',\n",
       " 'guadeloupe',\n",
       " 'guam',\n",
       " 'guatemala',\n",
       " 'guernsey',\n",
       " 'guinea',\n",
       " 'guinea-bissau',\n",
       " 'guyana',\n",
       " 'haiti',\n",
       " 'heard island and mcdonald islands',\n",
       " 'holy see',\n",
       " 'honduras',\n",
       " 'hong kong',\n",
       " 'hungary',\n",
       " 'iceland',\n",
       " 'india',\n",
       " 'indonesia',\n",
       " 'iran (islamic republic of)',\n",
       " 'iraq',\n",
       " 'ireland',\n",
       " 'isle of man',\n",
       " 'israel',\n",
       " 'italy',\n",
       " 'jamaica',\n",
       " 'japan',\n",
       " 'jersey',\n",
       " 'jordan',\n",
       " 'kazakhstan',\n",
       " 'kenya',\n",
       " 'kiribati',\n",
       " \"korea (democratic people's republic of)\",\n",
       " 'korea, republic of',\n",
       " 'kuwait',\n",
       " 'kyrgyzstan',\n",
       " \"lao people's democratic republic\",\n",
       " 'latvia',\n",
       " 'lebanon',\n",
       " 'lesotho',\n",
       " 'liberia',\n",
       " 'libya',\n",
       " 'liechtenstein',\n",
       " 'lithuania',\n",
       " 'luxembourg',\n",
       " 'macao',\n",
       " 'madagascar',\n",
       " 'malawi',\n",
       " 'malaysia',\n",
       " 'maldives',\n",
       " 'mali',\n",
       " 'malta',\n",
       " 'marshall islands',\n",
       " 'martinique',\n",
       " 'mauritania',\n",
       " 'mauritius',\n",
       " 'mayotte',\n",
       " 'mexico',\n",
       " 'micronesia (federated states of)',\n",
       " 'moldova, republic of',\n",
       " 'monaco',\n",
       " 'mongolia',\n",
       " 'montenegro',\n",
       " 'montserrat',\n",
       " 'morocco',\n",
       " 'mozambique',\n",
       " 'myanmar',\n",
       " 'namibia',\n",
       " 'nauru',\n",
       " 'nepal',\n",
       " 'netherlands',\n",
       " 'new caledonia',\n",
       " 'new zealand',\n",
       " 'nicaragua',\n",
       " 'niger',\n",
       " 'nigeria',\n",
       " 'niue',\n",
       " 'norfolk island',\n",
       " 'north macedonia',\n",
       " 'northern mariana islands',\n",
       " 'norway',\n",
       " 'oman',\n",
       " 'pakistan',\n",
       " 'palau',\n",
       " 'palestine, state of',\n",
       " 'panama',\n",
       " 'papua new guinea',\n",
       " 'paraguay',\n",
       " 'peru',\n",
       " 'philippines',\n",
       " 'pitcairn',\n",
       " 'poland',\n",
       " 'portugal',\n",
       " 'puerto rico',\n",
       " 'qatar',\n",
       " 'réunion',\n",
       " 'romania',\n",
       " 'russian federation',\n",
       " 'rwanda',\n",
       " 'saint barthélemy',\n",
       " 'saint helena, ascension and tristan da cunha',\n",
       " 'saint kitts and nevis',\n",
       " 'saint lucia',\n",
       " 'saint martin (french part)',\n",
       " 'saint pierre and miquelon',\n",
       " 'saint vincent and the grenadines',\n",
       " 'samoa',\n",
       " 'san marino',\n",
       " 'sao tome and principe',\n",
       " 'saudi arabia',\n",
       " 'senegal',\n",
       " 'serbia',\n",
       " 'seychelles',\n",
       " 'sierra leone',\n",
       " 'singapore',\n",
       " 'sint maarten (dutch part)',\n",
       " 'slovakia',\n",
       " 'slovenia',\n",
       " 'solomon islands',\n",
       " 'somalia',\n",
       " 'south africa',\n",
       " 'south georgia and the south sandwich islands',\n",
       " 'south sudan',\n",
       " 'spain',\n",
       " 'sri lanka',\n",
       " 'sudan',\n",
       " 'suriname',\n",
       " 'svalbard and jan mayen',\n",
       " 'sweden',\n",
       " 'switzerland',\n",
       " 'syrian arab republic',\n",
       " 'taiwan, province of china',\n",
       " 'tajikistan',\n",
       " 'tanzania, united republic of',\n",
       " 'thailand',\n",
       " 'timor-leste',\n",
       " 'togo',\n",
       " 'tokelau',\n",
       " 'tonga',\n",
       " 'trinidad and tobago',\n",
       " 'tunisia',\n",
       " 'turkey',\n",
       " 'turkmenistan',\n",
       " 'turks and caicos islands',\n",
       " 'tuvalu',\n",
       " 'uganda',\n",
       " 'ukraine',\n",
       " 'united arab emirates',\n",
       " 'united kingdom of great britain and northern ireland',\n",
       " 'united states of america',\n",
       " 'united states minor outlying islands',\n",
       " 'uruguay',\n",
       " 'uzbekistan',\n",
       " 'vanuatu',\n",
       " 'venezuela (bolivarian republic of)',\n",
       " 'viet nam',\n",
       " 'virgin islands (british)',\n",
       " 'virgin islands (u.s.)',\n",
       " 'wallis and futuna',\n",
       " 'western sahara',\n",
       " 'yemen',\n",
       " 'zambia',\n",
       " 'zimbabwe']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countries = pd.read_csv('all.csv')\n",
    "df_countries = df_countries['name'].apply(lambda x: x.lower())\n",
    "countries = df_countries.tolist()\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can elliminate (perhaps not the whole) a lot of names of countries. In our case, the produce noise on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weather', 'update', 'cold', 'front', 'could', 'pass', 'today']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nogeo_words = [word for word in relevant_words if word not in countries]\n",
    "nogeo_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First test:\n",
    "    \n",
    "- over the first message only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weather', 'update', 'cold', 'front', 'cuba', 'pass', 'haiti', 'today']\n"
     ]
    }
   ],
   "source": [
    "message = 'Weather update - a cold front from Cuba that could pass over Haiti'\n",
    "tokens = udacourse2.fn_tokenize_fast(msg_text, \n",
    "                                     verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens-start:79, token/stop:9, remove cities:7 &noise:7\n",
      " +lemmatizer:7\n",
      " +eliminate short:7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['update', 'front', 'cold', 'weather', 'today', 'pas', 'could']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = 'Weather update - a cold front from Cuba that could pass over Haiti'\n",
    "tokens = udacourse2.fn_tokenize(msg_text, \n",
    "                                lemmatize=True, \n",
    "                                rem_city=True, \n",
    "                                agg_words=True,\n",
    "                                rem_noise=True,\n",
    "                                elm_short=3,\n",
    "                                verbose=True)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It´s not so cool, some noise is still appearing in lemmatized words:\n",
    "    \n",
    "- an \"l\" was found, as in **French words**, like *l'orange*;\n",
    "\n",
    "- my **City** filter needs a lot of improving, as it didn´t filter avenues and so many other **geographic** references;\n",
    "\n",
    "- it passed a lot of unnuseful **two** or less letters words, as **u**, **st**;\n",
    "\n",
    "- a lot of noisy words as **help**, **thanks**, **please** were found;\n",
    "\n",
    "- there are several words **repetition** in some messages, like ['river', ... 'river', ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic test call\n",
    "\n",
    "- only for the first 50 messages, verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weather', 'update', 'cold', 'front', 'cuba', 'pass', 'haiti']\n",
      "['hurricane']\n",
      "['looking', 'name']\n",
      "['reports', 'leogane', 'destroyed', 'hospital', 'croix', 'functioning', 'needs', 'supplies', 'desperately']\n",
      "['says', 'side', 'haiti', 'rest', 'today', 'tonight']\n",
      "['information', 'national']\n",
      "['storm']\n",
      "['please', 'need', 'tents', 'water', 'silo']\n",
      "['receive', 'messages']\n",
      "['croix', 'des', 'bouquets', 'health', 'issues', 'workers', 'croix', 'des', 'bouquets']\n",
      "['nothing', 'eat', 'water', 'starving', 'thirsty']\n",
      "['petionville', 'need', 'information', 'regarding']\n",
      "['thomassin', 'pyron', 'water', 'desperately', 'need', 'water']\n",
      "['together', 'need', 'food', 'delma', 'didine']\n",
      "['information', 'order', 'participate', 'use']\n",
      "['comitee', 'delmas', 'impasse', 'charite', 'temporary', 'shelter', 'dire', 'need', 'water', 'food', 'medications', 'tents', 'clothes', 'please']\n",
      "['need', 'food', 'water', 'klecin', 'dying', 'hunger', 'impasse', 'chretien', 'klecin', 'extended', 'extension', 'hungry', 'sick']\n",
      "['call', 'want', 'call']\n",
      "['understand', 'use']\n",
      "['earthquake']\n",
      "['radio', 'ginen', 'journalist', 'died']\n",
      "['laplaine', 'victim']\n",
      "['lack', 'water', 'moleya', 'please', 'informed']\n",
      "['live', 'sibert', 'need', 'food', 'hungry']\n",
      "['want', 'faustin', 'anhy', 'nothing', 'food', 'water', 'medicine']\n",
      "['tell']\n",
      "['delma', 'anything', 'ever', 'please', 'provide', 'food', 'water', 'medicine']\n",
      "['gressier', 'needs', 'assistance', 'away', 'help']\n",
      "['water', 'food', 'fontamara', 'cite']\n",
      "['need', 'help', 'carrefour', 'forgotten', 'completely', 'foul', 'odor', 'killing', 'letting']\n",
      "['evening', 'radio', 'please', 'information', 'tiyous']\n",
      "['problem', 'delma', 'albert', 'jode', 'need', 'water', 'food']\n",
      "['find', 'needed', 'pant', 'phone']\n",
      "['sleeping', 'outdoors', 'field', 'lilavois', 'jan', 'coords', 'lilavois', 'apparently', 'pap']\n",
      "['want', 'carrefour', 'need', 'help', 'starving', 'death']\n",
      "['find', 'food', 'water', 'differents', 'needs', 'medicine', 'fontamara', 'cite']\n",
      "['delmas', 'silo', 'need', 'water']\n",
      "['help', 'cote', 'plage', 'carrefour']\n",
      "['leoganes', 'food', 'please']\n",
      "['comite', 'miracle', 'alerte', 'monseigneur', 'guilloux', 'streets', 'alerte', 'mgr', 'guilloux', 'urgently', 'receive', 'food', 'water', 'tents']\n",
      "['dal', 'blocked', 'wednesday', 'carrefour', 'water', 'shortage', 'food', 'medical', 'assistance']\n",
      "['jacmel', 'working', 'dying', 'hunger']\n",
      "['everybody', 'dead']\n",
      "['talk', 'petit', 'goave', 'please', 'look', 'petit', 'goave']\n",
      "['evening', 'earthquake']\n",
      "['fontamara', 'impass', 'pierre', 'louis', 'lots', 'difficulties', 'please', 'help']\n",
      "['evening', 'work', 'strenght', 'listening', 'matisan', 'water', 'food', 'shortage', 'provided', 'upon']\n",
      "['find', 'aid', 'food', 'fontamara', 'carrefour']\n",
      "['listening', 'radio', 'jacmel', 'need', 'help', 'remove', 'dead', 'bodies', 'colege', 'trinite', 'universite', 'bodies', 'professors', 'students']\n",
      "['jacmel', 'requesting', 'tractor', 'civil', 'unrest', 'social', 'disturbance']\n",
      "['asking', 'prayer', 'haiti']\n",
      "['marotiere', 'food', 'water', 'shortage', 'please', 'food']\n",
      "['listening', 'miraguan', 'asking', 'government', 'change', 'gallon', 'gas']\n",
      "['arab']\n",
      "['listening', 'radio', 'jacmel', 'asking', 'help', 'remove', 'dead', 'bodies', 'trinite', 'college', 'university', 'inasmo', 'dead', 'bodies', 'students', 'teachers']\n",
      "['transfert', 'house', 'money', 'haiti']\n",
      "['information', 'found', 'rubbles', 'school', 'trinite', 'ecole', 'sainte', 'trinite', 'jacmel', 'cookies', 'brought', 'colombian', 'dogs', 'keeping', 'alive']\n",
      "['help', 'jacmel']\n",
      "['find', 'help', 'food', 'fontamara', 'menos']\n",
      "['sos', 'sos', 'please', 'provide', 'police', 'officers', 'streets', 'insecure']\n",
      "['mother', 'water', 'provided']\n",
      "['needing', 'water', 'baby', 'beach']\n",
      "['help', 'needed', 'fond', 'parisien', 'idea', 'haitian', 'tell']\n",
      "['asking', 'water', 'medical', 'supply', 'food']\n",
      "['home', 'gressier', 'almost', 'collapsed', 'distroy', 'collapses', 'completly']\n",
      "['food', 'water', 'distributed', 'provided']\n",
      "['happy', 'hear', 'religious', 'hyme']\n",
      "['seven', 'house', 'betwenn', 'musso', 'juvenat', 'dyobel', 'dyobal', 'sure', 'rest', 'information', 'clear']\n",
      "['pastor', 'interpreter', 'seeking', 'help', 'teams']\n",
      "['problem', 'paco', 'lazon', 'police', 'want', 'almost', 'food', 'water']\n",
      "['sainte', 'bernadette', 'areas', 'received', 'anything', 'buying', 'water', 'warm', 'gourdes']\n",
      "['communicate', 'family', 'minutes', 'cell', 'phone', 'please', 'help']\n",
      "['sleeping', 'outside', 'field', 'lilavois', 'dying', 'hunger']\n",
      "['friend', 'dont', 'hear', 'hear', 'news', 'hear', 'happen', 'carrefour', 'petion']\n",
      "['asking', 'help', 'especially', 'sath']\n",
      "['driver', 'mechanic', 'want', 'help']\n",
      "['news', 'found', 'body', 'dead', 'hospitals', 'need', 'checked', 'registry', 'books', 'please', 'help', 'seems']\n",
      "['big', 'problem', 'jacmel', 'left', 'port', 'without', 'food', 'clothes', 'money', 'really', 'critical', 'situation']\n",
      "['receive', 'help', 'communale', 'violence']\n",
      "['food', 'distributed']\n",
      "['play', 'carnaval', 'anbasad', 'camp', 'simple', 'comment', 'creole', 'group', 'anbasad', 'camp', 'refer', 'read', 'cry', 'help']\n",
      "['cold', 'front', 'found', 'cuba', 'morning', 'haiti', 'tomorrow', 'isolated', 'rain', 'showers', 'expected', 'tonight']\n",
      "['give', 'cell', 'cards', 'cell', 'phone', 'minuts', 'find', 'cell', 'phone', 'cards', 'buy']\n",
      "['whoever', 'sees', 'streets', 'wearing', 'white', 'denim', 'skirt', 'printed', 'black', 'shirt', 'hair', 'cornrow']\n",
      "['please', 'need', 'help', 'food', 'toiletries']\n",
      "['weather', 'forcast', 'cold', 'front', 'cuba', 'pass', 'haiti', 'night']\n",
      "['food', 'water', 'mediacation', 'dont', 'tents', 'protect', 'selves', 'using', 'cistern', 'lovation', 'provided']\n",
      "['help']\n",
      "['adjs', 'group', 'house', 'jacmel', 'talking', 'southeast', 'victims', 'suffering', 'especially', 'jacmel', 'something', 'house', 'collapsing', 'sot', 'pop', 'jacmel', 'cut']\n",
      "['request', 'aid', 'services', 'forget', 'south', 'victims', 'suffering']\n",
      "['fort', 'mercredi', 'find', 'food', 'water']\n",
      "['taking', 'guess', 'mix', 'creole', 'french', 'sms', 'understand', 'whos', 'close', 'mounn', 'fort', 'mercredi', 'food', 'water', 'running', 'low', 'problem', 'hurt', 'please', 'help']\n",
      "['fort', 'mercredi', 'wednesday', 'find', 'tents', 'treated', 'water']\n",
      "['whos', 'fort', 'mercredi', 'food', 'water', 'please']\n",
      "['wounded', 'michely', 'hospital', 'medicine', 'looks', 'cut']\n",
      "['martissant', 'dantes']\n",
      "['digicel', 'emergency']\n",
      "['find', 'capital', 'bank', 'please']\n",
      "['plaine', 'sac', 'nearest', 'food', 'distribution']\n",
      "['listening', 'radio', 'dabon', 'need', 'help', 'doctors', 'unable', 'move', 'gas', 'dabon', 'close', 'leogane']\n",
      "['saying', 'stuck', 'presidential', 'pal', 'quake', 'need', 'water', 'says', 'finding', 'water', 'names']\n",
      "['live', 'plaine', 'wife', 'pregnant', 'injured', 'falling', 'blocks', 'walk', 'found', 'anyone', 'help', 'called', 'moya']\n",
      "['member', 'repatriated', 'duvivier', 'fond', 'grango']\n",
      "['urgent', 'action', 'needed', 'follow', 'sms', 'possible', 'delivery', 'possible', 'deliver', 'baby', 'matter']\n",
      "['please', 'add', 'airtime', 'phone']\n",
      "['dire', 'need', 'food', 'water', 'temporary', 'shelter', 'need', 'supplies', 'frere', 'boukan', 'plaine']\n",
      "['damaged', 'gas', 'find', 'motocycle', 'costs', 'port', 'money']\n",
      "['woul', 'aide', 'available', 'pap', 'provinces', 'badly', 'hit']\n",
      "['factory', 'fire', 'airport', 'sogebank', 'starting', 'burn', 'several', 'nearby', 'houses', 'documents', 'left', 'please', 'help']\n",
      "['morning', 'radio', 'victims', 'fonds', 'verettes', 'speak']\n",
      "['contact', 'post', 'radio', 'station', 'representatives', 'assistance']\n",
      "['radio', 'announcers', 'alive']\n",
      "['cold', 'front', 'cuba', 'morning', 'haiti', 'tomorrow', 'isolated', 'rain', 'showers', 'expected']\n",
      "['victims', 'help']\n",
      "['petion', 'water', 'nothing', 'money', 'petion']\n",
      "['port', 'titanyen']\n",
      "['group', 'police', 'found', 'kid', 'anne', 'please', 'rescue']\n",
      "['dans', 'etienne', 'route', 'jacmel', 'est', 'bloqu', 'est', 'trsdifficile', 'rendre', 'jacmel']\n",
      "['hungry', 'streets', 'robbed', 'currently', 'vivi', 'mitchell', 'route', 'freres']\n",
      "['please', 'gravel', 'vob', 'hungry', 'need', 'food']\n",
      "['water', 'today']\n",
      "['muguet', 'route', 'desprez', 'airport']\n",
      "['live', 'pleine', 'sleeping', 'hunger', 'killing']\n",
      "['live', 'plaine', 'sleeping', 'streets', 'house', 'destroyed', 'dying', 'thirst', 'hunger', 'anymore', 'help', 'coming']\n",
      "['lapleine', 'precise', 'carrefour', 'marin']\n",
      "['fire', 'perpetuel', 'secours', 'church', 'please', 'firefighters']\n",
      "['anse', 'pitree', 'house', 'delmas', 'destroyed', 'everything', 'inside', 'went', 'hometown', 'anse', 'help', 'absolutely', 'nothing']\n",
      "['need', 'food', 'medicine', 'lilovois', 'monarque']\n",
      "['place', 'want', 'available', 'spaces', 'tent', 'shelters', 'reason', 'station', 'front', 'house', 'safety', 'thief']\n",
      "['food', 'water', 'distributing', 'food', 'water', 'everywhere', 'need']\n",
      "['galet', 'hungry', 'tabarre', 'american', 'embassy']\n",
      "['commitee', 'nameajeans', 'youth', 'association', 'action', 'society', 'founded', 'september', 'president']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['criminals', 'jacmel', 'asking', 'police']\n",
      "['dying', 'hunger', 'petion']\n",
      "['exactly', 'akay', 'name', 'toman', 'miles', 'kabar', 'name', 'kafou', 'lachomy']\n",
      "['american', 'embassy', 'open', 'tomorrow']\n",
      "['construction', 'firm', 'south', 'african', 'recruited', 'civilians', 'architects', 'stockholders', 'wondering', 'needs', 'moment']\n",
      "['done', 'jacmel', 'trapped', 'underneath', 'rubbles', 'college', 'latriniti', 'help']\n",
      "['enter', 'houses', 'electricity']\n",
      "['need', 'kinds', 'help', 'bon', 'repos', 'route', 'ona', 'vile', 'really', 'need', 'help']\n",
      "['muguet', 'please', 'petion']\n",
      "['please', 'call', 'write', 'need', 'information', 'need', 'help', 'beeing', 'translators', 'food', 'distributors', 'services', 'else']\n",
      "['true', 'political', 'held', 'hinche']\n",
      "['field', 'need', 'speak', 'creole', 'french', 'half', 'english']\n",
      "['unrecognized', 'characterse', 'initial', 'formation', 'accelerated', 'organized', 'menfp', 'financed', 'bid', 'launched', 'truncated']\n",
      "['continues', 'truncated', 'regarding', 'education']\n",
      "['bizoton', 'desperately', 'needs', 'help', 'humiliated']\n",
      "['find', 'car', 'leave']\n",
      "['morning', 'live', 'delmas', 'without', 'water', 'without', 'food', 'finished', 'please', 'something']\n",
      "['carrefour', 'feuille', 'extended', 'need', 'help', 'waiting']\n",
      "['carrefour', 'edh', 'electricity', 'haiti', 'help', 'please']\n",
      "['everyone', 'forget', 'merger', 'water', 'hungry', 'rains', 'die']\n",
      "['digicel', 'problem', 'family', 'call', 'please', 'help']\n",
      "['please', 'humanitarian', 'aid', 'survive', 'delmas', 'musso', 'golf', 'course']\n",
      "['evening', 'carrefour', 'feuill', 'dying', 'hunger', 'ther', 'water', 'pleas', 'help']\n",
      "['need', 'food', 'water', 'stay', 'university', 'kiskeya', 'delams', 'delmas', 'pleas', 'respond']\n",
      "['visa', 'travel']\n",
      "['alot', 'victimes', 'arrived', 'ath', 'marchand', 'desalin', 'nan', 'ranboto', 'hospital', 'enough', 'supplys', 'specialist', 'surgeons', 'looked']\n",
      "['help', 'delmas', 'orchidee', 'thirsty']\n",
      "['want', 'port', 'came', 'cap', 'haitian', 'food', 'eat', 'cap', 'haitien', 'north', 'port']\n",
      "['marc', 'came', 'save', 'lives']\n",
      "['talk', 'earthquake', 'please']\n",
      "['port', 'food', 'need', 'goverment', 'aid', 'international', 'aid', 'thak', 'haiti']\n",
      "['port', 'food', 'need', 'goverment', 'aid', 'international', 'aid', 'thak', 'haiti']\n",
      "['liancourt', 'artibonit', 'recieved', 'alot', 'victimes', 'pap', 'different', 'condition', 'serious', 'pleas', 'help']\n",
      "['live', 'plaine', 'close', 'route', 'national', 'carrefour', 'vencent', 'bary', 'need', 'food', 'water', 'tents']\n",
      "['leogane', 'mathieu', 'abitation', 'communal', 'grand', 'riviere', 'waiting']\n",
      "['top', 'fontamara', 'carrefour', 'top', 'hill', 'label', 'unrecognized', 'characters', 'assistance', 'water', 'food', 'tents', 'medicine']\n",
      "['medicine', 'distributed', 'departments', 'counties', 'hospital']\n",
      "['asking', 'money', 'tranfer', 'offices', 'open', 'money', 'sent']\n",
      "['please', 'nazon', 'sylvio', 'cator', 'need', 'water', 'food', 'truncated']\n",
      "['morning', 'everyone', 'listening', 'miami', 'countries', 'helping', 'wife', 'kids', 'starve', 'death', 'haiti', 'help', 'please', 'help']\n",
      "['delmas', 'need', 'food', 'water', 'clothes', 'house', 'destroyed']\n",
      "['afternoon', 'group', 'bon', 'repo', 'loubens', 'need', 'help', 'sense', 'word', 'nobody', 'thinking', 'please', 'something', 'bye']\n",
      "['please', 'help', 'primati', 'malgro', 'gave', 'stuff', 'fight', 'something', 'hungry', 'thirsty', 'suffering', 'please', 'help']\n",
      "['internet', 'croix', 'des', 'bouquets', 'falaise', 'important', 'open', 'wireless', 'zones', 'everyone', 'laptops']\n",
      "['group', 'rubles', 'solidarite']\n",
      "['delmas', 'problem', 'water']\n",
      "['minutes', 'phone']\n",
      "['lycee', 'philippe', 'guerrier', 'les', 'cayes', 'leave', 'port', 'bad', 'odor', 'conditions', 'life', 'capital', 'need', 'help', 'please']\n",
      "['watch', 'warning', 'bad', 'foul', 'smell', 'coming', 'lingering', 'church', 'yard', 'woolio', 'nway', 'house']\n",
      "['live', 'louis', 'problems', 'place', 'problems', 'port', 'help']\n",
      "['badly', 'wounded', 'eat']\n",
      "['noone', 'visit', 'delmas', 'need', 'food', 'water']\n",
      "['delmas', 'goldstar', 'painson', 'yard', 'need', 'help']\n",
      "['jean', 'rabel', 'nothing', 'eat', 'please', 'port', 'lost', 'everything']\n",
      "['problems', 'cap', 'haitian', 'hospital', 'anymore', 'help', 'please']\n",
      "['need', 'help', 'rescuing', 'rubble', 'caraibean', 'university', 'delmas']\n",
      "['please', 'need', 'humanitarian', 'aid', 'lwes', 'hit', 'badly']\n",
      "['evening', 'please', 'quickly', 'assist', 'homeless', 'victims', 'morin', 'taifer', 'municipality', 'fou', 'carrefour']\n",
      "['cap', 'haitian', 'problems', 'lack', 'food', 'medication', 'housing']\n",
      "['asking', 'united', 'states', 'agents', 'money', 'cap', 'haitian']\n",
      "['brother', 'sister', 'jan', 'rabel', 'dont', 'anyone', 'something', 'population', 'port']\n",
      "['jeremie', 'grand', 'anse', 'boyfriend', 'died', 'months', 'pregnant', 'money', 'whatever', 'deliverance']\n",
      "['delmas', 'silo', 'hit', 'head', 'please', 'help']\n",
      "['leogane', 'mathieu', 'need', 'food', 'water', 'shelter', 'rain']\n",
      "['need', 'organization', 'support', 'hungry', 'need', 'food', 'water']\n",
      "['morning', 'emergency', 'relief', 'called', 'gabyon', 'food', 'water', 'please', 'need', 'help']\n",
      "['haitian', 'husband', 'alive', 'port', 'husband', 'lost', 'work', 'pay', 'family', 'parts', 'usa', 'thereas', 'house', 'still', 'remains', 'house', 'crushed', 'making', 'something']\n",
      "['evening', 'hope', 'keep', 'tortue', 'mind', 'coming', 'island', 'wounded', 'clothes', 'food']\n",
      "['port', 'margot', 'hrs', 'driving', 'cap', 'haitian', 'anything', 'survive', 'dying', 'please', 'help']\n",
      "process time:0 seconds\n"
     ]
    }
   ],
   "source": [
    "b_start = time()\n",
    "\n",
    "i = 0\n",
    "for message in X:\n",
    "    out = udacourse2.fn_tokenize_fast(message, \n",
    "                                      verbose=True)\n",
    "    i += 1\n",
    "    if i > 200: #it´s only for test, you can adjust it!\n",
    "        break\n",
    "\n",
    "b_spent = time() - b_start\n",
    "print('process time:{:.0f} seconds'.format(b_spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another Call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather update - a cold front from Cuba that could pass over Haiti\n",
      "Tokens-start:66, token/stop:8, remove cities:6 &noise:6\n",
      " +lemmatizer:6\n",
      " +eliminate short:6\n",
      " +eliminate noisy from 300:6\n",
      "['update', 'front', 'cold', 'weather', 'pas', 'could']\n",
      "\n",
      "Is the Hurricane over or is it not over\n",
      "Tokens-start:39, token/stop:1, remove cities:1 &noise:1\n",
      " +lemmatizer:1\n",
      " +eliminate short:1\n",
      " +eliminate noisy from 300:1\n",
      "['hurricane']\n",
      "\n",
      "Looking for someone but no name\n",
      "Tokens-start:31, token/stop:3, remove cities:3 &noise:2\n",
      " +lemmatizer:2\n",
      " +eliminate short:2\n",
      " +eliminate noisy from 300:2\n",
      "['looking', 'name']\n",
      "\n",
      "UN reports Leogane 80-90 destroyed. Only Hospital St. Croix functioning. Needs supplies desperately.\n",
      "Tokens-start:100, token/stop:11, remove cities:11 &noise:10\n",
      " +lemmatizer:10\n",
      " +eliminate short:8\n",
      " +eliminate noisy from 300:6\n",
      "['destroyed', 'leogane', 'functioning', 'desperately', 'hospital', 'supply']\n",
      "\n",
      "says: west side of Haiti, rest of the country today and tonight\n",
      "Tokens-start:63, token/stop:8, remove cities:7 &noise:6\n",
      " +lemmatizer:6\n",
      " +eliminate short:6\n",
      " +eliminate noisy from 300:5\n",
      "['say', 'tonight', 'side', 'today', 'rest']\n",
      "\n",
      "Information about the National Palace-\n",
      "Tokens-start:38, token/stop:3, remove cities:3 &noise:2\n",
      " +lemmatizer:2\n",
      " +eliminate short:2\n",
      " +eliminate noisy from 300:1\n",
      "['national']\n",
      "\n",
      "Storm at sacred heart of jesus\n",
      "Tokens-start:30, token/stop:4, remove cities:4 &noise:1\n",
      " +lemmatizer:1\n",
      " +eliminate short:1\n",
      " +eliminate noisy from 300:1\n",
      "['storm']\n",
      "\n",
      "Please, we need tents and water. We are in Silo, Thank you!\n",
      "Tokens-start:59, token/stop:6, remove cities:6 &noise:4\n",
      " +lemmatizer:4\n",
      " +eliminate short:4\n",
      " +eliminate noisy from 300:3\n",
      "['water', 'silo', 'tent']\n",
      "\n",
      "I would like to receive the messages, thank you\n",
      "Tokens-start:47, token/stop:5, remove cities:5 &noise:2\n",
      " +lemmatizer:2\n",
      " +eliminate short:2\n",
      " +eliminate noisy from 300:1\n",
      "['receive']\n",
      "\n",
      "I am in Croix-des-Bouquets. We have health issues. They ( workers ) are in Santo 15. ( an area in Croix-des-Bouquets )\n",
      "Tokens-start:118, token/stop:11, remove cities:11 &noise:7\n",
      " +lemmatizer:7\n",
      " +eliminate short:4\n",
      " +eliminate noisy from 300:4\n",
      "['health', 'bouquet', 'worker', 'issue']\n",
      "\n",
      "There's nothing to eat and water, we starving and thirsty.\n",
      "Tokens-start:58, token/stop:5, remove cities:5 &noise:5\n",
      " +lemmatizer:5\n",
      " +eliminate short:5\n",
      " +eliminate noisy from 300:5\n",
      "['water', 'thirsty', 'nothing', 'starving', 'eat']\n",
      "\n",
      "I am in Petionville. I need more information regarding 4636\n",
      "Tokens-start:59, token/stop:4, remove cities:4 &noise:4\n",
      " +lemmatizer:4\n",
      " +eliminate short:4\n",
      " +eliminate noisy from 300:2\n",
      "['regarding', 'petionville']\n",
      "\n",
      "I am in Thomassin number 32, in the area named Pyron. I would like to have some water. Thank God we are fine, but we desperately need water. Thanks\n",
      "Tokens-start:147, token/stop:15, remove cities:15 &noise:6\n",
      " +lemmatizer:6\n",
      " +eliminate short:5\n",
      " +eliminate noisy from 300:4\n",
      "['water', 'desperately', 'thomassin', 'pyron']\n",
      "\n",
      "Let's do it together, need food in Delma 75, in didine area\n",
      "Tokens-start:59, token/stop:7, remove cities:7 &noise:5\n",
      " +lemmatizer:5\n",
      " +eliminate short:5\n",
      " +eliminate noisy from 300:4\n",
      "['delma', 'together', 'food', 'didine']\n",
      "\n",
      "More information on the 4636 number in order for me to participate. ( To see if I can use it )\n",
      "Tokens-start:94, token/stop:6, remove cities:6 &noise:5\n",
      " +lemmatizer:5\n",
      " +eliminate short:5\n",
      " +eliminate noisy from 300:3\n",
      "['order', 'participate', 'use']\n",
      "\n",
      "A Comitee in Delmas 19, Rue ( street ) Janvier, Impasse Charite #2. We have about 500 people in a temporary shelter and we are in dire need of Water, Food, Medications, Tents and Clothes. Please stop by and see us.\n",
      "Tokens-start:214, token/stop:21, remove cities:21 &noise:16\n",
      " +lemmatizer:16\n",
      " +eliminate short:15\n",
      " +eliminate noisy from 300:11\n",
      "['water', 'clothes', 'impasse', 'medication', 'dire', 'comitee', 'charite', 'temporary', 'shelter', 'food', 'tent']\n",
      "\n",
      "We need food and water in Klecin 12. We are dying of hunger. Impasse Chretien Klecin 12 extended ( extension ) We are hungry and sick.\n",
      "Tokens-start:134, token/stop:13, remove cities:13 &noise:13\n",
      " +lemmatizer:13\n",
      " +eliminate short:12\n",
      " +eliminate noisy from 300:11\n",
      "['water', 'extended', 'dying', 'hungry', 'impasse', 'klecin', 'sick', 'extension', 'chretien', 'food', 'hunger']\n",
      "\n",
      "are you going to call me or do you want me to call ou? let me know?\n",
      "Tokens-start:67, token/stop:7, remove cities:7 &noise:3\n",
      " +lemmatizer:3\n",
      " +eliminate short:1\n",
      " +eliminate noisy from 300:0\n",
      "[]\n",
      "\n",
      "I don't understand how to use this thing 4636.\n",
      "Tokens-start:46, token/stop:3, remove cities:3 &noise:2\n",
      " +lemmatizer:2\n",
      " +eliminate short:2\n",
      " +eliminate noisy from 300:2\n",
      "['understand', 'use']\n",
      "\n",
      "I would like to know if the earthquake is over. Thanks\n",
      "Tokens-start:54, token/stop:5, remove cities:5 &noise:1\n",
      " +lemmatizer:1\n",
      " +eliminate short:1\n",
      " +eliminate noisy from 300:1\n",
      "['earthquake']\n",
      "\n",
      "I would like to know if one of the radio ginen Journalist died?\n",
      "Tokens-start:63, token/stop:8, remove cities:8 &noise:5\n",
      " +lemmatizer:5\n",
      " +eliminate short:5\n",
      " +eliminate noisy from 300:4\n",
      "['ginen', 'died', 'journalist', 'radio']\n",
      "\n",
      "process time:0.3523 seconds\n"
     ]
    }
   ],
   "source": [
    "b_start = time()\n",
    "\n",
    "i = 0\n",
    "for message in X:\n",
    "    print(message)\n",
    "    out = udacourse2.fn_tokenize(message, \n",
    "                                 lemmatize=True, \n",
    "                                 rem_city=True, \n",
    "                                 agg_words=True,\n",
    "                                 rem_noise=True,\n",
    "                                 elm_short=3,\n",
    "                                 great_noisy=True,\n",
    "                                 verbose=True)\n",
    "    print(out)\n",
    "    print()\n",
    "    i += 1\n",
    "    if i > 20: #it´s only for test, you can adjust it!\n",
    "        break\n",
    "\n",
    "b_spent = time() - b_start\n",
    "print('process time:{:.4f} seconds'.format(b_spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don´t try it! (complete tokenizer)\n",
    "\n",
    "- it´s a slow test! (takes like 221 seconds to tokenize all the dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b_start = time()\n",
    "\n",
    "#X_tokens = X.apply(lambda x: udacourse2.fn_tokenize(x, \n",
    "#                                                    lemmatize=True, \n",
    "#                                                    rem_city=True, \n",
    "#                                                    agg_words=True,\n",
    "#                                                    rem_noise=True,\n",
    "#                                                    elm_short=3,\n",
    "#                                                    great_noisy=True,\n",
    "#                                                    verbose=False))\n",
    "\n",
    "#b_spent = time() - b_start\n",
    "#print('process time:{:.0f} seconds'.format(b_spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- it´s a bit faster test (it takes 46 seconds to run)\n",
    "\n",
    "- the secret is that it loops only one time for row, as it condenses all the filters into one loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time:42 seconds\n"
     ]
    }
   ],
   "source": [
    "b_start = time()\n",
    "\n",
    "X_tokens = X.apply(lambda x: udacourse2.fn_tokenize_fast(x, \n",
    "                                                         verbose=False))\n",
    "\n",
    "b_spent = time() - b_start\n",
    "print('process time:{:.0f} seconds'.format(b_spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have a **series** with all my tokenized messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [weather, update, cold, front, cuba, pass, haiti]\n",
       "1                                          [hurricane]\n",
       "2                                      [looking, name]\n",
       "3    [reports, leogane, destroyed, hospital, croix,...\n",
       "4            [says, side, haiti, rest, today, tonight]\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokens.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I can filter it for rows that have an **empty list**:\n",
    "    \n",
    "- solution found [here](https://stackoverflow.com/questions/29100380/remove-empty-lists-in-pandas-series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2522     []\n",
       "2678     []\n",
       "4487     []\n",
       "5347     []\n",
       "5709     []\n",
       "5737     []\n",
       "6152     []\n",
       "6153     []\n",
       "6229     []\n",
       "7190     []\n",
       "7266     []\n",
       "7559     []\n",
       "7751     []\n",
       "7807     []\n",
       "8891     []\n",
       "8901     []\n",
       "9650     []\n",
       "9863     []\n",
       "12221    []\n",
       "12225    []\n",
       "12258    []\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokens[X_tokens.str.len() == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [weather, update, cold, front, cuba, pass, haiti]\n",
       "1                                              [hurricane]\n",
       "2                                          [looking, name]\n",
       "3        [reports, leogane, destroyed, hospital, croix,...\n",
       "4                [says, side, haiti, rest, today, tonight]\n",
       "                               ...                        \n",
       "26240    [training, demonstrated, enhance, micronutrien...\n",
       "26241    [suitable, candidate, selected, ocha, jakarta,...\n",
       "26242    [proshika, operating, cox, bazar, municipality...\n",
       "26243    [women, protesting, conduct, elections, tearga...\n",
       "26244    [radical, shift, thinking, came, result, meeti...\n",
       "Name: message, Length: 26224, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser2 = X_tokens[X_tokens.str.len() > 0]\n",
    "ser2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time:0 seconds\n"
     ]
    }
   ],
   "source": [
    "b_start = time()\n",
    "\n",
    "dic_tokens = udacourse2.fn_subcount_lists(column=X_tokens, \n",
    "                                          verbose=False)\n",
    "\n",
    "b_spent = time() - b_start\n",
    "print('process time:{:.0f} seconds'.format(b_spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorted dictionnary [here](https://stackoverflow.com/questions/613183/how-do-i-sort-a-dictionary-by-value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data processed\n"
     ]
    }
   ],
   "source": [
    "dic_tokens\n",
    "\n",
    "d_tokens = dic_tokens['elements']\n",
    "t_sorted = sorted(d_tokens.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "if t_sorted:\n",
    "    print('data processed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorted list of tuples of most counted tokens:\n",
    "\n",
    "- filtering the more counted 300 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('water', 2930),\n",
       " ('food', 2799),\n",
       " ('help', 2623),\n",
       " ('need', 2162),\n",
       " ('please', 2051),\n",
       " ('earthquake', 1802),\n",
       " ('haiti', 1043),\n",
       " ('government', 993),\n",
       " ('areas', 979),\n",
       " ('sandy', 927),\n",
       " ('find', 917),\n",
       " ('information', 856),\n",
       " ('relief', 812),\n",
       " ('aid', 778),\n",
       " ('affected', 758),\n",
       " ('health', 753),\n",
       " ('children', 662),\n",
       " ('work', 593),\n",
       " ('million', 583),\n",
       " ('emergency', 580),\n",
       " ('flood', 568),\n",
       " ('supplies', 550),\n",
       " ('tents', 550),\n",
       " ('want', 549),\n",
       " ('give', 541),\n",
       " ('international', 535),\n",
       " ('power', 525),\n",
       " ('house', 522),\n",
       " ('last', 520),\n",
       " ('rain', 507),\n",
       " ('rains', 506),\n",
       " ('still', 485),\n",
       " ('hurricane', 484),\n",
       " ('hit', 479),\n",
       " ('heavy', 479),\n",
       " ('disaster', 472),\n",
       " ('school', 469),\n",
       " ('support', 468),\n",
       " ('storm', 457),\n",
       " ('santiago', 450),\n",
       " ('assistance', 446),\n",
       " ('medical', 441),\n",
       " ('shelter', 436),\n",
       " ('floods', 428),\n",
       " ('victims', 427),\n",
       " ('families', 427),\n",
       " ('destroyed', 425),\n",
       " ('south', 425),\n",
       " ('family', 424),\n",
       " ('live', 423),\n",
       " ('national', 412),\n",
       " ('north', 410),\n",
       " ('houses', 409),\n",
       " ('port', 400),\n",
       " ('united', 396),\n",
       " ('years', 391),\n",
       " ('job', 383),\n",
       " ('high', 380),\n",
       " ('days', 376),\n",
       " ('living', 374),\n",
       " ('first', 367),\n",
       " ('red', 367),\n",
       " ('weather', 356),\n",
       " ('anything', 354),\n",
       " ('community', 352),\n",
       " ('flooding', 352),\n",
       " ('homes', 351),\n",
       " ('river', 351),\n",
       " ('provide', 349),\n",
       " ('notes', 347),\n",
       " ('quake', 344),\n",
       " ('pakistan', 341),\n",
       " ('needs', 335),\n",
       " ('care', 332),\n",
       " ('villages', 326),\n",
       " ('reported', 326),\n",
       " ('working', 324),\n",
       " ('caused', 324),\n",
       " ('humanitarian', 322),\n",
       " ('conditions', 320),\n",
       " ('distribution', 317),\n",
       " ('situation', 313),\n",
       " ('team', 313),\n",
       " ('tsunami', 313),\n",
       " ('hospital', 310),\n",
       " ('left', 310),\n",
       " ('tent', 307),\n",
       " ('thousands', 307),\n",
       " ('today', 306),\n",
       " ('development', 306),\n",
       " ('received', 305),\n",
       " ('nations', 298),\n",
       " ('security', 297),\n",
       " ('damaged', 296),\n",
       " ('drought', 296),\n",
       " ('efforts', 295),\n",
       " ('place', 292),\n",
       " ('women', 292),\n",
       " ('countries', 291),\n",
       " ('lost', 290),\n",
       " ('major', 290),\n",
       " ('damage', 287),\n",
       " ('crops', 287),\n",
       " ('call', 284),\n",
       " ('disease', 284),\n",
       " ('important', 283),\n",
       " ('central', 283),\n",
       " ('rice', 283),\n",
       " ('chile', 283),\n",
       " ('without', 280),\n",
       " ('morning', 280),\n",
       " ('roads', 280),\n",
       " ('news', 278),\n",
       " ('several', 277),\n",
       " ('authorities', 274),\n",
       " ('killed', 274),\n",
       " ('provided', 273),\n",
       " ('home', 273),\n",
       " ('system', 270),\n",
       " ('use', 264),\n",
       " ('nothing', 259),\n",
       " ('population', 258),\n",
       " ('officials', 256),\n",
       " ('season', 256),\n",
       " ('rainfall', 256),\n",
       " ('hygiene', 254),\n",
       " ('following', 253),\n",
       " ('diseases', 252),\n",
       " ('severe', 251),\n",
       " ('needed', 250),\n",
       " ('land', 250),\n",
       " ('public', 249),\n",
       " ('military', 249),\n",
       " ('china', 249),\n",
       " ('parts', 248),\n",
       " ('blankets', 247),\n",
       " ('winter', 247),\n",
       " ('risk', 243),\n",
       " ('providing', 239),\n",
       " ('communities', 239),\n",
       " ('rescue', 238),\n",
       " ('districts', 238),\n",
       " ('capital', 237),\n",
       " ('tell', 236),\n",
       " ('workers', 234),\n",
       " ('drinking', 234),\n",
       " ('life', 233),\n",
       " ('cyclone', 233),\n",
       " ('open', 231),\n",
       " ('project', 231),\n",
       " ('supply', 229),\n",
       " ('coming', 229),\n",
       " ('items', 229),\n",
       " ('continue', 226),\n",
       " ('africa', 226),\n",
       " ('facilities', 226),\n",
       " ('dead', 225),\n",
       " ('crop', 225),\n",
       " ('systems', 225),\n",
       " ('possible', 224),\n",
       " ('residents', 224),\n",
       " ('large', 223),\n",
       " ('away', 222),\n",
       " ('night', 222),\n",
       " ('equipment', 222),\n",
       " ('farmers', 222),\n",
       " ('evening', 220),\n",
       " ('services', 220),\n",
       " ('died', 219),\n",
       " ('electricity', 219),\n",
       " ('problems', 219),\n",
       " ('month', 218),\n",
       " ('early', 218),\n",
       " ('found', 217),\n",
       " ('sanitation', 217),\n",
       " ('schools', 216),\n",
       " ('kits', 216),\n",
       " ('production', 216),\n",
       " ('island', 215),\n",
       " ('hunger', 214),\n",
       " ('card', 213),\n",
       " ('building', 212),\n",
       " ('expected', 211),\n",
       " ('recent', 211),\n",
       " ('human', 207),\n",
       " ('states', 206),\n",
       " ('months', 206),\n",
       " ('provinces', 204),\n",
       " ('camps', 204),\n",
       " ('problem', 203),\n",
       " ('money', 203),\n",
       " ('temporary', 202),\n",
       " ('sent', 202),\n",
       " ('delmas', 199),\n",
       " ('hungry', 199),\n",
       " ('police', 199),\n",
       " ('ask', 199),\n",
       " ('displaced', 198),\n",
       " ('asking', 197),\n",
       " ('reports', 196),\n",
       " ('bring', 196),\n",
       " ('programme', 196),\n",
       " ('afghanistan', 196),\n",
       " ('coast', 195),\n",
       " ('ground', 195),\n",
       " ('unicef', 195),\n",
       " ('group', 194),\n",
       " ('safe', 194),\n",
       " ('receive', 193),\n",
       " ('eat', 193),\n",
       " ('cold', 192),\n",
       " ('carrefour', 192),\n",
       " ('sleep', 192),\n",
       " ('survivors', 192),\n",
       " ('access', 192),\n",
       " ('groups', 192),\n",
       " ('india', 192),\n",
       " ('answer', 190),\n",
       " ('baby', 189),\n",
       " ('poor', 187),\n",
       " ('snow', 187),\n",
       " ('clothing', 186),\n",
       " ('activities', 186),\n",
       " ('monsoon', 186),\n",
       " ('office', 185),\n",
       " ('clean', 185),\n",
       " ('sleeping', 184),\n",
       " ('agricultural', 184),\n",
       " ('air', 183),\n",
       " ('cases', 183),\n",
       " ('per', 182),\n",
       " ('phone', 181),\n",
       " ('camp', 181),\n",
       " ('something', 181),\n",
       " ('organization', 180),\n",
       " ('refugees', 180),\n",
       " ('buildings', 180),\n",
       " ('love', 179),\n",
       " ('control', 179),\n",
       " ('worst', 177),\n",
       " ('shelters', 176),\n",
       " ('political', 176),\n",
       " ('agriculture', 176),\n",
       " ('result', 176),\n",
       " ('hundreds', 176),\n",
       " ('available', 175),\n",
       " ('waiting', 175),\n",
       " ('agency', 175),\n",
       " ('march', 175),\n",
       " ('include', 175),\n",
       " ('percent', 175),\n",
       " ('operations', 175),\n",
       " ('able', 174),\n",
       " ('center', 173),\n",
       " ('addition', 173),\n",
       " ('temperatures', 172),\n",
       " ('members', 171),\n",
       " ('october', 171),\n",
       " ('fire', 170),\n",
       " ('lives', 170),\n",
       " ('staff', 170),\n",
       " ('based', 170),\n",
       " ('natural', 170),\n",
       " ('weeks', 169),\n",
       " ('aceh', 169),\n",
       " ('death', 168),\n",
       " ('training', 168),\n",
       " ('clothes', 167),\n",
       " ('distributed', 167),\n",
       " ('teams', 165),\n",
       " ('president', 165),\n",
       " ('program', 165),\n",
       " ('report', 165),\n",
       " ('cause', 164),\n",
       " ('indonesia', 164),\n",
       " ('construction', 163),\n",
       " ('far', 163),\n",
       " ('regions', 163),\n",
       " ('minister', 163),\n",
       " ('winds', 162),\n",
       " ('army', 161),\n",
       " ('strong', 161),\n",
       " ('infrastructure', 161),\n",
       " ('climate', 161),\n",
       " ('crisis', 160),\n",
       " ('coastal', 160),\n",
       " ('levels', 160),\n",
       " ('change', 159),\n",
       " ('tons', 159),\n",
       " ('massive', 159),\n",
       " ('resources', 159),\n",
       " ('increased', 158),\n",
       " ('livestock', 158),\n",
       " ('especially', 156),\n",
       " ('called', 156),\n",
       " ('magnitude', 156),\n",
       " ('treatment', 156),\n",
       " ('scale', 156),\n",
       " ('agencies', 156),\n",
       " ('capacity', 156)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_sorted[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifying the **tokenize** function just to absorve less meaningful tokens to discard:\n",
    "    \n",
    "- **ver 1.2** update: tokenizer function created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "great_noisy = ['people', 'help', 'need', 'said', 'country', 'government', 'one', 'year', 'good', 'day',\n",
    "    'two', 'get', 'message', 'many', 'region', 'city', 'province', 'road', 'district', 'including', 'time',\n",
    "    'new', 'still', 'due', 'local', 'part', 'problem', 'may', 'take', 'come', 'effort', 'note', 'around',\n",
    "    'person', 'lot', 'already', 'situation', 'see', 'response', 'even', 'reported', 'caused', 'village', 'bit',\n",
    "    'made', 'way', 'across', 'west', 'never', 'southern', 'january', 'least', 'zone', 'small', 'next', 'little',\n",
    "    'four', 'must', 'non', 'used', 'five', 'wfp', 'however', 'com', 'set', 'every', 'think', 'item', 'yet', \n",
    "    'carrefour', 'asking', 'ask', 'site', 'line', 'put', 'unicef', 'got', 'east', 'june', 'got', 'ministry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Older atempt to clear tokens\n",
    "\n",
    "Tried to isolate some words that I think are noisy, for exclusion:\n",
    "    \n",
    "- general geographic references, as **area** and **village**;\n",
    "\n",
    "- social communication words, as **thanks** and **please**;\n",
    "\n",
    "- religious ways to talk, as **pray**\n",
    "\n",
    "- unmeaningful words, as **thing** and **like**\n",
    "\n",
    "- visually filtered some words that I think don´t aggregate too much to the **Machine Learning**\n",
    "\n",
    "- just think about - you prefer your **IA** trained for 'thanks' or for 'hurricane'?\n",
    "\n",
    "- really I´m not 100% sure about these words, buy my **tokenize** function can enable and disable this list, and re-train the machine, and see if the performance increase or decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "unhelpful_words = ['thank', 'thanks', 'god', 'fine', 'number', 'area', 'let', 'stop', 'know', 'going', 'thing',\n",
    "    'would', 'hello', 'say', 'neither', 'right', 'asap', 'near', 'want', 'also', 'like', 'since', 'grace', \n",
    "    'congratulate', 'situated', 'tell', 'almost', 'hyme', 'sainte', 'croix', 'ville', 'street', 'valley', 'section',\n",
    "    'carnaval', 'rap', 'cry', 'location', 'ples', 'bless', 'entire', 'specially',  'sorry', 'saint', 'village', \n",
    "    'located', 'palace', 'might', 'given']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing **elliminate duplicates**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addon', 'place']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ['addon', 'place', 'addon']\n",
    "test = list(set(test))\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing **elliminate short words**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elliminate: l\n",
      "elliminate: us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['addon', 'place']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min = 3\n",
    "list2 = []\n",
    "test2 = ['addon', 'l', 'us', 'place']\n",
    "\n",
    "for word in test2:\n",
    "    if len(word) < min:\n",
    "        print('elliminate:', word)\n",
    "    else: \n",
    "        list2.append(word)\n",
    "    \n",
    "list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solution [here](https://stackoverflow.com/questions/3501382/checking-whether-a-variable-is-an-integer-or-not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "if isinstance(min, int):\n",
    "    print('OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have two **Tokenizer** functions:\n",
    "\n",
    "- `fn_tokenize` $\\rightarrow$ it allows to test each individual methods, and contains all the methods described, but a bit slow, as it iterates all the words again for each method\n",
    "\n",
    "- `fn_tokenize_fast` $\\rightarrow$ it is a **boosted** version, with only one iteration, for running faster, but you cannot set each method individually for more accurate test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### A small review over each item for our first machine learning pipelines\n",
    "\n",
    "#### Feature Extraction\n",
    "\n",
    "Feature Extraction from SKlearn documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
    "\n",
    "\"Convert a collection of text documents to a matrix of token counts\"\n",
    "\n",
    "- we are looking for **tokens** that will be turned into **vectors** in a Machine Learning Model;\n",
    "\n",
    "- they are represented as **scalars** in a **matrix**, that indicates the scale of each one of these tokens.\n",
    "\n",
    "\"This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix.\"\n",
    "\n",
    "- normally matrix representations of the natural reallity are a bit **sparse**\n",
    "\n",
    "- in this case, to save some memory, they indicate a use of a propper representation\n",
    "\n",
    "\"If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data.\"\n",
    "\n",
    "- me already made it, drastically reducing the **variability** of terms\n",
    "\n",
    "- it its represented by our **fn_tokenizer**\n",
    "\n",
    "#### Preprocessing\n",
    "\n",
    "TF-IDF from SKlearn documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html)\n",
    "\n",
    "- **tf** is about **term frequency** and;\n",
    "\n",
    "- **idf** is about **inverse document frequency**.\n",
    "\n",
    "\"Transform a count matrix to a normalized tf or tf-idf representation\"\n",
    "\n",
    "- it means that it basically **normalizes** the count matrix\n",
    "\n",
    "*Tf means term-frequency while tf-idf means term-frequency times inverse document-frequency. This is a common term weighting scheme in information retrieval, that has also found good use in document classification.*\n",
    "\n",
    "- it takes term-frequency and it **rescales** it by the gereral document-frequency\n",
    "\n",
    "*The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus.*\n",
    "\n",
    "- the idea is to not weight too much a **noisy** and very frequent word\n",
    "\n",
    "- we tried to \"manually\" elliminate some of the **noisy** words, but as the number of tokens is too high, it´s quite impossible to make a good job\n",
    "\n",
    "#### Training a Machine Learning\n",
    "\n",
    "As we have **labels**, a good strategy is to use **supervised learning**\n",
    "\n",
    "- we could try to kind of make **clusters** of messages, using **unsupervised learning**, or try some strategy on **semi-supervised learning**, as we have some of the messages (40) that don´t have any classification;\n",
    "\n",
    "- the most obvious way is to train a **Classifier**;\n",
    "\n",
    "- as we have multiple labels, a **Multi Target Classifier** seems to be the better choice.\n",
    "\n",
    "Multi target classification [here](https://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html)\n",
    "\n",
    "\"This strategy consists of fitting one classifier per target. This is a simple strategy for extending classifiers that do not natively support multi-target classification\"\n",
    "\n",
    "- OK, we will be basically using **slices** of train for each feature, as we don´t have so much **Machines** that are natively supporting multi-target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Prepare the data\n",
    "\n",
    "Make the lasts opperations for preparing the dataset for training on **Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For **training** data, it is a **data inconsistency** if you consider that all the labels are blank\n",
    "\n",
    "- so we have 6,317 rows that we need to **remove** before **training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all labels are blank in 6317 rows\n"
     ]
    }
   ],
   "source": [
    "print('all labels are blank in {} rows'.format(df[df['if_blank'] == 1].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19928"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['if_blank'] == 0]\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying if removal was complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removal complete!\n"
     ]
    }
   ],
   "source": [
    "if df[df['if_blank'] == 1].shape[0] == 0:\n",
    "    print('removal complete!')\n",
    "else:\n",
    "    raise Exception('something went wrong with rows removal before training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version 1.3** update: **pre-tokenizer** (a premature tokenization strategy) created, for removing **untrainable rows**\n",
    "\n",
    "What is this **crazy thing** over here? \n",
    "\n",
    ">- I created a **provisory** column, and **tokenizing** it\n",
    ">- Why I need it for now? Just for removing rows that are **impossible to train**\n",
    ">- After tokenization, if I get a **empty list**, I need to remove this row before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "process time:34 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>if_blank</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>[weather, update, cold, front, cuba, pass, haiti]</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  \\\n",
       "0  Weather update - a cold front from Cuba that c...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [weather, update, cold, front, cuba, pass, haiti]   \n",
       "\n",
       "                                            original   genre  if_blank  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct         0   \n",
       "\n",
       "   related  request  offer  aid_related  medical_help  ...  aid_centers  \\\n",
       "0        1        0      0            0             0  ...            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "try:\n",
    "    df = df.drop('tokenized', axis=1)\n",
    "except KeyError:\n",
    "    print('OK')\n",
    "\n",
    "#inserting a provisory column\n",
    "df.insert(1, 'tokenized', np.nan)\n",
    "\n",
    "#tokenizing over the provisory\n",
    "df['tokenized'] = df.apply(lambda x: udacourse2.fn_tokenize_fast(x['message']), axis=1)\n",
    "\n",
    "#removing NaN over provisory (if istill exist)\n",
    "df = df[df['tokenized'].notnull()]\n",
    "\n",
    "spent = time() - start\n",
    "print('process time:{:.0f} seconds'.format(spent))\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering empy lists on `provisory`, found [here](https://stackoverflow.com/questions/42964724/pandas-filter-out-column-values-containing-empty-list)\n",
    "\n",
    "**Version 1.4** update: could absorb **pre-tokenized** column as a input for **Machine Learning Classifier**, saving time!\n",
    "\n",
    "And another **crazy thing**, I regret about removing `provisory` tokenized column:\n",
    "\n",
    ">- why? Just because I already **trained** my **X** subdataset, o I will not need to do it later!\n",
    ">- and if I make the thing **wizely**, I will accelerate the pipeline process, as I already made the hard job for the **CountVectorized**\n",
    ">- it will also faccilitate to **train** diverse Classifiers, as I save a lot of individual processing, making it **early** in my process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 6 rows with no tokens\n",
      "*after removal, found 0 rows with no tokens\n",
      "now I have 19922 rows to train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>if_blank</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[weather, update, cold, front, cuba, pass, haiti]</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tokenized  \\\n",
       "0  [weather, update, cold, front, cuba, pass, haiti]   \n",
       "\n",
       "                                            original   genre  if_blank  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct         0   \n",
       "\n",
       "   related  request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        1        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_tokens = df[df['tokenized'].apply(lambda x: len(x)) == 0].shape[0]\n",
    "print('found {} rows with no tokens'.format(empty_tokens))\n",
    "\n",
    "df = df[df['tokenized'].apply(lambda x: len(x)) > 0]\n",
    "empty_tokens = df[df['tokenized'].apply(lambda x: len(x)) == 0].shape[0]\n",
    "print('*after removal, found {} rows with no tokens'.format(empty_tokens))\n",
    "\n",
    "#I will not drop it anymore!\n",
    "#try:\n",
    "#    df = df.drop('provisory', axis=1)\n",
    "#except KeyError:\n",
    "#    print('OK')\n",
    "\n",
    "#Instead, I will drop 'message' column\n",
    "try:\n",
    "    df = df.drop('message', axis=1)\n",
    "except KeyError:\n",
    "    print('OK')\n",
    "\n",
    "print('now I have {} rows to train'.format(df.shape[0]))\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Database data inconsistency fix\n",
    "\n",
    "**Version 1.5** update - added **hierarchical structure** on labels, for checking and correcting unfilled classes that already have at least one subclass alredy filled\n",
    "\n",
    "A **more advanced** issue about these data\n",
    "\n",
    "A more detailed explanation, you can found at the file `ETL Pipeline Preparatione.ipynb`\n",
    "\n",
    "The fact is: \n",
    "\n",
    ">- these labels are not **chaotic** as we initially think they are\n",
    ">- looking with care, we can see a very clear **hierarchic structure** on them\n",
    ">- it they are really hierarchized, so, we can verify them for **data inconsistencies**, using **database fundamentals**\n",
    "\n",
    "---\n",
    "\n",
    "#### Another viewpoint about these labels\n",
    "\n",
    "If we look at them more carefully, we can find a curious pattern on them\n",
    "\n",
    "These labels looks as they have a kind of hierarchy behind their shape, as:\n",
    "\n",
    "First **hierarchical** class: \n",
    "\n",
    ">- **related**\n",
    ">- **request**\n",
    ">- **offer**\n",
    ">- **direct_report**\n",
    "\n",
    "And then, **related** seems to have a **Second** hierarchical class\n",
    "\n",
    "Features for considering a training a classifier on **two layes**, or to **group** them all in main groups, as they are clearly **collinear**:\n",
    "\n",
    ">- **aid_related** $\\rightarrow$ groups aid calling (new things to add/ to do **after** the disaster)\n",
    ">>- **food**\n",
    ">>- **shelter**\n",
    ">>- **water**\n",
    ">>- **death**\n",
    ">>- **refugees**\n",
    ">>- **money**\n",
    ">>- **security**\n",
    ">>- **military**\n",
    ">>- **clothing**\n",
    ">>- **tools**\n",
    ">>- **missing_people**\n",
    ">>- **child_alone**\n",
    ">>- **search_and_rescue**\n",
    ">>- **medical_help**\n",
    ">>- **medical_products**\n",
    ">>- **aid_centers**\n",
    ">>- **other_aid**\n",
    ">- **weather_related** $\\rightarrow$ groups what was the main **cause** of the disaster\n",
    ">>- **earthquake**\n",
    ">>- **storm**\n",
    ">>- **floods**\n",
    ">>- **fire**\n",
    ">>- **cold**\n",
    ">>- **other_weather**\n",
    ">- **infrastructure_related** $\\rightarrow$ groups **heavy infra** that was probably dammaged during the disaster\n",
    ">>- **buildings**\n",
    ">>- **transport**\n",
    ">>- **hospitals**\n",
    ">>- **electricity**\n",
    ">>- **shops**\n",
    ">>- **other_infrastructure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying a correction for **database data consistency**:\n",
    "\n",
    ">- using the function that I already created (see: `ETL Pipeline Preparatione.ipynb`)\n",
    ">- the idea is when at least some element of a **subcategory** is filled for one **category**, it is expected that the **category** was filled too\n",
    ">- this is valido for the main category **related** too!\n",
    "\n",
    "*This is only one more **advanced step** for **data preparation**, as it involves only a mechanic and automatized correction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###function group_check started\n",
      "  - count for main class:aid_related, 10877 entries\n",
      "  - for main, without any sub-categories,  3515 entries\n",
      "  - for subcategories,  7388 entries\n",
      "  - for lost parent sub-categories,  26 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.1971s\n",
      "###function group_check started\n",
      "  - count for main class:weather_related, 7304 entries\n",
      "  - for main, without any sub-categories,  1359 entries\n",
      "  - for subcategories,  5945 entries\n",
      "  - for lost parent sub-categories,  0 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0794s\n",
      "###function group_check started\n",
      "  - count for main class:infrastructure_related, 1705 entries\n",
      "  - for main, without any sub-categories,  679 entries\n",
      "  - for subcategories,  2926 entries\n",
      "  - for lost parent sub-categories,  1900 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0848s\n",
      "###function group_check started\n",
      "  - count for main class:related, 19922 entries\n",
      "  - for main, without any sub-categories,  9436 entries\n",
      "  - for subcategories,  10486 entries\n",
      "  - for lost parent sub-categories,  0 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0709s\n",
      "(19922, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>if_blank</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[weather, update, cold, front, cuba, pass, haiti]</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tokenized  \\\n",
       "0  [weather, update, cold, front, cuba, pass, haiti]   \n",
       "\n",
       "                                            original   genre  if_blank  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct         0   \n",
       "\n",
       "   related  request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        1        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#correction for aid_related\n",
    "df = udacourse2.fn_group_check(dataset=df,\n",
    "                               subset='aid',\n",
    "                               correct=True, \n",
    "                               shrink=False, \n",
    "                               shorten=False, \n",
    "                               verbose=True)\n",
    "#correction for weather_related\n",
    "df = udacourse2.fn_group_check(dataset=df,\n",
    "                               subset='wtr',\n",
    "                               correct=True, \n",
    "                               shrink=False, \n",
    "                               shorten=False, \n",
    "                               verbose=True)\n",
    "#correction for infrastrucutre_related\n",
    "df = udacourse2.fn_group_check(dataset=df,\n",
    "                               subset='ifr',\n",
    "                               correct=True, \n",
    "                               shrink=False, \n",
    "                               shorten=False, \n",
    "                               verbose=True)\n",
    "#correction for related(considering that the earlier were already corrected)\n",
    "df = udacourse2.fn_group_check(dataset=df,\n",
    "                               subset='main',\n",
    "                               correct=True, \n",
    "                               shrink=False, \n",
    "                               shorten=False, \n",
    "                               verbose=True)\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Break the data\n",
    "\n",
    "Break the dataset into the **training columns** and **labels** (if it have **multilabels**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is the **Training Text Column**:\n",
    "    \n",
    "- if I observe the potential training data really well, I could `genre` column as training data too!\n",
    "\n",
    "- or I can use also `related`, `request`, `offer` columns for training `aid_related` data\n",
    "\n",
    "*A discussion of how much these **Label** columns are **hierarchically defined** is made laterly in this notebook*\n",
    "\n",
    "---\n",
    "\n",
    "For this moment, I am using only `message` as training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [weather, update, cold, front, cuba, pass, haiti]\n",
       "Name: tokenized, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['tokenized']\n",
    "X.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y is constituted by the **Classification Labels**\n",
    "\n",
    "**Version 1.6** update: removed `related` column from the Labels dataset. Why? Because when I go to statistics after training the **Machine Learning Classifier**, it turns allways at `1`. So, sometimes this coluimn (like in Adaboost) is causing problems when training our Classifier, and adding nothing to the model\n",
    "\n",
    ">- was: `y = df[df.columns[4:]]`\n",
    ">- now: `y = df[df.columns[5:]]`\n",
    "\n",
    "**Version 1.7** update: removed columns that contains **only zeroes**. Why? Just because they are **impossible to train** on our Classifier!, so they add nothing to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*child_alone -> only zeroes training column!\n",
      "['child_alone']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        0      0            0             0                 0   \n",
       "\n",
       "   search_and_rescue  security  military  water  food  ...  aid_centers  \\\n",
       "0                  0         0         0      0     0  ...            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[df.columns[5:]]\n",
    "\n",
    "remove_lst = []\n",
    "\n",
    "for column in y.columns:\n",
    "    col = y[column]\n",
    "    if (col == 0).all():\n",
    "        print('*{} -> only zeroes training column!'.format(column))\n",
    "        remove_lst.append(column)\n",
    "    else:\n",
    "        #print('*{} -> column OK'.format(column))\n",
    "        pass\n",
    "print(remove_lst)\n",
    "\n",
    "y = y.drop(remove_lst, axis=1)\n",
    "\n",
    "y.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Split the data \n",
    "\n",
    "Into **Train** and **Test** subdatasets\n",
    "\n",
    ">- let´s start it with **20%** of test data\n",
    ">- I am not using **random_state** settings (and why **42**? I personally think it is about a reference to the book **The Hitchhicker´s Guide to de Galaxy**, from Douglas Adams!\n",
    "\n",
    "**Version 1.8** update: now I am using **random_state** parameter, so I can compare exactly the same thing, when using randomized processes, for ensuring the same results for each function call\n",
    "\n",
    "---\n",
    "\n",
    "**Future** possible updates:\n",
    "\n",
    ">- I can test/train using other parameters for test_size, like **0.25** and see if it interfers so much\n",
    ">- I can try to do **bootstrap** and see if I can plot a good **normalization** curve for it!\n",
    "\n",
    "**NEW Future** possible update:\n",
    "\n",
    ">- I could use **Cross Validation** in order to use all my data for training!\n",
    ">- **Warning** there are some papers saying that to take care about using **Cross Validation** on Model Training. The reason is, it may let **data leakage** from your **train** to your **test** dataset, masking the real power of your model!\n",
    ">- so I need to **study more** about that before trying to implement it in Python\n",
    ">- the discussion about \"data leakage\" when using cross validation strategies when **fitting** data is [here](https://stackoverflow.com/questions/56129726/fitting-model-when-using-cross-validation-to-evaluate-performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split makes randomization, so random_state parameter was set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it looks OK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19922"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0] + X_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Choose your first Classifier \n",
    "\n",
    "- and build a **Pipeline** for it\n",
    "\n",
    "Each Pipeline is a Python Object that can be called for **methods**, as **fit()**\n",
    "\n",
    "---\n",
    "\n",
    "What **Classifier** to choose?\n",
    "\n",
    "- **Towards Data Science** give us some tips [here](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)\n",
    "\n",
    "---\n",
    "\n",
    "Start with a **Naïve Bayes** (NB)\n",
    "\n",
    "`clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)`\n",
    "\n",
    "In a Pipeline way (pipeline documentation is [here](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html):\n",
    "\n",
    ">- I had some issues with `CountVectorizer`, but could clear it using Stack Overflow [here](https://stackoverflow.com/questions/32674380/countvectorizer-vocabulary-wasnt-fitted)\n",
    ">- should I use `CountVectorizer(tokenizer=udacourse2.fn_tokenize_fast)`?... but I will **not**!\n",
    ">- why? Just because I already proceeded with **tokenization** in a earlier step\n",
    ">- so, how to overpass this hellish `tokenizer=...` parameter?\n",
    ">- I found a clever solution [here](https://stackoverflow.com/questions/35867484/pass-tokens-to-countvectorizer)\n",
    ">- so, I prepared a **dummy** function to overpass the tokenizer over **CountVertorizer**\n",
    "\n",
    "First I tried to set Classifier as **MultinomialNB()**, and it crashes:\n",
    "\n",
    ">- only **one** Label to be trained was expected, and there were 36 Labels!;\n",
    ">- reading the documentation for SKlearn, it turned clear that it is necessary (if your Classifier algorithm was not originally built for **multicriteria**, to run it **n** times, one for each label\n",
    ">- so it is necessary to include it our pipeline, using `MultiOutputClassifier()` transformer\n",
    "\n",
    "*And... it looks pretty **fast** to train, not? What is the secret? We are **bypassing** the tokenizer and preprecessor, as we **already made** it at the dataset!*\n",
    "\n",
    "*Another thing, we are not using the **whole** dataset... it´s just about a little **issue** we have, as there are a lot of **missing labels** at the dataset! And for me, it will **distort** our training! (lately I will compare the results with traning the **raw** dataset)*\n",
    "\n",
    "**Naïve Bayes** is known as a very **fast** method:\n",
    "\n",
    ">- but it is also known as being not so **accurate**\n",
    ">- and it have so **few** parameters for a later refinement\n",
    "\n",
    "I could reach Model Accuracy of **92.2**, after **.58** seconds for fitting the Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAÏVE BAYES - process time: 1.10 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "#Naïve Bayes classifier pipeline - no randomization involved\n",
    "pipeline_mbnb = Pipeline([('vect', CountVectorizer(tokenizer=dummy, preprocessor=dummy)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf',  MultiOutputClassifier(MultinomialNB()))])\n",
    "                          #('clf', MultinomialNB())]) #<-my terrible mistake!\n",
    "#remembering:\n",
    "#CountVectorizer -> makes the count for tokenized vectors\n",
    "#TfidTransformer -> makes the weight \"normalization\" for word occurences\n",
    "#MultinomialNB -> is my Classifier\n",
    "\n",
    "#fit text_clf (our first Classifier model)\n",
    "pipeline_mbnb.fit(X_train, y_train)\n",
    "\n",
    "spent = time() - start\n",
    "print('NAÏVE BAYES - process time: {:.2f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want, I can see the parameters for my **Pipeline**, using this command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline_mbnb.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Run metrics for it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting using **Naïve Bayes** Classifier\n",
    "\n",
    "And I took this **weird** Error Message:\n",
    "\n",
    "\"**UndefinedMetricWarning:**\" \n",
    "\n",
    ">- \"Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples\"\n",
    ">- \"Use `zero_division` parameter to control this behavior\"\n",
    "\n",
    "And searching, I found this explanation [here](https://stackoverflow.com/questions/43162506/undefinedmetricwarning-f-score-is-ill-defined-and-being-set-to-0-0-in-labels-wi)\n",
    "\n",
    ">- it is not an **weird error** at all. Some labels could´t be predicted when running the Classifier\n",
    ">- so the report don´t know how to handle them\n",
    "\n",
    "\"What you can do, is decide that you are not interested in the scores of labels that were not predicted, and then explicitly specify the labels you are interested in (which are labels that were predicted at least once):\"\n",
    "\n",
    "`metrics.f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))`\n",
    "\n",
    "#### Dealing with this issue\n",
    "\n",
    "**First**, I altered my function `fn_plot_scores` for not allowing comparisons over an empty (**not trained**) column, as `y_pred`\n",
    "\n",
    "And to check if all predicted values are **zeroes** [here](https://stackoverflow.com/questions/48570797/check-if-pandas-column-contains-all-zeros)\n",
    "\n",
    "And I was using in my function a **general** calculus for Accuracy. The problem is: **zeroes** for **zeroes** result a **1** accuracy, distorting my actual Accuracy, for a better (**unreal**) higher value:\n",
    "\n",
    ">- so, for general model Accuracy, I cannot use this `accuracy = (y_pred == y_test.values).mean()`\n",
    ">- using instead `f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))`\n",
    "\n",
    "**Version 1.9** updated: created my own customized function for showing metrics\n",
    "\n",
    "**Version 1.15** updated: improved my customized function for other metrics\n",
    "\n",
    ">- I was using the mean F1 Score as \"Model Precision\" and that seems a bit **silly**, as there were other metrics\n",
    ">- I could find a better material At SkLearn documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)\n",
    ">- for example, as we are using binary labels, and the most important one is the \"1\", label, we can set is in the parameters as `average='binary'` and `pos_label=1`\n",
    ">- another thing, **Precision** and **Reacall** are more **effective** for Machine Learning than **F1**\n",
    ">- about ill-defined parameters, I found some documentation at [Udacity](https://knowledge.udacity.com/questions/314220)\n",
    "\n",
    "**Future improvement**\n",
    "\n",
    ">- there are better metrics for **multilabel classificication** [here](https://medium.com/analytics-vidhya/metrics-for-multi-label-classification-49cc5aeba1c3#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjgxOWQxZTYxNDI5ZGQzZDNjYWVmMTI5YzBhYzJiYWU4YzZkNDZmYmMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2MzAyNzYxNDYsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwNTAzNjUxNTUwMDU1MTQ1OTkzNSIsImVtYWlsIjoiZXBhc3NldG9AZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImF6cCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsIm5hbWUiOiJFZHVhcmRvIFBhc3NldG8iLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EtL0FPaDE0R2pJNmh5V3FSTGNfdHZCYlg4OWxFTEphZ3diMFBYeXJNOGN1YXBLR1E9czk2LWMiLCJnaXZlbl9uYW1lIjoiRWR1YXJkbyIsImZhbWlseV9uYW1lIjoiUGFzc2V0byIsImlhdCI6MTYzMDI3NjQ0NiwiZXhwIjoxNjMwMjgwMDQ2LCJqdGkiOiIzYzYyZThiZDhkYWU4YjU4NWJlZDI4ZGFhYjE5ZDkwY2MyOTFmNjhlIn0.kwd1YjjoxP-RUFHA86RftkGHMMwic3edRM31Yz8sJL9dg0jzPwS2c9peJ9kDuIQK5x8PWvZxhnl-wI32M_D_FvWv5UXad1cYnkuEGnxeo94LPCUam-aOnUvDDpefUEOv8Oe2751C0VH1MrlDiOQxyGcYBIjnr2NtdaN8Y8pm-ZLonqw3zpZO-2Wlkhnrb12ruZmpWD2CbqZCHpNwmYq0bQqCrNp_dCZ9mBjc5xrYN2G8Us7ESZcCnqLLjk_cb6UVV81LFjKkrjGifBsOac-ANoc7TBJQnFW41FISORWL8j84mW7jl8UgEmxrgc8kaFtHm6oC5ptc9YLRBDq1Q93ZBQ)\n",
    ">- we could use **Precision at k** `P@k`, **Avg precision at k** `AP@k`, **Mean avg precision at k** `MAP@k` and **Sampled F1 Score** `F1 Samples`\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.17** for **Naïve Bayes** updated new, **more realistic** metrics based on **10 top** labels:\n",
    "\n",
    ">- Model Accuracy now is **31.2**%\n",
    ">- Precision now is **85.9**%\n",
    ">- Recall now is **26.4**%\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.18** for **Naïve Bayes** letting the tokenizer take the same word more than once:\n",
    "\n",
    ">- Model Accuracy now is **31.5**%\n",
    ">- Precision now is **86.3**%\n",
    ">- Recall now is **26.6**%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###function scores_report started\n",
      "######################################################\n",
      "*aid_related -> label iloc[2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.44      0.56      2313\n",
      "           1       0.65      0.89      0.75      2668\n",
      "\n",
      "    accuracy                           0.68      4981\n",
      "   macro avg       0.71      0.66      0.65      4981\n",
      "weighted avg       0.70      0.68      0.66      4981\n",
      "\n",
      "######################################################\n",
      "*weather_related -> label iloc[26]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85      3109\n",
      "           1       0.83      0.59      0.69      1872\n",
      "\n",
      "    accuracy                           0.80      4981\n",
      "   macro avg       0.81      0.76      0.77      4981\n",
      "weighted avg       0.81      0.80      0.79      4981\n",
      "\n",
      "######################################################\n",
      "*direct_report -> label iloc[33]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.96      0.88      3726\n",
      "           1       0.77      0.37      0.50      1255\n",
      "\n",
      "    accuracy                           0.81      4981\n",
      "   macro avg       0.79      0.66      0.69      4981\n",
      "weighted avg       0.81      0.81      0.79      4981\n",
      "\n",
      "######################################################\n",
      "*request -> label iloc[0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91      3884\n",
      "           1       0.82      0.45      0.58      1097\n",
      "\n",
      "    accuracy                           0.86      4981\n",
      "   macro avg       0.84      0.71      0.75      4981\n",
      "weighted avg       0.85      0.86      0.84      4981\n",
      "\n",
      "######################################################\n",
      "*other_aid -> label iloc[16]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      4163\n",
      "           1       1.00      0.00      0.00       818\n",
      "\n",
      "    accuracy                           0.84      4981\n",
      "   macro avg       0.92      0.50      0.46      4981\n",
      "weighted avg       0.86      0.84      0.76      4981\n",
      "\n",
      "######################################################\n",
      "*food -> label iloc[9]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      4266\n",
      "           1       0.84      0.08      0.15       715\n",
      "\n",
      "    accuracy                           0.87      4981\n",
      "   macro avg       0.85      0.54      0.54      4981\n",
      "weighted avg       0.86      0.87      0.82      4981\n",
      "\n",
      "######################################################\n",
      "*earthquake -> label iloc[30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      4384\n",
      "           1       0.93      0.19      0.31       597\n",
      "\n",
      "    accuracy                           0.90      4981\n",
      "   macro avg       0.92      0.59      0.63      4981\n",
      "weighted avg       0.90      0.90      0.87      4981\n",
      "\n",
      "######################################################\n",
      "*storm -> label iloc[28]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94      4371\n",
      "           1       0.89      0.05      0.10       610\n",
      "\n",
      "    accuracy                           0.88      4981\n",
      "   macro avg       0.89      0.53      0.52      4981\n",
      "weighted avg       0.88      0.88      0.84      4981\n",
      "\n",
      "######################################################\n",
      "*shelter -> label iloc[10]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      4410\n",
      "           1       0.90      0.02      0.03       571\n",
      "\n",
      "    accuracy                           0.89      4981\n",
      "   macro avg       0.89      0.51      0.49      4981\n",
      "weighted avg       0.89      0.89      0.84      4981\n",
      "\n",
      "######################################################\n",
      "*floods -> label iloc[27]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      4412\n",
      "           1       1.00      0.02      0.03       569\n",
      "\n",
      "    accuracy                           0.89      4981\n",
      "   macro avg       0.94      0.51      0.49      4981\n",
      "weighted avg       0.90      0.89      0.84      4981\n",
      "\n",
      "###Model metrics for 10 labels:\n",
      " Accuracy: 0.315 (31.5%)\n",
      " Precision: 0.863 (86.3%)\n",
      " Recall: 0.266 (26.6%)\n",
      "\n",
      "###Worst metrics:\n",
      " Accuracy: 0.002 (0.2%) for other_aid\n",
      " Precision: 0.645 (64.5%) for aid_related\n",
      " Recall: 0.001 (0.1%) for other_aid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.31483529958459766, 0.8628820325241943, 0.26578107990419364)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipeline_mbnb.predict(X_test)\n",
    "udacourse2.fn_scores_report2(y_test, \n",
    "                             y_pred,\n",
    "                             best_10=True)\n",
    "#udacourse2.fn_scores_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy is distorted by **false fitting** (zeroes over zeroes)\n",
    "\n",
    "Manually, I could find the true meaning as near to **82%**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 corrected Model Accuracy: 0.82 (82%)\n"
     ]
    }
   ],
   "source": [
    "real_f1 = [.78, .86, .83, .85, .80, .83, .81, .91, .86, .69, .83]\n",
    "\n",
    "corr_precision = statistics.mean(real_f1)\n",
    "print('F1 corrected Model Accuracy: {:.2f} ({:.0f}%)'.format(corr_precision, corr_precision*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Critics about the performance of my Classifier\n",
    "\n",
    "I know what you are thinking: \"Uh, there is something **wrong** with the Accuracy of this guy\"\n",
    "\n",
    "So, as you can see: **92.2%** is too high for a **Naïve Bayes Classifier**!\n",
    "\n",
    "There are some explanations here:\n",
    "\n",
    ">- if you read it with care, you will find this **weird** label `related`. And it seems to **positivate** for every row on my dataset. So It distorts the average for a **higher** one\n",
    ">- if you look at each **weighted avg**, you will find some clearly **bad** values, as **68%** for **aid_related** (if you start thinking about it, is something like in **2/3** of the cases the model guesses well for this label... so a really **bad** performance)\n",
    "\n",
    "*Updated 1: when I removed `related` column, my **Model Accuracy** felt down to **56.1%**. Normally my Labels are holding something as **75-78%** f1-score. Now I think that these **untrainable columns** are making my average Accuracy to fall down!*\n",
    "\n",
    "---\n",
    "\n",
    "But there is another **critic** about this data.\n",
    "\n",
    "I am **Engineer** by profession. And I work for almost **19** years in a **hidrology** datacenter for the Brazillian Government. So, in some cases, you see some data and start thinking: \"this data is not what it seems\".\n",
    "\n",
    "And the main problem with this data is:\n",
    "\n",
    ">- it is a **mistake** to think that all we need to do with it is to train a **Supervised Learning** machine!\n",
    ">- if you look with care, this is not about **Supervised Learning**, it is an actual **Semi-Supervised Learning** problem. Why?\n",
    ">- just consider that there were **zillions** of Tweeter messages about catastrophes all around the world. And then, when the message was not originally in English, they translated it. And then someone manually **labeled** each of these catastrophe reports. And a **lot** of them remained with **no classification**\n",
    ">- it I just interpret it as a **Supervised Learning** challenge, I will feed my Classifier with a lot of **false negatives**. And my Machine Learning Model will learn how to **keep in blank** a lot of these messages, as it was trained by my **raw** data!\n",
    "\n",
    "So in **preprocessing** step, I avoided **unlabelled data**, filtering and removing for training every row that not contains any label on it. They were clearly, **negleted** for labeling, when manually processed!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Try other Classifiers\n",
    "\n",
    "- I will try some Classifiers based on a **hierarchical structure**:\n",
    "\n",
    ">- why **hierarchical structure** for words? Just because I think we do it **naturally** in our brain\n",
    ">- when science mimic nature I personally think that things goes in a better way. So, let´s try it!\n",
    "\n",
    "First of them, **Random Forest** Classifier\n",
    "\n",
    ">- as **RFC** is a **single-label** Classifier, we need to call it **n** times for each label to be classified\n",
    ">- so, que need to call it indirectly, using **Multi-Output** Classifier tool\n",
    ">- it took **693.73 seconds** (as 11 minutes and 35 seconds) to complete the tast (not so bad!)\n",
    ">- I tried to configure a **GridSearch**, just to set the number of processors to `-1` (meaning, the **maximum** number)\n",
    "\n",
    "Accuracy was near to **93%** before removing `related` label. Now it remains as **93.8%**. So, it don't matter!\n",
    "\n",
    "**Version 1.10** update: prepared other Machine Learning Classifiers for training the data\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.17** for **Random Forest** updated new, **more realistic** metrics based on **10 top** labels:\n",
    "\n",
    ">- Model Accuracy now is **66.5**%\n",
    ">- Precision now is **69.8**%\n",
    ">- Recall now is **70.1**%\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.18** for **Random Forest** letting the tokenizer take the same word more than once:\n",
    "\n",
    ">- Model Accuracy now is **66.4**%\n",
    ">- Precision now is **79.8**%\n",
    ">- Recall now is **59.7**%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST - process time: 13 minutes, 21.23 seconds (801.23s)\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "#Random Forest makes randomization, so random_state parameter was set\n",
    "pipeline_rafo = Pipeline([('vect', CountVectorizer(tokenizer=dummy, preprocessor=dummy)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', MultiOutputClassifier(RandomForestClassifier(random_state=42)))])\n",
    "\n",
    "pipeline_rafo.fit(X_train, y_train)\n",
    "\n",
    "#an attempt to use multiple cores to process the task\n",
    "\n",
    "#param_grid = \n",
    "#gs_clf = GridSearchCV(pipeline_rafo, parameters, n_jobs=-1)\n",
    "#gs_clf = gs_clf.fit(X_train, y_train)\n",
    "\n",
    "spent = time() - start\n",
    "s_min = spent // 60\n",
    "print('RANDOM FOREST - process time: {:.0f} minutes, {:.2f} seconds ({:.2f}s)'\\\n",
    "      .format(s_min, spent-(s_min*60), spent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###function scores_report started\n",
      "######################################################\n",
      "*aid_related -> label iloc[2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.67      0.70      2313\n",
      "           1       0.74      0.79      0.76      2668\n",
      "\n",
      "    accuracy                           0.74      4981\n",
      "   macro avg       0.74      0.73      0.73      4981\n",
      "weighted avg       0.74      0.74      0.74      4981\n",
      "\n",
      "######################################################\n",
      "*weather_related -> label iloc[26]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.89      3109\n",
      "           1       0.86      0.76      0.81      1872\n",
      "\n",
      "    accuracy                           0.86      4981\n",
      "   macro avg       0.86      0.84      0.85      4981\n",
      "weighted avg       0.86      0.86      0.86      4981\n",
      "\n",
      "######################################################\n",
      "*direct_report -> label iloc[33]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.89      3726\n",
      "           1       0.71      0.48      0.57      1255\n",
      "\n",
      "    accuracy                           0.82      4981\n",
      "   macro avg       0.78      0.71      0.73      4981\n",
      "weighted avg       0.81      0.82      0.81      4981\n",
      "\n",
      "######################################################\n",
      "*request -> label iloc[0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      3884\n",
      "           1       0.77      0.64      0.70      1097\n",
      "\n",
      "    accuracy                           0.88      4981\n",
      "   macro avg       0.84      0.79      0.81      4981\n",
      "weighted avg       0.87      0.88      0.87      4981\n",
      "\n",
      "######################################################\n",
      "*other_aid -> label iloc[16]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91      4163\n",
      "           1       0.62      0.09      0.16       818\n",
      "\n",
      "    accuracy                           0.84      4981\n",
      "   macro avg       0.73      0.54      0.54      4981\n",
      "weighted avg       0.81      0.84      0.79      4981\n",
      "\n",
      "######################################################\n",
      "*food -> label iloc[9]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97      4266\n",
      "           1       0.83      0.73      0.78       715\n",
      "\n",
      "    accuracy                           0.94      4981\n",
      "   macro avg       0.89      0.85      0.87      4981\n",
      "weighted avg       0.94      0.94      0.94      4981\n",
      "\n",
      "######################################################\n",
      "*earthquake -> label iloc[30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4384\n",
      "           1       0.90      0.81      0.85       597\n",
      "\n",
      "    accuracy                           0.97      4981\n",
      "   macro avg       0.94      0.90      0.92      4981\n",
      "weighted avg       0.97      0.97      0.97      4981\n",
      "\n",
      "######################################################\n",
      "*storm -> label iloc[28]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      4371\n",
      "           1       0.77      0.60      0.68       610\n",
      "\n",
      "    accuracy                           0.93      4981\n",
      "   macro avg       0.86      0.79      0.82      4981\n",
      "weighted avg       0.92      0.93      0.93      4981\n",
      "\n",
      "######################################################\n",
      "*shelter -> label iloc[10]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      4410\n",
      "           1       0.85      0.49      0.62       571\n",
      "\n",
      "    accuracy                           0.93      4981\n",
      "   macro avg       0.89      0.74      0.79      4981\n",
      "weighted avg       0.93      0.93      0.92      4981\n",
      "\n",
      "######################################################\n",
      "*floods -> label iloc[27]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4412\n",
      "           1       0.93      0.56      0.70       569\n",
      "\n",
      "    accuracy                           0.95      4981\n",
      "   macro avg       0.94      0.78      0.84      4981\n",
      "weighted avg       0.94      0.95      0.94      4981\n",
      "\n",
      "###Model metrics for 10 labels:\n",
      " Accuracy: 0.664 (66.4%)\n",
      " Precision: 0.798 (79.8%)\n",
      " Recall: 0.597 (59.7%)\n",
      "\n",
      "###Worst metrics:\n",
      " Accuracy: 0.162 (16.2%) for other_aid\n",
      " Precision: 0.618 (61.8%) for other_aid\n",
      " Recall: 0.093 (9.3%) for other_aid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6637689138512191, 0.7976322127539948, 0.5969071962832412)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipeline_rafo.predict(X_test)\n",
    "udacourse2.fn_scores_report2(y_test, \n",
    "                             y_pred,\n",
    "                             best_10=True)\n",
    "#udacourse2.fn_scores_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another tree like Classifier is **Adaboost**:\n",
    "\n",
    ">- they say Adaboost is specially good for **differenciate** positives and negatives\n",
    ">- it took **106.16 seconds** (kind of **1** minute and **45** seconds) to complete the task... not so bad... (as AdaBoost don´t use **trees**, but **stumps** for doing its job)\n",
    "\n",
    "Accuracy was near to **91%**. After removing `related` label:\n",
    "\n",
    ">- it raised to **93.6%**. As Adaboost is based on **stumps**, a bad label perhaps distorts the model\n",
    ">- training time lowered to **71,57** seconds, so kind of a time reduction about 30%\n",
    "\n",
    "*Adaboost seems to be really **fast**, when compared to Random Forest. And without loosing too much in terms of Model Accuracy...*\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.17** for **Adaboost** updated new, **more realistic** metrics based on **10 top** labels:\n",
    "\n",
    ">- Model Accuracy now is **66.3**%\n",
    ">- Precision now is **77.7**%\n",
    ">- Recall now is **58.7**%\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.18** for **Adaboost** letting the tokenizer take the same word more than once:\n",
    "\n",
    ">- Model Accuracy now is **65.4**%\n",
    ">- Precision now is **77.3**%\n",
    ">- Recall now is **57.8**%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADABOOST - process time: 142.60 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "#Adaboost makes randomization, so random_state parameter was set\n",
    "pipeline_adab = Pipeline([('vect', CountVectorizer(tokenizer=dummy, preprocessor=dummy)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf',  MultiOutputClassifier(AdaBoostClassifier(random_state=42)))])\n",
    "\n",
    "pipeline_adab.fit(X_train, y_train)\n",
    "\n",
    "spent = time() - start\n",
    "print('ADABOOST - process time: {:.2f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###function scores_report started\n",
      "######################################################\n",
      "*aid_related -> label iloc[2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69      2313\n",
      "           1       0.73      0.73      0.73      2668\n",
      "\n",
      "    accuracy                           0.71      4981\n",
      "   macro avg       0.71      0.71      0.71      4981\n",
      "weighted avg       0.71      0.71      0.71      4981\n",
      "\n",
      "######################################################\n",
      "*weather_related -> label iloc[26]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      3109\n",
      "           1       0.88      0.70      0.78      1872\n",
      "\n",
      "    accuracy                           0.85      4981\n",
      "   macro avg       0.86      0.82      0.83      4981\n",
      "weighted avg       0.85      0.85      0.85      4981\n",
      "\n",
      "######################################################\n",
      "*direct_report -> label iloc[33]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88      3726\n",
      "           1       0.70      0.46      0.55      1255\n",
      "\n",
      "    accuracy                           0.81      4981\n",
      "   macro avg       0.77      0.70      0.72      4981\n",
      "weighted avg       0.80      0.81      0.80      4981\n",
      "\n",
      "######################################################\n",
      "*request -> label iloc[0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.95      0.91      3884\n",
      "           1       0.76      0.55      0.64      1097\n",
      "\n",
      "    accuracy                           0.86      4981\n",
      "   macro avg       0.82      0.75      0.78      4981\n",
      "weighted avg       0.85      0.86      0.85      4981\n",
      "\n",
      "######################################################\n",
      "*other_aid -> label iloc[16]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.96      0.91      4163\n",
      "           1       0.46      0.16      0.24       818\n",
      "\n",
      "    accuracy                           0.83      4981\n",
      "   macro avg       0.66      0.56      0.57      4981\n",
      "weighted avg       0.79      0.83      0.80      4981\n",
      "\n",
      "######################################################\n",
      "*food -> label iloc[9]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4266\n",
      "           1       0.82      0.73      0.77       715\n",
      "\n",
      "    accuracy                           0.94      4981\n",
      "   macro avg       0.89      0.85      0.87      4981\n",
      "weighted avg       0.94      0.94      0.94      4981\n",
      "\n",
      "######################################################\n",
      "*earthquake -> label iloc[30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      4384\n",
      "           1       0.90      0.81      0.86       597\n",
      "\n",
      "    accuracy                           0.97      4981\n",
      "   macro avg       0.94      0.90      0.92      4981\n",
      "weighted avg       0.97      0.97      0.97      4981\n",
      "\n",
      "######################################################\n",
      "*storm -> label iloc[28]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      4371\n",
      "           1       0.80      0.54      0.65       610\n",
      "\n",
      "    accuracy                           0.93      4981\n",
      "   macro avg       0.87      0.76      0.80      4981\n",
      "weighted avg       0.92      0.93      0.92      4981\n",
      "\n",
      "######################################################\n",
      "*shelter -> label iloc[10]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      4410\n",
      "           1       0.78      0.53      0.63       571\n",
      "\n",
      "    accuracy                           0.93      4981\n",
      "   macro avg       0.86      0.75      0.80      4981\n",
      "weighted avg       0.92      0.93      0.92      4981\n",
      "\n",
      "######################################################\n",
      "*floods -> label iloc[27]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4412\n",
      "           1       0.89      0.58      0.70       569\n",
      "\n",
      "    accuracy                           0.94      4981\n",
      "   macro avg       0.92      0.79      0.84      4981\n",
      "weighted avg       0.94      0.94      0.94      4981\n",
      "\n",
      "###Model metrics for 10 labels:\n",
      " Accuracy: 0.654 (65.4%)\n",
      " Precision: 0.773 (77.3%)\n",
      " Recall: 0.578 (57.8%)\n",
      "\n",
      "###Worst metrics:\n",
      " Accuracy: 0.236 (23.6%) for other_aid\n",
      " Precision: 0.461 (46.1%) for other_aid\n",
      " Recall: 0.159 (15.9%) for other_aid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.654363384791236, 0.7728101688203811, 0.5784827533968593)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipeline_adab.predict(X_test)\n",
    "udacourse2.fn_scores_report2(y_test, \n",
    "                             y_pred,\n",
    "                             best_10=True)\n",
    "#udacourse2.fn_scores_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Falling in a trap when choosing another Classifier\n",
    "\n",
    "Then I tried a **Stochastic Gradient Descent** (SGD) [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)\n",
    "\n",
    "_\"Linear classifiers (SVM, logistic regression, etc.) with SGD training\"_\n",
    "\n",
    "It can works with a **Support Vector Machine** (SVM), that is a fancy way of defining a good frontier\n",
    "\n",
    "\n",
    "`clf = SGDClassifier()` with some parameters\n",
    "  \n",
    ">- `learning_rate='optimal'`$\\rightarrow$ **decreasing strength schedule** used for updating the gradient of the loss at each sample\n",
    ">- `loss='hinge'` $\\rightarrow$ **Linear SVM** for the fitting model (works with data represented as dense or sparse arrays for features)\n",
    ">- `penalty=[‘l2’, ‘l1’, ‘elasticnet’]` $\\rightarrow$ **regularizer**  shrinks model parameters towards the zero vector using an **Elastic Net** (l2) or \n",
    ">- `alpha=[1e-5, 1e-4, 1e-3]` $\\rightarrow$ stopping criteria, the higher the value, the **stronger** the regularization (also used to compute the **Learning Rate**, when set to learning_rate is set to ‘optimal’\n",
    ">- `n_iter=[1, 5, 10]` $\\rightarrow$ number of passes over the **Epochs** (Training Data). It only impacts the behavior in the **fit method**, and not the partial_fit method\n",
    ">- `random_state=42` $\\rightarrow$ if you want to replicate exactly the same output each time you retrain your machine\n",
    "  \n",
    "*Observe that this is a kind of a lecture over the text at SkLearn website for this Classifier*\n",
    "\n",
    "---\n",
    "\n",
    "And **SGDC** didn´t work! It gave me a **ValueError: y should be a 1d array, got an array instead**. So, something went wrong:\n",
    "\n",
    "Searching for the cause of the problem, I found this explanation [here](https://stackoverflow.com/questions/20335853/scikit-multilabel-classification-valueerror-bad-input-shape)\n",
    "\n",
    "*\"No, SGDClassifier does not do **multilabel classification** (what I need!) -- it does **multiclass classification**, which is a different problem, although both are solved using a one-vs-all problem reduction\"*\n",
    "\n",
    "*(we use Multiclass Classification when the possible classifications are **mutually exclusive**. For example, I have a picture with a kind of fruit, and it could be classified as a **banana**, or a **pear**, or even an **apple**. Clearly that is not our case!)*\n",
    "\n",
    "*Then, neither **SGD** nor OneVsRestClassifier.fit will accept a **sparse matrix** (is what I have!) for y* \n",
    "\n",
    "*- SGD wants an **array of labels** (is what I have!), as you've already found out*\n",
    "\n",
    "*- OneVsRestClassifier wants, for multilabel purposes, a list of lists of labels*\n",
    "\n",
    "*Observe that this is a kind of a lecture over the explanatory text that I got at SKLearn website for SGDC for Multilabel*\n",
    "\n",
    "---\n",
    "\n",
    "There is a good explanation about **Multiclass** and **Multilabel** Classifiers [here](https://scikit-learn.org/stable/modules/multiclass.html)\n",
    "\n",
    "Don´t try to run this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time()\n",
    "\n",
    "#def dummy(doc):\n",
    "#    return doc\n",
    "\n",
    "#random_state=42 #<-just to remember!\n",
    "#pipeline_sgrd = Pipeline([('vect', CountVectorizer(tokenizer=dummy, preprocessor=dummy)),\n",
    "#                          ('tfidf', TfidfTransformer()),\n",
    "#                          ('clf', SGDClassifier(loss='hinge', \n",
    "#                                                penalty='l2',\n",
    "#                                                alpha=1e-3))]) \n",
    "#fit_sgrd = pipeline_sgrd.fit(X_train, y_train)\n",
    "\n",
    "#spent = time() - start\n",
    "#print('STOCHASTIC GRADIENT DESCENT - process time:{:.2f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try **K-Neighbors Classifier**\n",
    "\n",
    "**First** try, `n_neighbors=3`:\n",
    "\n",
    ">- model Accuracy was **91.8%**... not so bad!\n",
    ">- and... why only **3** neighbors? You see this parameter is quite **arbitrary** in our case... it could be 2 or 5... as we have so much (or so few neighbors that we can rely on, this can **tune better** our classifier)... and why not try it, using **GridSearch**?\n",
    "\n",
    "**Second** try, `n_neighbors=7` and `p=1` (using **GridSearch**, explanation below to tune it for a better result):\n",
    "\n",
    ">- it took **.74** seconds to **fit** the Classifier\n",
    ">- the slowest part was to **predict**, as **5** minutes and **27** seconds!\n",
    ">- it gave us **92.0%** of model Accuracy... and a lot of **non-fitting** labels!\n",
    ">- so, it was not a good idea to use the new parameters, the **original ones** are better!\n",
    "\n",
    "Some reflexions about models, **GridSearch** and best parameters:\n",
    "\n",
    ">- sometimes a **slight** difference don´t worth the computational price\n",
    ">- another thing to reflect about: why I started with only **3** neighbors? Just because Tweeter messages are quite **short**. When tokenized, the number of **tokens** normally don´t exceed **7**!\n",
    ">- so, giving a brutal **resolution** to poor data, normally is not a good idea\n",
    "\n",
    "**Third** try, `n_neighbors=3` and `p=1`\n",
    "\n",
    ">- I achieved **91.3** accuracy, don´t using so much computational power!\n",
    ">- only tunning a bit the **power** parameter provided me with a silghtly **better** result\n",
    ">- training time is **0.79** seconds and predict is **5** minutes and **27** seconds\n",
    "\n",
    "**Version 1.11** update: preparation of k-Neighbors Classifier for training\n",
    "\n",
    "*k-Neighbors seems to not fit so well for this kind of problems!*\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.17** for **k-Nearest** updated new, **more realistic** metrics based on **10 top** labels:\n",
    "\n",
    ">- Model Accuracy now is **39.1**%\n",
    ">- Precision now is **60.1**%\n",
    ">- Recall now is **32.6**%\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.18** for **k-Nearest** letting the tokenizer take the same word more than once:\n",
    "\n",
    ">- Model Accuracy now is **38.8**%\n",
    ">- Precision now is **60.5**%\n",
    ">- Recall now is **32.2**%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K NEIGHBORS CLASSIFIER - process time: 0.56 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "#k-Neighbors don´t use randomization\n",
    "pipeline_knbr = Pipeline([('vect', CountVectorizer(tokenizer=dummy, preprocessor=dummy)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', MultiOutputClassifier(KNeighborsClassifier(n_neighbors=3, p=1)))])\n",
    "\n",
    "pipeline_knbr.fit(X_train, y_train)\n",
    "\n",
    "spent = time() - start\n",
    "print('K NEIGHBORS CLASSIFIER - process time: {:.2f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###function scores_report started\n",
      "######################################################\n",
      "*aid_related -> label iloc[2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.78      0.63      2313\n",
      "           1       0.67      0.39      0.49      2668\n",
      "\n",
      "    accuracy                           0.57      4981\n",
      "   macro avg       0.60      0.59      0.56      4981\n",
      "weighted avg       0.60      0.57      0.56      4981\n",
      "\n",
      "######################################################\n",
      "*weather_related -> label iloc[26]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.89      0.80      3109\n",
      "           1       0.69      0.43      0.53      1872\n",
      "\n",
      "    accuracy                           0.72      4981\n",
      "   macro avg       0.71      0.66      0.66      4981\n",
      "weighted avg       0.71      0.72      0.70      4981\n",
      "\n",
      "######################################################\n",
      "*direct_report -> label iloc[33]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81      3726\n",
      "           1       0.44      0.42      0.43      1255\n",
      "\n",
      "    accuracy                           0.72      4981\n",
      "   macro avg       0.63      0.62      0.62      4981\n",
      "weighted avg       0.72      0.72      0.72      4981\n",
      "\n",
      "######################################################\n",
      "*request -> label iloc[0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      3884\n",
      "           1       0.55      0.48      0.51      1097\n",
      "\n",
      "    accuracy                           0.80      4981\n",
      "   macro avg       0.70      0.68      0.69      4981\n",
      "weighted avg       0.79      0.80      0.79      4981\n",
      "\n",
      "######################################################\n",
      "*other_aid -> label iloc[16]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.94      0.89      4163\n",
      "           1       0.29      0.13      0.18       818\n",
      "\n",
      "    accuracy                           0.81      4981\n",
      "   macro avg       0.57      0.54      0.54      4981\n",
      "weighted avg       0.76      0.81      0.77      4981\n",
      "\n",
      "######################################################\n",
      "*food -> label iloc[9]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94      4266\n",
      "           1       0.79      0.31      0.44       715\n",
      "\n",
      "    accuracy                           0.89      4981\n",
      "   macro avg       0.84      0.65      0.69      4981\n",
      "weighted avg       0.88      0.89      0.87      4981\n",
      "\n",
      "######################################################\n",
      "*earthquake -> label iloc[30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      4384\n",
      "           1       0.51      0.58      0.55       597\n",
      "\n",
      "    accuracy                           0.88      4981\n",
      "   macro avg       0.73      0.75      0.74      4981\n",
      "weighted avg       0.89      0.88      0.89      4981\n",
      "\n",
      "######################################################\n",
      "*storm -> label iloc[28]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95      4371\n",
      "           1       0.79      0.27      0.40       610\n",
      "\n",
      "    accuracy                           0.90      4981\n",
      "   macro avg       0.85      0.63      0.67      4981\n",
      "weighted avg       0.89      0.90      0.88      4981\n",
      "\n",
      "######################################################\n",
      "*shelter -> label iloc[10]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95      4410\n",
      "           1       0.75      0.19      0.30       571\n",
      "\n",
      "    accuracy                           0.90      4981\n",
      "   macro avg       0.83      0.59      0.62      4981\n",
      "weighted avg       0.89      0.90      0.87      4981\n",
      "\n",
      "######################################################\n",
      "*floods -> label iloc[27]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94      4412\n",
      "           1       0.55      0.02      0.04       569\n",
      "\n",
      "    accuracy                           0.89      4981\n",
      "   macro avg       0.72      0.51      0.49      4981\n",
      "weighted avg       0.85      0.89      0.84      4981\n",
      "\n",
      "###Model metrics for 10 labels:\n",
      " Accuracy: 0.388 (38.8%)\n",
      " Precision: 0.605 (60.5%)\n",
      " Recall: 0.322 (32.2%)\n",
      "\n",
      "###Worst metrics:\n",
      " Accuracy: 0.037 (3.7%) for floods\n",
      " Precision: 0.295 (29.5%) for other_aid\n",
      " Recall: 0.019 (1.9%) for floods\n",
      "process time: 257.57 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "y_pred = pipeline_knbr.predict(X_test)\n",
    "udacourse2.fn_scores_report2(y_test, \n",
    "                             y_pred,\n",
    "                             best_10=True)\n",
    "#udacourse2.fn_scores_report(y_test, y_pred)\n",
    "\n",
    "spent = time() - start\n",
    "print('process time: {:.2f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Suport Vector Machine, fed by TfidVectorizer:\n",
    "    \n",
    ">- now, the idea is to train another type of machine, a **Support Vector Machine** (SVM)\n",
    ">- SVM uses another philosophy, as you create a coordinate space for **vectors**\n",
    ">- the space coordinate system can be a **cartesian planes**, or **polar combinations**\n",
    ">- the idea is to sepparate data using vectors as **sepparation elements**\n",
    ">- in this case, whe use only **linear** elements to make de sepparation\n",
    "\n",
    "Why **Linear**?\n",
    "\n",
    ">- the **computational cost** for linear entities on **discrete** computers is really low (if we were using **valved** computers, we could start exploring **non-linear** models with better profit)\n",
    ">- now we ned **fit** and **transform** opperations on our vectors provider\n",
    ">- it is a **fast** machine (**18.84**seconds), with the amazing Model Accuracy of a bit less than **93%** (one of the features could not be trained!)\n",
    ">- when corrected **labels consistencies**, based on our **hierarchical structure**, Model Accuracy raised a bit, reaching **93.6**!\n",
    "\n",
    "**Version 1.12** update: preparation of a completely different kind of **Machine Learning Classifier**\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.17** for **Linear Support Vector** updated new, **more realistic** metrics based on **10 top** labels:\n",
    "\n",
    ">- Model Accuracy now is **70.6**%\n",
    ">- Precision now is **70.8**%\n",
    ">- Recall now is **71.1**%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR SUPPORT VECTOR MACHINE - process time:27.10 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "feats = TfidfVectorizer(analyzer='word', \n",
    "                        tokenizer=dummy, \n",
    "                        preprocessor=dummy,\n",
    "                        token_pattern=None,\n",
    "                        ngram_range=(1, 3))\n",
    "\n",
    "classif = OneVsRestClassifier(LinearSVC(C=2., \n",
    "                                        random_state=42))\n",
    "\n",
    "#don´t use this line, I thought it was necessary to to te sepparation!\n",
    "#feats = feats.fit_transform(X_train)\n",
    "\n",
    "pipeline_lnsv = Pipeline([('vect', feats),\n",
    "                          ('clf', classif)])\n",
    "\n",
    "pipeline_lnsv.fit(X_train, y_train)\n",
    "\n",
    "spent = time() - start\n",
    "print('LINEAR SUPPORT VECTOR MACHINE - process time:{:.2f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you experience:\n",
    "\n",
    "*NotFittedError: Vocabulary not fitted or provided*\n",
    "[here](https://stackoverflow.com/questions/60472925/python-scikit-svm-vocabulary-not-fitted-or-provided)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Test Area (for Version 1.16 improvement)\n",
    "\n",
    "I am trying to create new **fancy** metrics for scoring my Classifiers\n",
    "\n",
    ">- I was taking only the **General Average F1 Score** as metrics, and it seems so pooly detailed\n",
    "\n",
    "\n",
    "I have for most classified labels, according to my `fn_labels_report` function:\n",
    "\n",
    "1. related:19928 (75.9%)\n",
    "2. aid_related:10903 (41.5%)\n",
    "3. weather_related:7304 (27.8%)\n",
    "4. direct_report:5080 (19.4%)\n",
    "5. request:4480 (17.1%)\n",
    "6. other_aid:3448 (13.1%)\n",
    "7. food:2930 (11.2%)\n",
    "8. earthquake:2455 (9.4%)\n",
    "9. storm:2448 (9.3%)\n",
    "10. shelter:2319 (8.8%)\n",
    "11. floods:2158 (8.2%)\n",
    "\n",
    "When I remove **related** (as it will only classify as **\"1\"** for **All** my dataset, when I remove rows that have **no** classification at all - so, I cannot **train** on them), I will get these new columns as:\n",
    "\n",
    "1. aid_related\n",
    "2. weather_related\n",
    "3. direct_report\n",
    "4. request\n",
    "5. other_aid\n",
    "6. food\n",
    "7. earthquake\n",
    "8. storm\n",
    "9. shelter\n",
    "10. floods\n",
    "\n",
    "Turning them into a list:\n",
    "\n",
    "`top_labels = ['aid_related', 'weather_related', 'direct_report', 'request', 'other_aid', 'food', 'earthquake', 'storm', 'shelter', 'floods']`\n",
    "\n",
    "Retrieve their position by name [here](https://stackoverflow.com/questions/13021654/get-column-index-from-column-name-in-python-pandas):\n",
    "\n",
    "`y_test.columns.get_loc(\"offer\")`\n",
    "\n",
    "**Version 1.16** update: new `fn_scores_report2` function created\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.17** for **k-Nearest** updated new, **more realistic** metrics based on **10 top** labels:\n",
    "\n",
    ">- Model Accuracy now is **69.9**%\n",
    ">- Precision now is **70.8**%\n",
    ">- Recall now is **71.1**%\n",
    "\n",
    "**Version 1.18** for **Linear Support Vector Machine** letting the tokenizer take the same word more than once:\n",
    "\n",
    ">- Model Accuracy now is **70.5**%\n",
    ">- Precision now is **71.9**%\n",
    ">- Recall now is **69.7**%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###function scores_report started\n",
      "######################################################\n",
      "*aid_related -> label iloc[2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.56      0.64      2313\n",
      "           1       0.69      0.84      0.76      2668\n",
      "\n",
      "    accuracy                           0.71      4981\n",
      "   macro avg       0.72      0.70      0.70      4981\n",
      "weighted avg       0.72      0.71      0.70      4981\n",
      "\n",
      "######################################################\n",
      "*weather_related -> label iloc[26]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      3109\n",
      "           1       0.80      0.79      0.80      1872\n",
      "\n",
      "    accuracy                           0.85      4981\n",
      "   macro avg       0.84      0.84      0.84      4981\n",
      "weighted avg       0.85      0.85      0.85      4981\n",
      "\n",
      "######################################################\n",
      "*direct_report -> label iloc[33]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      3726\n",
      "           1       0.63      0.62      0.62      1255\n",
      "\n",
      "    accuracy                           0.81      4981\n",
      "   macro avg       0.75      0.75      0.75      4981\n",
      "weighted avg       0.81      0.81      0.81      4981\n",
      "\n",
      "######################################################\n",
      "*request -> label iloc[0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92      3884\n",
      "           1       0.71      0.71      0.71      1097\n",
      "\n",
      "    accuracy                           0.87      4981\n",
      "   macro avg       0.81      0.81      0.81      4981\n",
      "weighted avg       0.87      0.87      0.87      4981\n",
      "\n",
      "######################################################\n",
      "*other_aid -> label iloc[16]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.90      4163\n",
      "           1       0.45      0.36      0.40       818\n",
      "\n",
      "    accuracy                           0.82      4981\n",
      "   macro avg       0.66      0.64      0.65      4981\n",
      "weighted avg       0.81      0.82      0.81      4981\n",
      "\n",
      "######################################################\n",
      "*food -> label iloc[9]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      4266\n",
      "           1       0.78      0.81      0.79       715\n",
      "\n",
      "    accuracy                           0.94      4981\n",
      "   macro avg       0.88      0.88      0.88      4981\n",
      "weighted avg       0.94      0.94      0.94      4981\n",
      "\n",
      "######################################################\n",
      "*earthquake -> label iloc[30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      4384\n",
      "           1       0.86      0.78      0.82       597\n",
      "\n",
      "    accuracy                           0.96      4981\n",
      "   macro avg       0.92      0.88      0.90      4981\n",
      "weighted avg       0.96      0.96      0.96      4981\n",
      "\n",
      "######################################################\n",
      "*storm -> label iloc[28]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4371\n",
      "           1       0.73      0.72      0.72       610\n",
      "\n",
      "    accuracy                           0.93      4981\n",
      "   macro avg       0.84      0.84      0.84      4981\n",
      "weighted avg       0.93      0.93      0.93      4981\n",
      "\n",
      "######################################################\n",
      "*shelter -> label iloc[10]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      4410\n",
      "           1       0.73      0.69      0.71       571\n",
      "\n",
      "    accuracy                           0.94      4981\n",
      "   macro avg       0.85      0.83      0.84      4981\n",
      "weighted avg       0.93      0.94      0.93      4981\n",
      "\n",
      "######################################################\n",
      "*floods -> label iloc[27]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97      4412\n",
      "           1       0.81      0.65      0.72       569\n",
      "\n",
      "    accuracy                           0.94      4981\n",
      "   macro avg       0.88      0.81      0.84      4981\n",
      "weighted avg       0.94      0.94      0.94      4981\n",
      "\n",
      "###Model metrics for 10 labels:\n",
      " Accuracy: 0.705 (70.5%)\n",
      " Precision: 0.719 (71.9%)\n",
      " Recall: 0.697 (69.7%)\n",
      "\n",
      "###Worst metrics:\n",
      " Accuracy: 0.398 (39.8%) for other_aid\n",
      " Precision: 0.447 (44.7%) for other_aid\n",
      " Recall: 0.358 (35.8%) for other_aid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7051297978208334, 0.7187426419336524, 0.6965549902942181)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipeline_lnsv.predict(X_test)\n",
    "udacourse2.fn_scores_report2(y_test, \n",
    "                             y_pred,\n",
    "                             best_10=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don´t use this function! (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = pipeline_lnsv.predict(X_test)\n",
    "#udacourse2.fn_scores_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Make a Fine Tunning effort over Classifiers\n",
    "\n",
    "#### First attempt: Stochastic Gradient Descent\n",
    "\n",
    "**Grid Search**\n",
    "\n",
    "`parameters = {'vect__ngram_range': [(1, 1), (1, 2)],`\n",
    "              `'tfidf__use_idf': (True, False),`\n",
    "              `'clf__alpha': (1e-2, 1e-3)}`\n",
    "\n",
    "- use **multiple cores** to process the task\n",
    "\n",
    "`gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)`\n",
    "\n",
    "`gs_clf = gs_clf.fit(twenty_train.data, twenty_train.target)`\n",
    "\n",
    "-see the **mean score** of the parameters\n",
    "\n",
    "`gs_clf.best_score_`\n",
    "\n",
    "`gs_clf.best_params_`\n",
    "\n",
    "*Not implemented, by the reason that our SGD effort was abandonned. Only some  sketches from my studies for GridSearch on SGD remain here! (source, SKlearn parameters + documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)*\n",
    "\n",
    "#### Second attempt: k-Neighbors\n",
    "\n",
    ">- we can see tunable parameters using the command `Class_k.get_params()`\n",
    ">- I tried to tune up for `n_neighbors` and for `p`\n",
    ">- it took **74** minutes and **15** seconds to run (so, don´t try it!)\n",
    ">- best estimator was **n_neighbors=7** and **p=1** $\\rightarrow$ \"Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1)\" (from SkLearn documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version 1.13** update: implemented **Grid Search** for some sellected Classifiers\n",
    "\n",
    "**Future implementation**: test other parameters for a better fine-tunning (I don't made an **exaustive fine-tunning**!)\n",
    "\n",
    "Don´t use this code, it takes too much time to process!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = time()\n",
    "\n",
    "#def dummy(doc):\n",
    "#    return doc\n",
    "\n",
    "\n",
    "#k-Neighbors don´t use randomization\n",
    "#Vect_k = CountVectorizer(tokenizer=dummy, preprocessor=dummy)\n",
    "#Transf_k = TfidfTransformer()\n",
    "#Class_k = MultiOutputClassifier(KNeighborsClassifier())\n",
    "\n",
    "#pipeline_knbr = Pipeline([('vect', Vect_k),\n",
    "#                          ('tfidf', Transf_k),\n",
    "#                          ('clf', Class_k)])\n",
    "\n",
    "#param_dict = {'clf__estimator__n_neighbors': [3,5,7],\n",
    "#              'clf__estimator__p': [1,2]}\n",
    "\n",
    "#estimator = GridSearchCV(estimator=pipeline_knbr, \n",
    "#                         param_grid=param_dict,\n",
    "#                         n_jobs=-1) #, scoring='roc_auc')\n",
    "\n",
    "#estimator.fit(X_train, y_train)\n",
    "\n",
    "#spent = time() - start\n",
    "#s_min = spent // 60\n",
    "#print('K NEIGHBORS CLASSIFIER - process time: {:.0f} minutes, {:.2f} seconds ({:.2f}s)'\\\n",
    "#      .format(s_min, spent-(s_min*60), spent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit_knbr.best_estimator_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear SVC**: new parameter found by using **Grid Search**\n",
    "\n",
    "- `C=0.5`\n",
    "\n",
    "- run time for training the Classifier is **4**min **26**sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LINEAR SUPPORT VECTOR MACHINE - process time: 4 minutes, 30.83 seconds (270.83s)\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "feats = TfidfVectorizer(analyzer='word', \n",
    "                        tokenizer=dummy, \n",
    "                        preprocessor=dummy,\n",
    "                        token_pattern=None,\n",
    "                        ngram_range=(1, 3))\n",
    "classif = OneVsRestClassifier(LinearSVC())\n",
    "\n",
    "pipeline_lnsv = Pipeline([('vect', feats),\n",
    "                          ('clf', classif)])\n",
    "\n",
    "\n",
    "param_dict = {'clf__estimator__C': [0.1,0.5,1.0,2.0,5.0]}\n",
    "\n",
    "estimator = GridSearchCV(estimator=pipeline_lnsv, \n",
    "                         param_grid=param_dict,\n",
    "                         n_jobs=-1) #, scoring='roc_auc')\n",
    "\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "spent = time() - start\n",
    "s_min = spent // 60\n",
    "print('LINEAR SUPPORT VECTOR MACHINE - process time: {:.0f} minutes, {:.2f} seconds ({:.2f}s)'\\\n",
    "      .format(s_min, spent-(s_min*60), spent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classif.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(ngram_range=(1, 3),\n",
       "                                 preprocessor=<function dummy at 0x0000022B95B5AC18>,\n",
       "                                 token_pattern=None,\n",
       "                                 tokenizer=<function dummy at 0x0000022B95B5AC18>)),\n",
       "                ('clf', OneVsRestClassifier(estimator=LinearSVC(C=0.5)))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.best_estimator_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NotFittedError: Vocabulary not fitted or provided*\n",
    "[here](https://stackoverflow.com/questions/60472925/python-scikit-svm-vocabulary-not-fitted-or-provided)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Choosing my Classifier\n",
    "\n",
    "### Classifiers Training & Tunning Summary\n",
    "\n",
    "\n",
    "|      Classifier      | Model Accuracy | Time to Train |           Observation          |\n",
    "|:--------------------:|:--------------:|:-------------:|:------------------------------:|\n",
    "| Binomial Naive Bayes | less than 82%  | 0.68s         | 22 labels couldn't be trained! |\n",
    "| Random Forest        | less than 90%  | 11m 44s       | 3 labels couldn't be trained!  |\n",
    "| Adaboost             | 93.6%          | 100.5s        |                                |\n",
    "| k-Neighbors          | less than 90%  | 0.58s         | 3 labels couldn't be trained!  |\n",
    "| Linear SVM           | less than 93%  | 26.81s        | 2 labels couldn't be trained!  |\n",
    "\n",
    "*thanks for the service Tables Generator [here](https://www.tablesgenerator.com/markdown_tables)\n",
    "\n",
    "#### In my concept, the rank is\n",
    "\n",
    "**First** place, Adaboost. It seemed **reliable** and **fast** for this particular task, and it is a neat machine, really easy to understand\n",
    "\n",
    "**Second** place, Linear SVM. Some of these labels are really **hard** to train and it was really **fast**\n",
    "\n",
    "**Third** place, k-Neighbors. It is **fast** and seeme so realiable as **Random Forest**, that is **too hard** to train\n",
    "\n",
    "---\n",
    "\n",
    "And I will take... **Linear SVM**!\n",
    "\n",
    "*Why? just because I cannot **really** believe that some of these labels can be trained!*\n",
    "\n",
    "The \"bad guy\" were `tools`, `shops`, `aid centers` and the **real** problem involved is:\n",
    "\n",
    ">- `shops` $\\rightarrow$ 120\n",
    ">- `tools` $\\rightarrow$ 159\n",
    ">- `aid_centers` $\\rightarrow$ 309\n",
    "\n",
    ">- there are so **few** labelled rows for these 3 guys that I really cannot believe that any Machine Learning Classifier can really **train** for them!\n",
    ">- and what about **Adaboost**? Well, Adaboost is based on **stumps** algorithm. And by processing the data, it cannot really reach a true **zero**, as the stumps inside them do not allow this kind of thing. So, instead of a **1**, it will give you a **0.999%**, that worth nothing for practical uses\n",
    ">- lately I can run more **GridSearch** and over **Linear SVM**. Adaboost don't have so much options for future improvement\n",
    "\n",
    "So, I will use in my model **Linear SVM**\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.14** update: filtering for **valid** ones over critical labels\n",
    "\n",
    "Choosen model changed to **Adaboost**. Why?\n",
    "\n",
    ">- conting for **valid** labels showed that these labels are in fact **trainable**, but that is not so easy to do it\n",
    ">- probably they are pressed to **zero**, as there are much more **false negatives** under these labels\n",
    "\n",
    "**Future version** - as my labels columns are clearly **hierarchical**:\n",
    "\n",
    ">- I could break my original dataset into 3 **more specific** datasets, as `infrastructure_related`, `aid_related` and `weather_related`, and include in each one the rows that are **relevant**\n",
    ">- In this case, the noise caused by **false negatives** will decrease, turning easier for each training achieve a better score\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.17** updated: metrics **changed**, so my choice may change too!\n",
    "\n",
    "New table for **Classifier evaluation** (10 greatest labels):\n",
    "\n",
    "|      Classifier      | Precision | Recall | Worst Metrics |\n",
    "|:--------------------:|:---------:|:------:|:-------------:|\n",
    "| Binomial Naïve Bayes | 85.9%     | 26.4%  | 65.6% & 0.1%  |\n",
    "| Random Forest        | 79.8%     | 60.1%  | 62.2% & 8.4%  |\n",
    "| Adaboost             | 77.7%     | 58.7%  | 48.4% & 20.4% |\n",
    "| k-Neighbors          | 60.1%     | 32.6%  | 28.6% & 1.2%  |\n",
    "| Linear SVM           | 70.8%     | 71.1%  | 43.0% & 32.5% |\n",
    "\n",
    "*Random Forest is very **slow** to fit!*\n",
    "*k-Neighbors is really **slow** to predict!*\n",
    "\n",
    "So, now I can see a lot of advantage for choosing **Linear SVM**:\n",
    "\n",
    ">- it is not **slow** for fit/train\n",
    ">- I can later explorer other better parameters using **GridSearch**\n",
    ">- It **don´t decay** so fast, for labels without so much rows for train\n",
    "\n",
    "My second choice is **Adaboost**\n",
    "\n",
    "*If things don´t go pretty well, I have a fancy alternative!*\n",
    "\n",
    "**Version 1.18**: letting the tokenizer take the same word more than once:\n",
    "\n",
    "|      Classifier      | Precision | Recall | Worst Metrics | Observations                  |\n",
    "|:--------------------:|:---------:|:------:|:-------------:|:-----------------------------:|\n",
    "| Binomial Naïve Bayes | 86.3%     | 26.6%  | 64.5% & 0.1%  | Imperceptible changes         |\n",
    "| Random Forest        | 79.8%     | 59.7%  | 61.8% & 9.3%  | Recall lowered a bit          |\n",
    "| Adaboost             | 77.3%     | 55.8%  | 46.1% & 15.9% | Recall lowered a bit          |\n",
    "| k-Neighbors          | 60.5%     | 32.2%  | 29.5% & 1.9%  | Parameters slightly increased |\n",
    "| Linear SVM           | 70.5%     | 71.9%  | 44.7% & 35.8% | Parameters slightly increased |\n",
    "\n",
    "*Fo, I will **keep** my tokenizer letting repeated tokens for each message, as I choose to use **Linear SVM**. If in future, training will turn so slow (as I get more and more messages at my dataset for training), I can go back to the earlier setting (only unique tokens per message)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying the amount of **positive** data for **few** data on the labels:\n",
    "\n",
    "- observe that `child_alone` was previously removed from our training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "offer             118.0\n",
       "missing_people    299.0\n",
       "tools             159.0\n",
       "hospitals         283.0\n",
       "shops             120.0\n",
       "aid_centers       309.0\n",
       "fire              282.0\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df[df.columns[5:]]\n",
    "a = df2.apply(pd.Series.value_counts).loc[1]\n",
    "a[a < 400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean score of the parameters\n",
    "#gs_clf.best_score_\n",
    "#gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Choose your model, with the fine tunning already done (this can be changed later!)\n",
    "\n",
    "How to deal with picke [here](https://www.codegrepper.com/code-examples/python/save+and+load+python+pickle+stackoverflow)\n",
    "\n",
    "Pickle documentation [here](https://docs.python.org/3/library/pickle.html#module-pickle)\n",
    "\n",
    "2. Final considerations about this model:\n",
    "\n",
    ">- I choosed **Adaboost** as our Classifier\n",
    ">- The explanation for my choice is at the item **above**\n",
    "\n",
    "---\n",
    "\n",
    "**Version 1.18** update: now my Classifier was changed to **Linear SVC**. The explanations for my choice rests **above**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying the **Demo** code, that I found at **Codegreeper.com**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dic = {'hello': 'world'}\n",
    "\n",
    "with open('filename.pkl', 'wb') as pk_writer: #wb is for write+binary\n",
    "    pickle.dump(dic, \n",
    "                pk_writer, \n",
    "                protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('filename.pkl', 'rb') as pk_reader: #rb is for read+binary\n",
    "    dic_unpk = pickle.load(pk_reader)\n",
    "\n",
    "print (dic == dic_unpk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'classifier.pkl'\n",
    "\n",
    "with open (file_name, 'wb') as pk_writer: \n",
    "    pickle.dump(pipeline_lnsv, pk_writer)\n",
    "    \n",
    "with open('classifier.pkl', 'rb') as pk_reader: #rb is for read+binary\n",
    "    pipeline_lnsv = pickle.load(pk_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lnsv.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X. Use the notebook to complete `train.py`\n",
    "\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "under development",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-5cacf03ea685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'under development'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: under development"
     ]
    }
   ],
   "source": [
    "raise Exception('under development')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import udacourse2 #my library for this project!\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "#SQLAlchemy toolkit\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import pool\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "#Machine Learning preparing/preprocessing toolkits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Machine Learning Feature Extraction tools\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Machine Learning Classifiers\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "#Machine Learning Classifiers extra tools\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#pickling tool\n",
    "import pickle\n",
    "\n",
    "#only a dummy function, as I pre-tokenize my data\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "#########1#########2#########3#########4#########5#########6#########7#########8\n",
    "def load_data(data_file, \n",
    "              verbose=False):\n",
    "    '''This function takes a path for a MySQL table and returns processed data\n",
    "    for training a Machine Learning Classifier\n",
    "    Inputs:\n",
    "      - data_file (mandatory) - full path for SQLite table - text string\n",
    "      - verbose (optional) - if you want some verbosity during the running \n",
    "        (default=False)\n",
    "    Outputs:\n",
    "      - X - tokenized text X-training - Pandas Series\n",
    "      - y - y-multilabels 0|1 - Pandas Dataframe'''\n",
    "    if verbose:\n",
    "        print('###load_data function started')\n",
    "    start = time()\n",
    "\n",
    "    #1.read in file\n",
    "    #importing MySQL to Pandas - load data from database\n",
    "    engine = create_engine(data_file, poolclass=pool.NullPool) #, echo=True)\n",
    "    #retrieving tables names from my DB\n",
    "    inspector = inspect(engine)\n",
    "    if verbose:\n",
    "        print('existing tables in my SQLite database:', inspector.get_table_names())\n",
    "    connection = engine.connect()\n",
    "    df = pd.read_sql('SELECT * FROM Messages', con=connection)\n",
    "    connection.close()\n",
    "    df.name = 'df'\n",
    "    \n",
    "    #2.clean data\n",
    "    #2.1.Elliminate rows with all-blank labels\n",
    "    if verbose:\n",
    "        print('all labels are blank in {} rows'.format(df[df['if_blank'] == 1].shape[0]))\n",
    "    df = df[df['if_blank'] == 0]\n",
    "    if verbose:\n",
    "        print('remaining rows:', df.shape[0])\n",
    "    #Verifying if removal was complete\n",
    "    if df[df['if_blank'] == 1].shape[0] == 0:\n",
    "        if verbose:\n",
    "            print('removal complete!')\n",
    "        else:\n",
    "            raise Exception('something went wrong with rows removal before training')\n",
    "            \n",
    "    #2.2.Premature Tokenization Strategy (pre-tokenizer)\n",
    "    #Pre-Tokenizer + not removing provisory tokenized column\n",
    "    #inserting a tokenized column\n",
    "    try:\n",
    "        df = df.drop('tokenized', axis=1)\n",
    "    except KeyError:\n",
    "        print('OK')\n",
    "    df.insert(1, 'tokenized', np.nan)\n",
    "    #tokenizing over the provisory\n",
    "    df['tokenized'] = df.apply(lambda x: udacourse2.fn_tokenize_fast(x['message']), axis=1)\n",
    "    #removing NaN over provisory (if istill exist)\n",
    "    df = df[df['tokenized'].notnull()]\n",
    "    empty_tokens = df[df['tokenized'].apply(lambda x: len(x)) == 0].shape[0]\n",
    "    if verbose:\n",
    "        print('found {} rows with no tokens'.format(empty_tokens))\n",
    "    df = df[df['tokenized'].apply(lambda x: len(x)) > 0]\n",
    "    empty_tokens = df[df['tokenized'].apply(lambda x: len(x)) == 0].shape[0]\n",
    "    if verbose:\n",
    "        print('*after removal, found {} rows with no tokens'.format(empty_tokens))\n",
    "    #I will drop the original 'message' column\n",
    "    try:\n",
    "        df = df.drop('message', axis=1)\n",
    "    except KeyError:\n",
    "        if verbose:\n",
    "            print('OK')\n",
    "    if verbose:\n",
    "        print('now I have {} rows to train'.format(df.shape[0]))\n",
    "\n",
    "    #2.3.Database Data Consistency Check/Fix\n",
    "    #correction for aid_related\n",
    "    df = udacourse2.fn_group_check(dataset=df,\n",
    "                                   subset='aid',\n",
    "                                   correct=True, \n",
    "                                   shrink=False, \n",
    "                                   shorten=False, \n",
    "                                   verbose=True)\n",
    "    #correction for weather_related\n",
    "    df = udacourse2.fn_group_check(dataset=df,\n",
    "                                   subset='wtr',\n",
    "                                   correct=True, \n",
    "                                   shrink=False, \n",
    "                                   shorten=False, \n",
    "                                   verbose=True)\n",
    "    #correction for infrastrucutre_related\n",
    "    df = udacourse2.fn_group_check(dataset=df,\n",
    "                                   subset='ifr',\n",
    "                                   correct=True, \n",
    "                                   shrink=False, \n",
    "                                   shorten=False, \n",
    "                                   verbose=True)\n",
    "    #correction for related(considering that the earlier were already corrected)\n",
    "    df = udacourse2.fn_group_check(dataset=df,\n",
    "                                   subset='main',\n",
    "                                   correct=True, \n",
    "                                   shrink=False, \n",
    "                                   shorten=False, \n",
    "                                   verbose=True)\n",
    "    \n",
    "    #load to database <-I don't know for what it is\n",
    "    \n",
    "    #3.Define features and label arrays (break the data)\n",
    "    #3.1.X is the Training Text Column\n",
    "    X = df['tokenized']\n",
    "    #3.2.y is the Classification labels\n",
    "    #I REMOVED \"related\" column from my labels, as it is impossible to train it!\n",
    "    y = df[df.columns[5:]]\n",
    "    remove_lst = []\n",
    "\n",
    "    for column in y.columns:\n",
    "        col = y[column]\n",
    "        if (col == 0).all():\n",
    "            if verbose:\n",
    "                print('*{} -> only zeroes training column!'.format(column))\n",
    "            remove_lst.append(column)\n",
    "        else:\n",
    "            #print('*{} -> column OK'.format(column))\n",
    "            pass\n",
    "        \n",
    "    if verbose:\n",
    "        print(remove_lst)\n",
    "    y = y.drop(remove_lst, axis=1)\n",
    "    \n",
    "    spent = time() - start\n",
    "    if verbose:\n",
    "        print('*dataset breaked into X-Training Text Column and Y-Multilabels')    \n",
    "        print('process time:{:.0f} seconds'.format(spent))\n",
    "    return X, y\n",
    "\n",
    "#########1#########2#########3#########4#########5#########6#########7#########8\n",
    "def build_model(verbose=False):\n",
    "    '''This function builds the Classifier Pipeline, for future fitting\n",
    "    Inputs:\n",
    "      - verbose (optional) - if you want some verbosity during the running \n",
    "        (default=False)\n",
    "    Output:\n",
    "      - model_pipeline for your Classifiear (untrained)\n",
    "    '''\n",
    "    if verbose:\n",
    "        print('###build_model function started')\n",
    "    start = time()\n",
    "    \n",
    "    #1.text processing and model pipeline\n",
    "    #(text processing was made at a earlier step, at Load Data function)\n",
    "    feats = TfidfVectorizer(analyzer='word', \n",
    "                            tokenizer=dummy, \n",
    "                            preprocessor=dummy,\n",
    "                            token_pattern=None,\n",
    "                            ngram_range=(1, 3))\n",
    "    \n",
    "    classif = OneVsRestClassifier(LinearSVC(C=2., \n",
    "                                            random_state=42))\n",
    "    \n",
    "    model_pipeline = Pipeline([('vect', feats),\n",
    "                               ('clf', classif)])\n",
    "    \n",
    "    #define parameters for GridSearchCV (parameters already defined)\n",
    "    #create gridsearch object and return as final model pipeline (made at pipeline preparation)\n",
    "    #obs: for better performance, I pre-tokenized my data. And GridSearch was runned on Jupyter,\n",
    "    #     and the best parameters where adjusted, just to save processing time during code execution.\n",
    "    spent = time() - start\n",
    "    if verbose:\n",
    "        print('*Linear Support Vector Machine pipeline was created')\n",
    "        print('process time:{:.0f} seconds'.format(spent))\n",
    "    return model_pipeline\n",
    "\n",
    "#########1#########2#########3#########4#########5#########6#########7#########8\n",
    "def train(X, \n",
    "          y, \n",
    "          model, \n",
    "          verbose=False):\n",
    "    '''This function trains your already created Classifier Pipeline\n",
    "    Inputs:\n",
    "      - X (mandatory) - tokenized data for training - Pandas Series\n",
    "      - y (mandatory) - Multilabels 0|1 - Pandas Dataset\n",
    "      - verbose (optional) - if you want some verbosity during the running \n",
    "        (default=False)\n",
    "    Output:\n",
    "      - trained model'''\n",
    "    if verbose:\n",
    "        print('###train function started')\n",
    "    start = time()\n",
    "\n",
    "    #1.Train test split\n",
    "    #Split makes randomization, so random_state parameter was set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                        y, \n",
    "                                                        test_size=0.25, \n",
    "                                                        random_state=42)\n",
    "    if (X_train.shape[0] + X_test.shape[0]) == X.shape[0]:\n",
    "        if verbose:\n",
    "            print('data split into train and text seems OK')\n",
    "    else:\n",
    "        raise Exception('something went wrong when splitting the data')\n",
    "        \n",
    "    #2.fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # output model test results\n",
    "    y_pred = model.predict(X_test)\n",
    "    if verbose:\n",
    "        metrics = udacourse2.fn_scores_report2(y_test, \n",
    "                                               y_pred,\n",
    "                                               best_10=True,\n",
    "                                               verbose=True)\n",
    "    else:\n",
    "        metrics = udacourse2.fn_scores_report2(y_test, \n",
    "                                               y_pred,\n",
    "                                               best_10=True,\n",
    "                                               verbose=False)\n",
    "\n",
    "    for metric in metrics:\n",
    "        if metric < 0.6:\n",
    "            raise Exception('something is wrong, model is predicting poorly')\n",
    "\n",
    "    spent = time() - start\n",
    "    if verbose:\n",
    "        print('*classifier was trained!')\n",
    "        print('process time:{:.0f} seconds'.format(spent))\n",
    "    return model\n",
    "\n",
    "#########1#########2#########3#########4#########5#########6#########7#########8\n",
    "def export_model(model,\n",
    "                 file_name='classifier.pkl',\n",
    "                 verbose=False):\n",
    "    '''This function writes your already trained Classifiear as a Picke Binary\n",
    "    file.\n",
    "    Inputs:\n",
    "      - model (mandatory) - your already trained Classifiear - Python Object\n",
    "      - file_name (optional) - the name of the file to be created (default:\n",
    "         'classifier.pkl')\n",
    "      - verbose (optional) - if you want some verbosity during the running \n",
    "        (default=False)\n",
    "       Output: return True if everything runs OK\n",
    "      ''' \n",
    "    if verbose:\n",
    "        print('###export_model function started')\n",
    "    start = time()\n",
    "\n",
    "    #1.Export model as a pickle file\n",
    "    file_name = file_name\n",
    "\n",
    "    #writing the file\n",
    "    with open (file_name, 'wb') as pk_writer: \n",
    "        pickle.dump(model, pk_writer)\n",
    "\n",
    "    #reading the file\n",
    "    #with open('classifier.pkl', 'rb') as pk_reader:\n",
    "    #    model = pickle.load(pk_reader)\n",
    "    \n",
    "    spent = time() - start\n",
    "    if verbose:\n",
    "        print('*trained Classifier was exported')\n",
    "        print('process time:{:.0f} seconds'.format(spent))\n",
    "        \n",
    "    return True\n",
    "\n",
    "#########1#########2#########3#########4#########5#########6#########7#########8\n",
    "def run_pipeline(data_file='sqlite:///Messages.db', \n",
    "                 verbose=False):\n",
    "    '''This function is a caller: it calls load, build, train and save modules\n",
    "    Inputs:\n",
    "      - data_file (optional) - complete path to the SQLite datafile to be \n",
    "        processed - (default='sqlite:///Messages.db')\n",
    "      - verbose (optional) - if you want some verbosity during the running \n",
    "        (default=False)\n",
    "    Output: return True if everything runs OK\n",
    "    '''\n",
    "    if verbose:\n",
    "        print('###run_pipeline function started')\n",
    "    start = time()\n",
    "\n",
    "    #1.Run ETL pipeline\n",
    "    X, y = load_data(data_file, \n",
    "                     verbose=verbose)\n",
    "    #2.Build model pipeline\n",
    "    model = build_model(verbose=verbose)\n",
    "    #3.Train model pipeline\n",
    "    model = train(X, \n",
    "                  y, \n",
    "                  model, \n",
    "                  verbose=verbose)\n",
    "    # save the model\n",
    "    export_model(model,\n",
    "                 verbose=verbose)\n",
    "    \n",
    "    spent = time() - start\n",
    "    if verbose:\n",
    "        print('process time:{:.0f} seconds'.format(spent))\n",
    "    return True\n",
    "\n",
    "#########1#########2#########3#########4#########5#########6#########7#########8\n",
    "def main():\n",
    "    '''This is the main Machine Learning Pipeline function. It calls the other \n",
    "    ones, in the correctorder.\n",
    "    '''\n",
    "    data_file = sys.argv[1]  # get filename of dataset\n",
    "    run_pipeline(data_file='sqlite:///Messages.db',\n",
    "                 verbose=True)\n",
    "\n",
    "#########1#########2#########3#########4#########5#########6#########7#########8\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`P@k` implementation [here](https://medium.com/analytics-vidhya/metrics-for-multi-label-classification-49cc5aeba1c3#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjgxOWQxZTYxNDI5ZGQzZDNjYWVmMTI5YzBhYzJiYWU4YzZkNDZmYmMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2MzAyNzYxNDYsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwNTAzNjUxNTUwMDU1MTQ1OTkzNSIsImVtYWlsIjoiZXBhc3NldG9AZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImF6cCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsIm5hbWUiOiJFZHVhcmRvIFBhc3NldG8iLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EtL0FPaDE0R2pJNmh5V3FSTGNfdHZCYlg4OWxFTEphZ3diMFBYeXJNOGN1YXBLR1E9czk2LWMiLCJnaXZlbl9uYW1lIjoiRWR1YXJkbyIsImZhbWlseV9uYW1lIjoiUGFzc2V0byIsImlhdCI6MTYzMDI3NjQ0NiwiZXhwIjoxNjMwMjgwMDQ2LCJqdGkiOiIzYzYyZThiZDhkYWU4YjU4NWJlZDI4ZGFhYjE5ZDkwY2MyOTFmNjhlIn0.kwd1YjjoxP-RUFHA86RftkGHMMwic3edRM31Yz8sJL9dg0jzPwS2c9peJ9kDuIQK5x8PWvZxhnl-wI32M_D_FvWv5UXad1cYnkuEGnxeo94LPCUam-aOnUvDDpefUEOv8Oe2751C0VH1MrlDiOQxyGcYBIjnr2NtdaN8Y8pm-ZLonqw3zpZO-2Wlkhnrb12ruZmpWD2CbqZCHpNwmYq0bQqCrNp_dCZ9mBjc5xrYN2G8Us7ESZcCnqLLjk_cb6UVV81LFjKkrjGifBsOac-ANoc7TBJQnFW41FISORWL8j84mW7jl8UgEmxrgc8kaFtHm6oC5ptc9YLRBDq1Q93ZBQ)\n",
    "\n",
    "\"Given a list of actual classes and predicted classes, precision at k would be defined as the number of correct predictions considering only the top k elements of each class divided by k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patk(actual, pred, k):\n",
    "\t#we return 0 if k is 0 because \n",
    "\t#   we can't divide the no of common values by 0 \n",
    "\tif k == 0:\n",
    "\t\treturn 0\n",
    "\n",
    "\t#taking only the top k predictions in a class \n",
    "\tk_pred = pred[:k]\n",
    "\n",
    "\t#taking the set of the actual values \n",
    "\tactual_set = set(actual)\n",
    "\n",
    "\t#taking the set of the predicted values \n",
    "\tpred_set = set(k_pred)\n",
    "\n",
    "\t#taking the intersection of the actual set and the pred set\n",
    "\t\t# to find the common values\n",
    "\tcommon_values = actual_set.intersection(pred_set)\n",
    "\n",
    "\treturn len(common_values)/len(pred[:k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the values of the actual and the predicted class\n",
    "y_true = [1 ,2, 0]\n",
    "y_pred = [1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(patk(y_true, y_pred,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AP@k` implementation [here](https://medium.com/analytics-vidhya/metrics-for-multi-label-classification-49cc5aeba1c3#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjgxOWQxZTYxNDI5ZGQzZDNjYWVmMTI5YzBhYzJiYWU4YzZkNDZmYmMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2MzAyNzYxNDYsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwNTAzNjUxNTUwMDU1MTQ1OTkzNSIsImVtYWlsIjoiZXBhc3NldG9AZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImF6cCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsIm5hbWUiOiJFZHVhcmRvIFBhc3NldG8iLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EtL0FPaDE0R2pJNmh5V3FSTGNfdHZCYlg4OWxFTEphZ3diMFBYeXJNOGN1YXBLR1E9czk2LWMiLCJnaXZlbl9uYW1lIjoiRWR1YXJkbyIsImZhbWlseV9uYW1lIjoiUGFzc2V0byIsImlhdCI6MTYzMDI3NjQ0NiwiZXhwIjoxNjMwMjgwMDQ2LCJqdGkiOiIzYzYyZThiZDhkYWU4YjU4NWJlZDI4ZGFhYjE5ZDkwY2MyOTFmNjhlIn0.kwd1YjjoxP-RUFHA86RftkGHMMwic3edRM31Yz8sJL9dg0jzPwS2c9peJ9kDuIQK5x8PWvZxhnl-wI32M_D_FvWv5UXad1cYnkuEGnxeo94LPCUam-aOnUvDDpefUEOv8Oe2751C0VH1MrlDiOQxyGcYBIjnr2NtdaN8Y8pm-ZLonqw3zpZO-2Wlkhnrb12ruZmpWD2CbqZCHpNwmYq0bQqCrNp_dCZ9mBjc5xrYN2G8Us7ESZcCnqLLjk_cb6UVV81LFjKkrjGifBsOac-ANoc7TBJQnFW41FISORWL8j84mW7jl8UgEmxrgc8kaFtHm6oC5ptc9YLRBDq1Q93ZBQ)\n",
    "\n",
    "\"It is defined as the average of all the precision at k for k =1 to k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apatk(acutal, pred, k):\n",
    "\t#creating a list for storing the values of precision for each k \n",
    "\tprecision_ = []\n",
    "\tfor i in range(1, k+1):\n",
    "\t\t#calculating the precision at different values of k \n",
    "\t\t#      and appending them to the list \n",
    "\t\tprecision_.append(pk.patk(acutal, pred, i))\n",
    "\n",
    "\t#return 0 if there are no values in the list\n",
    "\tif len(precision_) == 0:\n",
    "\t\treturn 0 \n",
    "\n",
    "\t#returning the average of all the precision values\n",
    "\treturn np.mean(precision_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the values of the actual and the predicted class\n",
    "y_true = [[1,2,0,1], [0,4], [3], [1,2]]\n",
    "y_pred = [[1,1,0,1], [1,4], [2], [1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tfor i in range(len(y_true)):\n",
    "\t\tfor j in range(1, 4):\n",
    "\t\t\tprint(\n",
    "\t\t\t\tf\"\"\"\n",
    "\t\t\t\ty_true = {y_true[i]}\n",
    "\t\t\t\ty_pred = {y_pred[i]}\n",
    "\t\t\t\tAP@{j} = {apatk(y_true[i], y_pred[i], k=j)}\n",
    "\t\t\t\t\"\"\"\n",
    "\t\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MAP@k` implementation [here](https://medium.com/analytics-vidhya/metrics-for-multi-label-classification-49cc5aeba1c3#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjgxOWQxZTYxNDI5ZGQzZDNjYWVmMTI5YzBhYzJiYWU4YzZkNDZmYmMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2MzAyNzYxNDYsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwNTAzNjUxNTUwMDU1MTQ1OTkzNSIsImVtYWlsIjoiZXBhc3NldG9AZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImF6cCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsIm5hbWUiOiJFZHVhcmRvIFBhc3NldG8iLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EtL0FPaDE0R2pJNmh5V3FSTGNfdHZCYlg4OWxFTEphZ3diMFBYeXJNOGN1YXBLR1E9czk2LWMiLCJnaXZlbl9uYW1lIjoiRWR1YXJkbyIsImZhbWlseV9uYW1lIjoiUGFzc2V0byIsImlhdCI6MTYzMDI3NjQ0NiwiZXhwIjoxNjMwMjgwMDQ2LCJqdGkiOiIzYzYyZThiZDhkYWU4YjU4NWJlZDI4ZGFhYjE5ZDkwY2MyOTFmNjhlIn0.kwd1YjjoxP-RUFHA86RftkGHMMwic3edRM31Yz8sJL9dg0jzPwS2c9peJ9kDuIQK5x8PWvZxhnl-wI32M_D_FvWv5UXad1cYnkuEGnxeo94LPCUam-aOnUvDDpefUEOv8Oe2751C0VH1MrlDiOQxyGcYBIjnr2NtdaN8Y8pm-ZLonqw3zpZO-2Wlkhnrb12ruZmpWD2CbqZCHpNwmYq0bQqCrNp_dCZ9mBjc5xrYN2G8Us7ESZcCnqLLjk_cb6UVV81LFjKkrjGifBsOac-ANoc7TBJQnFW41FISORWL8j84mW7jl8UgEmxrgc8kaFtHm6oC5ptc9YLRBDq1Q93ZBQ)\n",
    "\n",
    "\"The average of all the values of `AP@k` over the whole training data is known as `MAP@k`. This helps us give an accurate representation of the accuracy of whole prediction data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import apk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapk(acutal, pred, k):\n",
    "\n",
    "\t#creating a list for storing the Average Precision Values\n",
    "\taverage_precision = []\n",
    "\t#interating through the whole data and calculating the apk for each \n",
    "\tfor i in range(len(acutal)):\n",
    "\t\taverage_precision.append(apk.apatk(acutal[i], pred[i], k))\n",
    "\n",
    "\t#returning the mean of all the data\n",
    "\treturn np.mean(average_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the values of the actual and the predicted class\n",
    "y_true = [[1,2,0,1], [0,4], [3], [1,2]]\n",
    "y_pred = [[1,1,0,1], [1,4], [2], [1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(mapk(y_true, y_pred,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`F1 Samples` implementation [here](https://medium.com/analytics-vidhya/metrics-for-multi-label-classification-49cc5aeba1c3#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjgxOWQxZTYxNDI5ZGQzZDNjYWVmMTI5YzBhYzJiYWU4YzZkNDZmYmMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2MzAyNzYxNDYsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwNTAzNjUxNTUwMDU1MTQ1OTkzNSIsImVtYWlsIjoiZXBhc3NldG9AZ21haWwuY29tIiwiZW1haWxfdmVyaWZpZWQiOnRydWUsImF6cCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsIm5hbWUiOiJFZHVhcmRvIFBhc3NldG8iLCJwaWN0dXJlIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tL2EtL0FPaDE0R2pJNmh5V3FSTGNfdHZCYlg4OWxFTEphZ3diMFBYeXJNOGN1YXBLR1E9czk2LWMiLCJnaXZlbl9uYW1lIjoiRWR1YXJkbyIsImZhbWlseV9uYW1lIjoiUGFzc2V0byIsImlhdCI6MTYzMDI3NjQ0NiwiZXhwIjoxNjMwMjgwMDQ2LCJqdGkiOiIzYzYyZThiZDhkYWU4YjU4NWJlZDI4ZGFhYjE5ZDkwY2MyOTFmNjhlIn0.kwd1YjjoxP-RUFHA86RftkGHMMwic3edRM31Yz8sJL9dg0jzPwS2c9peJ9kDuIQK5x8PWvZxhnl-wI32M_D_FvWv5UXad1cYnkuEGnxeo94LPCUam-aOnUvDDpefUEOv8Oe2751C0VH1MrlDiOQxyGcYBIjnr2NtdaN8Y8pm-ZLonqw3zpZO-2Wlkhnrb12ruZmpWD2CbqZCHpNwmYq0bQqCrNp_dCZ9mBjc5xrYN2G8Us7ESZcCnqLLjk_cb6UVV81LFjKkrjGifBsOac-ANoc7TBJQnFW41FISORWL8j84mW7jl8UgEmxrgc8kaFtHm6oC5ptc9YLRBDq1Q93ZBQ)\n",
    "\n",
    "\"This metric calculates the F1 score for each instance in the data and then calculates the average of the F1 scores\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_sampled(actual, pred):\n",
    "    #converting the multi-label classification to a binary output\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    actual = mlb.fit_transform(actual)\n",
    "    pred = mlb.fit_transform(pred)\n",
    "\n",
    "    #fitting the data for calculating the f1 score \n",
    "    f1 = f1_score(actual, pred, average = \"samples\")\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the values of the actual and the predicted class\n",
    "y_true = [[1,2,0,1], [0,4], [3], [1,2]]\n",
    "y_pred = [[1,1,0,1], [1,4], [2], [1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(f1_sampled(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
