{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Testing\n",
    "\n",
    "---\n",
    "\n",
    "**Run on terminal** requisites:\n",
    "\n",
    "\"If someone in the future comes with a revised or new dataset of messages, they should be able to easily create a new model just by running your code. These Python scripts should be able to run with additional arguments specifying the files used for the data and model.\"\n",
    "\n",
    "`python process_data.py disaster_messages.csv disaster_categories.csv DisasterResponse.db`\n",
    "\n",
    "`python train_classifier.py ../data/DisasterResponse.db classifier.pkl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the test part of Machine Learning Pipeline\n",
    "\n",
    ">- import libraries\n",
    ">- read data from a SQLite table named `sqlite:///Messages.db`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from time import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint as pp\n",
    "import pickle\n",
    "\n",
    "import udacourse2 #my library for this project\n",
    "import train_classifier as tr #my pipeline\n",
    "\n",
    "data_file = 'sqlite:///Messages.db' #sys.argv[1] \n",
    "classifier = 'classifier.pkl' #sys.argv[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Test `load_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###load_data function started\n",
      "existing tables in my SQLite database: ['Messages']\n",
      "all labels are blank in 6304 rows\n",
      "remaining rows: 19876\n",
      "removal complete!\n",
      "*tokenized column don´t exist, creating it\n",
      "found 6 rows with no tokens\n",
      "*after removal, found 0 rows with no tokens\n",
      "*tokenized column dropped\n",
      "now I have 19870 rows to train\n",
      "###function group_check started\n",
      "  - count for main class:aid_related, 10841 entries\n",
      "  - for main, without any sub-categories,  3507 entries\n",
      "  - for subcategories,  7360 entries\n",
      "  - for lost parent sub-categories,  26 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0829s\n",
      "###function group_check started\n",
      "  - count for main class:weather_related, 7286 entries\n",
      "  - for main, without any sub-categories,  1357 entries\n",
      "  - for subcategories,  5929 entries\n",
      "  - for lost parent sub-categories,  0 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0370s\n",
      "###function group_check started\n",
      "  - count for main class:infrastructure_related, 1705 entries\n",
      "  - for main, without any sub-categories,  679 entries\n",
      "  - for subcategories,  2918 entries\n",
      "  - for lost parent sub-categories,  1892 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0690s\n",
      "###function group_check started\n",
      "  - count for main class:related, 19870 entries\n",
      "  - for main, without any sub-categories,  9414 entries\n",
      "  - for subcategories,  10456 entries\n",
      "  - for lost parent sub-categories,  0 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0430s\n",
      "X-training will be the message column\n",
      "*request -> column OK\n",
      "*offer -> column OK\n",
      "*aid_related -> column OK\n",
      "*medical_help -> column OK\n",
      "*medical_products -> column OK\n",
      "*search_and_rescue -> column OK\n",
      "*security -> column OK\n",
      "*military -> column OK\n",
      "*child_alone -> only zeroes (un)training column!\n",
      "*water -> column OK\n",
      "*food -> column OK\n",
      "*shelter -> column OK\n",
      "*clothing -> column OK\n",
      "*money -> column OK\n",
      "*missing_people -> column OK\n",
      "*refugees -> column OK\n",
      "*death -> column OK\n",
      "*other_aid -> column OK\n",
      "*infrastructure_related -> column OK\n",
      "*transport -> column OK\n",
      "*buildings -> column OK\n",
      "*electricity -> column OK\n",
      "*tools -> column OK\n",
      "*hospitals -> column OK\n",
      "*shops -> column OK\n",
      "*aid_centers -> column OK\n",
      "*other_infrastructure -> column OK\n",
      "*weather_related -> column OK\n",
      "*floods -> column OK\n",
      "*storm -> column OK\n",
      "*fire -> column OK\n",
      "*earthquake -> column OK\n",
      "*cold -> column OK\n",
      "*other_weather -> column OK\n",
      "*direct_report -> column OK\n",
      "remove colums: ['child_alone']\n",
      "(un)trainable label columns removed\n",
      "*dataset breaked into X-Training Text Column and Y-Multilabels\n",
      "process time:44 seconds\n"
     ]
    }
   ],
   "source": [
    "X, y = tr.load_data(data_file=data_file,\n",
    "                    remove_cols=True,\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Weather update - a cold front from Cuba that c...\n",
       "1              Is the Hurricane over or is it not over\n",
       "2                      Looking for someone but no name\n",
       "3    UN reports Leogane 80-90 destroyed. Only Hospi...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>search_and_rescue</th>\n",
       "      <th>security</th>\n",
       "      <th>military</th>\n",
       "      <th>water</th>\n",
       "      <th>food</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   request  offer  aid_related  medical_help  medical_products  \\\n",
       "0        0      0            0             0                 0   \n",
       "1        0      0            1             0                 0   \n",
       "2        0      0            0             0                 0   \n",
       "3        1      0            1             0                 1   \n",
       "\n",
       "   search_and_rescue  security  military  water  food  ...  aid_centers  \\\n",
       "0                  0         0         0      0     0  ...            0   \n",
       "1                  0         0         0      0     0  ...            0   \n",
       "2                  0         0         0      0     0  ...            0   \n",
       "3                  0         0         0      0     0  ...            0   \n",
       "\n",
       "   other_infrastructure  weather_related  floods  storm  fire  earthquake  \\\n",
       "0                     0                0       0      0     0           0   \n",
       "1                     0                1       0      1     0           0   \n",
       "2                     0                0       0      0     0           0   \n",
       "3                     0                0       0      0     0           0   \n",
       "\n",
       "   cold  other_weather  direct_report  \n",
       "0     0              0              0  \n",
       "1     0              0              0  \n",
       "2     0              0              0  \n",
       "3     0              0              0  \n",
       "\n",
       "[4 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Test `build_model` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###build_model function started\n",
      "Tree-type Classifier (Adaboost-default) pipeline is on the way\n",
      "*note: parameter C, is NOT used in this family of Classifiers, so don´t call it!\n",
      "creating convencional Adaboost pipeline\n",
      "*Classifier pipeline was created\n",
      "process time:0 seconds\n"
     ]
    }
   ],
   "source": [
    "model_pipeline = tr.build_model(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function fn_tokenize_fast at 0x000002B9BAF713A0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=AdaBoostClassifier(random_state=42)))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test `train` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###train function started\n",
      "data split into train and text seems OK\n",
      "###function scores_report started\n",
      "using top 10 labels\n",
      "######################################################\n",
      "*aid_related -> label iloc[2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70      2260\n",
      "           1       0.76      0.70      0.73      2708\n",
      "\n",
      "    accuracy                           0.71      4968\n",
      "   macro avg       0.71      0.72      0.71      4968\n",
      "weighted avg       0.72      0.71      0.72      4968\n",
      "\n",
      "######################################################\n",
      "*weather_related -> label iloc[26]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      3167\n",
      "           1       0.86      0.71      0.78      1801\n",
      "\n",
      "    accuracy                           0.85      4968\n",
      "   macro avg       0.86      0.82      0.83      4968\n",
      "weighted avg       0.85      0.85      0.85      4968\n",
      "\n",
      "######################################################\n",
      "*direct_report -> label iloc[33]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      3693\n",
      "           1       0.70      0.43      0.53      1275\n",
      "\n",
      "    accuracy                           0.81      4968\n",
      "   macro avg       0.76      0.68      0.71      4968\n",
      "weighted avg       0.79      0.81      0.79      4968\n",
      "\n",
      "######################################################\n",
      "*request -> label iloc[0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      3868\n",
      "           1       0.79      0.55      0.65      1100\n",
      "\n",
      "    accuracy                           0.87      4968\n",
      "   macro avg       0.84      0.75      0.78      4968\n",
      "weighted avg       0.86      0.87      0.86      4968\n",
      "\n",
      "######################################################\n",
      "*other_aid -> label iloc[16]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4103\n",
      "           1       0.52      0.14      0.22       865\n",
      "\n",
      "    accuracy                           0.83      4968\n",
      "   macro avg       0.68      0.56      0.56      4968\n",
      "weighted avg       0.79      0.83      0.78      4968\n",
      "\n",
      "######################################################\n",
      "*food -> label iloc[9]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4200\n",
      "           1       0.80      0.78      0.79       768\n",
      "\n",
      "    accuracy                           0.94      4968\n",
      "   macro avg       0.88      0.87      0.88      4968\n",
      "weighted avg       0.94      0.94      0.94      4968\n",
      "\n",
      "######################################################\n",
      "*earthquake -> label iloc[30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4356\n",
      "           1       0.90      0.81      0.85       612\n",
      "\n",
      "    accuracy                           0.96      4968\n",
      "   macro avg       0.94      0.90      0.92      4968\n",
      "weighted avg       0.96      0.96      0.96      4968\n",
      "\n",
      "######################################################\n",
      "*storm -> label iloc[28]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      4383\n",
      "           1       0.77      0.51      0.62       585\n",
      "\n",
      "    accuracy                           0.92      4968\n",
      "   macro avg       0.85      0.75      0.79      4968\n",
      "weighted avg       0.92      0.92      0.92      4968\n",
      "\n",
      "######################################################\n",
      "*shelter -> label iloc[10]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      4395\n",
      "           1       0.79      0.54      0.64       573\n",
      "\n",
      "    accuracy                           0.93      4968\n",
      "   macro avg       0.87      0.76      0.80      4968\n",
      "weighted avg       0.93      0.93      0.93      4968\n",
      "\n",
      "######################################################\n",
      "*floods -> label iloc[27]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4417\n",
      "           1       0.86      0.60      0.71       551\n",
      "\n",
      "    accuracy                           0.95      4968\n",
      "   macro avg       0.91      0.80      0.84      4968\n",
      "weighted avg       0.94      0.95      0.94      4968\n",
      "\n",
      "###Model metrics for 10 labels:\n",
      " Accuracy: 0.652 (65.2%)\n",
      " Precision: 0.775 (77.5%)\n",
      " Recall: 0.578 (57.8%)\n",
      "\n",
      "###Worst metrics:\n",
      " Accuracy: 0.222 (22.2%) for other_aid\n",
      " Precision: 0.519 (51.9%) for other_aid\n",
      " Recall: 0.141 (14.1%) for other_aid\n",
      "process time:0.5207 seconds\n",
      "*metrics alert: something is wrong, model is predicting poorly\n",
      "*classifier was trained!\n",
      "process time:150 seconds\n"
     ]
    }
   ],
   "source": [
    "model = tr.train(X=X,\n",
    "                 y=y,\n",
    "                 model=model_pipeline,\n",
    "                 verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test `export_model` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###export_model function started\n",
      "*trained Classifier was exported\n",
      "process time:0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = 'classifier.pkl'\n",
    "\n",
    "tr.export_model(model=model,\n",
    "                file_name=file_name,\n",
    "                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function fn_tokenize_fast at 0x000002B9BAF713A0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=AdaBoostClassifier(random_state=42)))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('classifier.pkl', 'rb') as pk_reader:\n",
    "    model_unpk = pickle.load(pk_reader)\n",
    "    \n",
    "model_unpk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test `run_pipeline` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process time: 191 seconds\n"
     ]
    }
   ],
   "source": [
    "data_file = 'sqlite:///Messages.db'\n",
    "start = time()\n",
    "\n",
    "tr.run_pipeline(data_file=data_file, verbose=False)\n",
    "\n",
    "spent = time() - start\n",
    "print('process time: {:.0f} seconds'.format(spent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.`Main` function calling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the main Machine Learning Pipeline function. It calls the other \n",
      "    ones, in the correct order.\n",
      "    Example: python train_classifier.py\n",
      "    Basic parameters:\n",
      "      - data_file - just indicate the complete path after the command \n",
      "        (default:'../data/DisasterResponse.db')\n",
      "        Example: python train_classifier.py ../data/Database.db\n",
      "      - classifier - you need to indicate both data_file and classifier\n",
      "        (default:'classifier.pkl')\n",
      "        Example: python train_classifier.py ../data/Database.db other.pkl\n",
      "    Extra parameters:\n",
      "      here you need to indicate both data_file and classifier, in order to use \n",
      "      them you can use only one, or more, in any order\n",
      "      -v -> verbose - if you want some verbosity during the running\n",
      "            (default=False)\n",
      "      -r -> remove columns - if you want to remove (un)trainable columns from\n",
      "            your y-labels dataset (default=False)\n",
      "      -t -> test size for splitting your data (default=0.25)\n",
      "      -s -> change Classifier from Adaboost (tree-type) to LSVM \n",
      "            (support vector machine-type)\n",
      "      -C -> C parameter for your Classificer (default=2.0)\n",
      "      -a -> run metrics over ALL labels (not recommended!) \n",
      "            default=False - run metris over the 10 main labels only\n",
      "      -p -> pre_tokenize - keep preprocessing tokenization column, for saving\n",
      "            processing time. Obsservation: keeping this column turns the system \n",
      "            faster, but may cause instability on Classifier training on Flask\n",
      "            due to \"pipeline leakage\" (not recomended) (default=False)  \n",
      "      -g -> perform Grid Search over Adaboost before training for the best\n",
      "            parameters. Please use it wisely, as it costs a lot of processing\n",
      "            time!\n",
      "      Example: python train_classifier data.db other.pkl -C=0.5 -t=0.2 -r -v\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(eval(pp.pformat(tr.main.__doc__)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###run_pipeline function started\n",
      "###load_data function started\n",
      "existing tables in my SQLite database: ['Messages']\n",
      "all labels are blank in 6304 rows\n",
      "remaining rows: 19876\n",
      "removal complete!\n",
      "*tokenized column don´t exist, creating it\n",
      "found 6 rows with no tokens\n",
      "*after removal, found 0 rows with no tokens\n",
      "*tokenized column dropped\n",
      "now I have 19870 rows to train\n",
      "###function group_check started\n",
      "  - count for main class:aid_related, 10841 entries\n",
      "  - for main, without any sub-categories,  3507 entries\n",
      "  - for subcategories,  7360 entries\n",
      "  - for lost parent sub-categories,  26 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0989s\n",
      "###function group_check started\n",
      "  - count for main class:weather_related, 7286 entries\n",
      "  - for main, without any sub-categories,  1357 entries\n",
      "  - for subcategories,  5929 entries\n",
      "  - for lost parent sub-categories,  0 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.1099s\n",
      "###function group_check started\n",
      "  - count for main class:infrastructure_related, 1705 entries\n",
      "  - for main, without any sub-categories,  679 entries\n",
      "  - for subcategories,  2918 entries\n",
      "  - for lost parent sub-categories,  1892 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0640s\n",
      "###function group_check started\n",
      "  - count for main class:related, 19870 entries\n",
      "  - for main, without any sub-categories,  9414 entries\n",
      "  - for subcategories,  10456 entries\n",
      "  - for lost parent sub-categories,  0 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0710s\n",
      "X-training will be the message column\n",
      "y dataset has 36 labels\n",
      "*dataset breaked into X-Training Text Column and Y-Multilabels\n",
      "process time:42 seconds\n",
      "###build_model function started\n",
      "Tree-type Classifier (Adaboost-default) pipeline is on the way\n",
      "*note: parameter C, is NOT used in this family of Classifiers, so don´t call it!\n",
      "creating convencional Adaboost pipeline\n",
      "*Classifier pipeline was created\n",
      "process time:0 seconds\n",
      "###train function started\n",
      "data split into train and text seems OK\n",
      "###function scores_report started\n",
      "using top 10 labels\n",
      "######################################################\n",
      "*aid_related -> label iloc[3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70      2260\n",
      "           1       0.76      0.70      0.73      2708\n",
      "\n",
      "    accuracy                           0.71      4968\n",
      "   macro avg       0.71      0.72      0.71      4968\n",
      "weighted avg       0.72      0.71      0.72      4968\n",
      "\n",
      "######################################################\n",
      "*weather_related -> label iloc[28]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      3167\n",
      "           1       0.86      0.71      0.78      1801\n",
      "\n",
      "    accuracy                           0.85      4968\n",
      "   macro avg       0.86      0.82      0.83      4968\n",
      "weighted avg       0.85      0.85      0.85      4968\n",
      "\n",
      "######################################################\n",
      "*direct_report -> label iloc[35]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      3693\n",
      "           1       0.70      0.43      0.53      1275\n",
      "\n",
      "    accuracy                           0.81      4968\n",
      "   macro avg       0.76      0.68      0.71      4968\n",
      "weighted avg       0.79      0.81      0.79      4968\n",
      "\n",
      "######################################################\n",
      "*request -> label iloc[1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      3868\n",
      "           1       0.79      0.55      0.65      1100\n",
      "\n",
      "    accuracy                           0.87      4968\n",
      "   macro avg       0.84      0.75      0.78      4968\n",
      "weighted avg       0.86      0.87      0.86      4968\n",
      "\n",
      "######################################################\n",
      "*other_aid -> label iloc[18]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4103\n",
      "           1       0.52      0.14      0.22       865\n",
      "\n",
      "    accuracy                           0.83      4968\n",
      "   macro avg       0.68      0.56      0.56      4968\n",
      "weighted avg       0.79      0.83      0.78      4968\n",
      "\n",
      "######################################################\n",
      "*food -> label iloc[11]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4200\n",
      "           1       0.80      0.78      0.79       768\n",
      "\n",
      "    accuracy                           0.94      4968\n",
      "   macro avg       0.88      0.87      0.88      4968\n",
      "weighted avg       0.94      0.94      0.94      4968\n",
      "\n",
      "######################################################\n",
      "*earthquake -> label iloc[32]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4356\n",
      "           1       0.90      0.81      0.85       612\n",
      "\n",
      "    accuracy                           0.96      4968\n",
      "   macro avg       0.94      0.90      0.92      4968\n",
      "weighted avg       0.96      0.96      0.96      4968\n",
      "\n",
      "######################################################\n",
      "*storm -> label iloc[30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      4383\n",
      "           1       0.77      0.51      0.62       585\n",
      "\n",
      "    accuracy                           0.92      4968\n",
      "   macro avg       0.85      0.75      0.79      4968\n",
      "weighted avg       0.92      0.92      0.92      4968\n",
      "\n",
      "######################################################\n",
      "*shelter -> label iloc[12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      4395\n",
      "           1       0.79      0.54      0.64       573\n",
      "\n",
      "    accuracy                           0.93      4968\n",
      "   macro avg       0.87      0.76      0.80      4968\n",
      "weighted avg       0.93      0.93      0.93      4968\n",
      "\n",
      "######################################################\n",
      "*floods -> label iloc[29]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4417\n",
      "           1       0.86      0.60      0.71       551\n",
      "\n",
      "    accuracy                           0.95      4968\n",
      "   macro avg       0.91      0.80      0.84      4968\n",
      "weighted avg       0.94      0.95      0.94      4968\n",
      "\n",
      "###Model metrics for 10 labels:\n",
      " Accuracy: 0.652 (65.2%)\n",
      " Precision: 0.775 (77.5%)\n",
      " Recall: 0.578 (57.8%)\n",
      "\n",
      "###Worst metrics:\n",
      " Accuracy: 0.222 (22.2%) for other_aid\n",
      " Precision: 0.519 (51.9%) for other_aid\n",
      " Recall: 0.141 (14.1%) for other_aid\n",
      "process time:0.7066 seconds\n",
      "*metrics alert: something is wrong, model is predicting poorly\n",
      "*classifier was trained!\n",
      "process time:158 seconds\n",
      "###export_model function started\n",
      "*trained Classifier was exported\n",
      "process time:0 seconds\n",
      "process time:200 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.run_pipeline(data_file=data_file,\n",
    "                classifier=classifier,\n",
    "                verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test Area\n",
    "\n",
    "SQL correct string for URL [here](https://stackoverflow.com/questions/49776619/sqlalchemy-exc-argumenterror-could-not-parse-rfc1738-url-from-string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###run_pipeline function started\n",
      "###load_data function started\n",
      "existing tables in my SQLite database: ['Messages']\n",
      "all labels are blank in 6304 rows\n",
      "remaining rows: 19876\n",
      "removal complete!\n",
      "*tokenized column don´t exist, creating it\n",
      "found 6 rows with no tokens\n",
      "*after removal, found 0 rows with no tokens\n",
      "*tokenized column dropped\n",
      "now I have 19870 rows to train\n",
      "###function group_check started\n",
      "  - count for main class:aid_related, 10841 entries\n",
      "  - for main, without any sub-categories,  3507 entries\n",
      "  - for subcategories,  7360 entries\n",
      "  - for lost parent sub-categories,  26 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0790s\n",
      "###function group_check started\n",
      "  - count for main class:weather_related, 7286 entries\n",
      "  - for main, without any sub-categories,  1357 entries\n",
      "  - for subcategories,  5929 entries\n",
      "  - for lost parent sub-categories,  0 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0370s\n",
      "###function group_check started\n",
      "  - count for main class:infrastructure_related, 1705 entries\n",
      "  - for main, without any sub-categories,  679 entries\n",
      "  - for subcategories,  2918 entries\n",
      "  - for lost parent sub-categories,  1892 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0410s\n",
      "###function group_check started\n",
      "  - count for main class:related, 19870 entries\n",
      "  - for main, without any sub-categories,  9414 entries\n",
      "  - for subcategories,  10456 entries\n",
      "  - for lost parent sub-categories,  0 entries\n",
      "    *correcting, new count: 0 entries\n",
      "elapsed time: 0.0400s\n",
      "X-training will be the message column\n",
      "y dataset has 36 labels\n",
      "*dataset breaked into X-Training Text Column and Y-Multilabels\n",
      "process time:44 seconds\n",
      "###build_model function started\n",
      "Tree-type Classifier (Adaboost-default) pipeline is on the way\n",
      "*note: parameter C, is NOT used in this family of Classifiers, so don´t call it!\n",
      "creating convencional Adaboost pipeline\n",
      "*Classifier pipeline was created\n",
      "process time:0 seconds\n",
      "###train function started\n",
      "data split into train and text seems OK\n",
      "###function scores_report started\n",
      "using top 10 labels\n",
      "######################################################\n",
      "*aid_related -> label iloc[3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.73      0.70      2260\n",
      "           1       0.76      0.70      0.73      2708\n",
      "\n",
      "    accuracy                           0.71      4968\n",
      "   macro avg       0.71      0.72      0.71      4968\n",
      "weighted avg       0.72      0.71      0.72      4968\n",
      "\n",
      "######################################################\n",
      "*weather_related -> label iloc[28]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      3167\n",
      "           1       0.86      0.71      0.78      1801\n",
      "\n",
      "    accuracy                           0.85      4968\n",
      "   macro avg       0.86      0.82      0.83      4968\n",
      "weighted avg       0.85      0.85      0.85      4968\n",
      "\n",
      "######################################################\n",
      "*direct_report -> label iloc[35]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      3693\n",
      "           1       0.70      0.43      0.53      1275\n",
      "\n",
      "    accuracy                           0.81      4968\n",
      "   macro avg       0.76      0.68      0.71      4968\n",
      "weighted avg       0.79      0.81      0.79      4968\n",
      "\n",
      "######################################################\n",
      "*request -> label iloc[1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92      3868\n",
      "           1       0.79      0.55      0.65      1100\n",
      "\n",
      "    accuracy                           0.87      4968\n",
      "   macro avg       0.84      0.75      0.78      4968\n",
      "weighted avg       0.86      0.87      0.86      4968\n",
      "\n",
      "######################################################\n",
      "*other_aid -> label iloc[18]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90      4103\n",
      "           1       0.52      0.14      0.22       865\n",
      "\n",
      "    accuracy                           0.83      4968\n",
      "   macro avg       0.68      0.56      0.56      4968\n",
      "weighted avg       0.79      0.83      0.78      4968\n",
      "\n",
      "######################################################\n",
      "*food -> label iloc[11]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      4200\n",
      "           1       0.80      0.78      0.79       768\n",
      "\n",
      "    accuracy                           0.94      4968\n",
      "   macro avg       0.88      0.87      0.88      4968\n",
      "weighted avg       0.94      0.94      0.94      4968\n",
      "\n",
      "######################################################\n",
      "*earthquake -> label iloc[32]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      4356\n",
      "           1       0.90      0.81      0.85       612\n",
      "\n",
      "    accuracy                           0.96      4968\n",
      "   macro avg       0.94      0.90      0.92      4968\n",
      "weighted avg       0.96      0.96      0.96      4968\n",
      "\n",
      "######################################################\n",
      "*storm -> label iloc[30]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      4383\n",
      "           1       0.77      0.51      0.62       585\n",
      "\n",
      "    accuracy                           0.92      4968\n",
      "   macro avg       0.85      0.75      0.79      4968\n",
      "weighted avg       0.92      0.92      0.92      4968\n",
      "\n",
      "######################################################\n",
      "*shelter -> label iloc[12]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96      4395\n",
      "           1       0.79      0.54      0.64       573\n",
      "\n",
      "    accuracy                           0.93      4968\n",
      "   macro avg       0.87      0.76      0.80      4968\n",
      "weighted avg       0.93      0.93      0.93      4968\n",
      "\n",
      "######################################################\n",
      "*floods -> label iloc[29]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      4417\n",
      "           1       0.86      0.60      0.71       551\n",
      "\n",
      "    accuracy                           0.95      4968\n",
      "   macro avg       0.91      0.80      0.84      4968\n",
      "weighted avg       0.94      0.95      0.94      4968\n",
      "\n",
      "###Model metrics for 10 labels:\n",
      " Accuracy: 0.652 (65.2%)\n",
      " Precision: 0.775 (77.5%)\n",
      " Recall: 0.578 (57.8%)\n",
      "\n",
      "###Worst metrics:\n",
      " Accuracy: 0.222 (22.2%) for other_aid\n",
      " Precision: 0.519 (51.9%) for other_aid\n",
      " Recall: 0.141 (14.1%) for other_aid\n",
      "process time:0.4217 seconds\n",
      "*metrics alert: something is wrong, model is predicting poorly\n",
      "*classifier was trained!\n",
      "process time:150 seconds\n",
      "###export_model function started\n",
      "*trained Classifier was exported\n",
      "process time:0 seconds\n",
      "process time:195 seconds\n"
     ]
    }
   ],
   "source": [
    "tr.main(data_file=data_file,\n",
    "        classifier=classifier,\n",
    "        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "test area",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-c88da6c8e934>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test area'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mException\u001b[0m: test area"
     ]
    }
   ],
   "source": [
    "raise Exception('test area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#args = sys.argv\n",
    "\n",
    "simul_args = ['xuru.db', 'boco.pkl', '-r', '-C=3.', '-t=.2', '-a', '-v']\n",
    "#simul_args = ['xuru.db']\n",
    "Esimul_args = ['xuru.db', 'boco.pkl', '-v', '-a', '-C=4.0', '-r', '-xu']\n",
    "optionals = ['-r', '-C', '-t', '-a', '-v']\n",
    "args = simul_args\n",
    "\n",
    "#first, set default arguments\n",
    "data_file = '../data/DisasterResponse.db'\n",
    "classifier = 'classifier.pkl'\n",
    "remove_cols = False\n",
    "C = 2.0\n",
    "test_size = 0.25\n",
    "best_10 = True\n",
    "verbose = False\n",
    "\n",
    "#second, try to change the two main arguments\n",
    "try:\n",
    "    args[0]\n",
    "except IndexError:\n",
    "    pass\n",
    "else:\n",
    "    data_file = args[0]   \n",
    "try:\n",
    "    args[1]\n",
    "except IndexError:\n",
    "    pass\n",
    "else:\n",
    "    classifier = args[1]\n",
    "\n",
    "remain_args = args[2:] #elliminate the two main arg    \n",
    "if len(remain_args) > 0:\n",
    "    for arg in remain_args:\n",
    "        comm = arg[:2] #get the command part\n",
    "        if comm == '-r':\n",
    "            remove_cols = True\n",
    "        elif comm == '-C':\n",
    "            C = arg[3:]\n",
    "        elif comm == '-t':\n",
    "            test_size = arg[3:]\n",
    "        elif comm == '-a':\n",
    "            best_10=False\n",
    "        elif comm == '-v':\n",
    "            verbose=True\n",
    "        else:\n",
    "            raise Exception('invalid argument')\n",
    "\n",
    "print('data_file={} classifier={} remove_cols={} C={} test_size={} best_10={} verbose={}'\\\n",
    "      .format(data_file, classifier, remove_cols, C, test_size, best_10, verbose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg='-s;'\n",
    "\n",
    "arg[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
